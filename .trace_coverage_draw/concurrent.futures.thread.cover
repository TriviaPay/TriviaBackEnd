       # Copyright 2009 Brian Quinlan. All Rights Reserved.
       # Licensed to PSF under a Contributor Agreement.
       
    1: """Implements ThreadPoolExecutor."""
       
    1: __author__ = 'Brian Quinlan (brian@sweetapp.com)'
       
    1: from concurrent.futures import _base
    1: import itertools
    1: import queue
    1: import threading
    1: import types
    1: import weakref
    1: import os
       
       
    1: _threads_queues = weakref.WeakKeyDictionary()
    1: _shutdown = False
       # Lock that ensures that new workers are not created while the interpreter is
       # shutting down. Must be held while mutating _threads_queues and _shutdown.
    1: _global_shutdown_lock = threading.Lock()
       
    1: def _python_exit():
           global _shutdown
>>>>>>     with _global_shutdown_lock:
>>>>>>         _shutdown = True
>>>>>>     items = list(_threads_queues.items())
>>>>>>     for t, q in items:
>>>>>>         q.put(None)
>>>>>>     for t, q in items:
>>>>>>         t.join()
       
       # Register for `_python_exit()` to be called just before joining all
       # non-daemon threads. This is used instead of `atexit.register()` for
       # compatibility with subinterpreters, which no longer support daemon threads.
       # See bpo-39812 for context.
    1: threading._register_atexit(_python_exit)
       
       
    2: class _WorkItem(object):
    1:     def __init__(self, future, fn, args, kwargs):
    1:         self.future = future
    1:         self.fn = fn
    1:         self.args = args
    1:         self.kwargs = kwargs
       
    1:     def run(self):
    1:         if not self.future.set_running_or_notify_cancel():
>>>>>>             return
       
    1:         try:
    1:             result = self.fn(*self.args, **self.kwargs)
>>>>>>         except BaseException as exc:
>>>>>>             self.future.set_exception(exc)
                   # Break a reference cycle with the exception 'exc'
>>>>>>             self = None
               else:
    1:             self.future.set_result(result)
       
    1:     __class_getitem__ = classmethod(types.GenericAlias)
       
       
    1: def _worker(executor_reference, work_queue, initializer, initargs):
    1:     if initializer is not None:
>>>>>>         try:
>>>>>>             initializer(*initargs)
>>>>>>         except BaseException:
>>>>>>             _base.LOGGER.critical('Exception in initializer:', exc_info=True)
>>>>>>             executor = executor_reference()
>>>>>>             if executor is not None:
>>>>>>                 executor._initializer_failed()
>>>>>>             return
    1:     try:
               while True:
    2:             work_item = work_queue.get(block=True)
    2:             if work_item is not None:
    1:                 work_item.run()
                       # Delete references to object. See issue16284
    1:                 del work_item
       
                       # attempt to increment idle count
    1:                 executor = executor_reference()
    1:                 if executor is not None:
    1:                     executor._idle_semaphore.release()
    1:                 del executor
    1:                 continue
       
    1:             executor = executor_reference()
                   # Exit if:
                   #   - The interpreter is shutting down OR
                   #   - The executor that owns the worker has been collected OR
                   #   - The executor that owns the worker has been shutdown.
    1:             if _shutdown or executor is None or executor._shutdown:
                       # Flag the executor as shutting down as early as possible if it
                       # is not gc-ed yet.
    1:                 if executor is not None:
    1:                     executor._shutdown = True
                       # Notice other workers
    1:                 work_queue.put(None)
    1:                 return
>>>>>>             del executor
>>>>>>     except BaseException:
>>>>>>         _base.LOGGER.critical('Exception in worker', exc_info=True)
       
       
    2: class BrokenThreadPool(_base.BrokenExecutor):
    1:     """
           Raised when a worker thread in a ThreadPoolExecutor failed initializing.
           """
       
       
    2: class ThreadPoolExecutor(_base.Executor):
       
           # Used to assign unique thread names when thread_name_prefix is not supplied.
    1:     _counter = itertools.count().__next__
       
    1:     def __init__(self, max_workers=None, thread_name_prefix='',
                        initializer=None, initargs=()):
               """Initializes a new ThreadPoolExecutor instance.
       
               Args:
                   max_workers: The maximum number of threads that can be used to
                       execute the given calls.
                   thread_name_prefix: An optional name prefix to give our threads.
                   initializer: A callable used to initialize worker threads.
                   initargs: A tuple of arguments to pass to the initializer.
               """
    1:         if max_workers is None:
                   # ThreadPoolExecutor is often used to:
                   # * CPU bound task which releases GIL
                   # * I/O bound task (which releases GIL, of course)
                   #
                   # We use cpu_count + 4 for both types of tasks.
                   # But we limit it to 32 to avoid consuming surprisingly large resource
                   # on many core machine.
>>>>>>             max_workers = min(32, (os.cpu_count() or 1) + 4)
    1:         if max_workers <= 0:
>>>>>>             raise ValueError("max_workers must be greater than 0")
       
    1:         if initializer is not None and not callable(initializer):
>>>>>>             raise TypeError("initializer must be a callable")
       
    1:         self._max_workers = max_workers
    1:         self._work_queue = queue.SimpleQueue()
    1:         self._idle_semaphore = threading.Semaphore(0)
    1:         self._threads = set()
    1:         self._broken = False
    1:         self._shutdown = False
    1:         self._shutdown_lock = threading.Lock()
    2:         self._thread_name_prefix = (thread_name_prefix or
    1:                                     ("ThreadPoolExecutor-%d" % self._counter()))
    1:         self._initializer = initializer
    1:         self._initargs = initargs
       
    1:     def submit(self, fn, /, *args, **kwargs):
    1:         with self._shutdown_lock, _global_shutdown_lock:
    1:             if self._broken:
>>>>>>                 raise BrokenThreadPool(self._broken)
       
    1:             if self._shutdown:
>>>>>>                 raise RuntimeError('cannot schedule new futures after shutdown')
    1:             if _shutdown:
>>>>>>                 raise RuntimeError('cannot schedule new futures after '
                                          'interpreter shutdown')
       
    1:             f = _base.Future()
    1:             w = _WorkItem(f, fn, args, kwargs)
       
    1:             self._work_queue.put(w)
    1:             self._adjust_thread_count()
    1:             return f
    1:     submit.__doc__ = _base.Executor.submit.__doc__
       
    1:     def _adjust_thread_count(self):
               # if idle threads are available, don't spin new threads
    1:         if self._idle_semaphore.acquire(timeout=0):
>>>>>>             return
       
               # When the executor gets lost, the weakref callback will wake up
               # the worker threads.
    1:         def weakref_cb(_, q=self._work_queue):
>>>>>>             q.put(None)
       
    1:         num_threads = len(self._threads)
    1:         if num_threads < self._max_workers:
    2:             thread_name = '%s_%d' % (self._thread_name_prefix or self,
    1:                                      num_threads)
    2:             t = threading.Thread(name=thread_name, target=_worker,
    2:                                  args=(weakref.ref(self, weakref_cb),
    1:                                        self._work_queue,
    1:                                        self._initializer,
    1:                                        self._initargs))
    1:             t.start()
    1:             self._threads.add(t)
    1:             _threads_queues[t] = self._work_queue
       
    1:     def _initializer_failed(self):
>>>>>>         with self._shutdown_lock:
>>>>>>             self._broken = ('A thread initializer failed, the thread pool '
                                   'is not usable anymore')
                   # Drain work queue and mark pending futures failed
                   while True:
>>>>>>                 try:
>>>>>>                     work_item = self._work_queue.get_nowait()
>>>>>>                 except queue.Empty:
>>>>>>                     break
>>>>>>                 if work_item is not None:
>>>>>>                     work_item.future.set_exception(BrokenThreadPool(self._broken))
       
    1:     def shutdown(self, wait=True, *, cancel_futures=False):
    1:         with self._shutdown_lock:
    1:             self._shutdown = True
    1:             if cancel_futures:
                       # Drain all work items from the queue, and then cancel their
                       # associated futures.
                       while True:
>>>>>>                     try:
>>>>>>                         work_item = self._work_queue.get_nowait()
>>>>>>                     except queue.Empty:
>>>>>>                         break
>>>>>>                     if work_item is not None:
>>>>>>                         work_item.future.cancel()
       
                   # Send a wake-up to prevent threads calling
                   # _work_queue.get(block=True) from permanently blocking.
    1:             self._work_queue.put(None)
    1:         if wait:
    2:             for t in self._threads:
    1:                 t.join()
    1:     shutdown.__doc__ = _base.Executor.shutdown.__doc__
