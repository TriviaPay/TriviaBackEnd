    1: from __future__ import annotations
       
    1: from collections import defaultdict
    1: from copy import copy
    1: from functools import partial
    1: from typing import TYPE_CHECKING, Any, Callable, Iterable
       
    1: from pydantic_core import CoreSchema, PydanticCustomError, to_jsonable_python
    1: from pydantic_core import core_schema as cs
       
    1: from ._fields import PydanticMetadata
       
    1: if TYPE_CHECKING:
>>>>>>     from ..annotated_handlers import GetJsonSchemaHandler
       
       
    1: STRICT = {'strict'}
    1: SEQUENCE_CONSTRAINTS = {'min_length', 'max_length'}
    1: INEQUALITY = {'le', 'ge', 'lt', 'gt'}
    1: NUMERIC_CONSTRAINTS = {'multiple_of', 'allow_inf_nan', *INEQUALITY}
       
    1: STR_CONSTRAINTS = {*SEQUENCE_CONSTRAINTS, *STRICT, 'strip_whitespace', 'to_lower', 'to_upper', 'pattern'}
    1: BYTES_CONSTRAINTS = {*SEQUENCE_CONSTRAINTS, *STRICT}
       
    1: LIST_CONSTRAINTS = {*SEQUENCE_CONSTRAINTS, *STRICT}
    1: TUPLE_CONSTRAINTS = {*SEQUENCE_CONSTRAINTS, *STRICT}
    1: SET_CONSTRAINTS = {*SEQUENCE_CONSTRAINTS, *STRICT}
    1: DICT_CONSTRAINTS = {*SEQUENCE_CONSTRAINTS, *STRICT}
    1: GENERATOR_CONSTRAINTS = {*SEQUENCE_CONSTRAINTS, *STRICT}
       
    1: FLOAT_CONSTRAINTS = {*NUMERIC_CONSTRAINTS, *STRICT}
    1: INT_CONSTRAINTS = {*NUMERIC_CONSTRAINTS, *STRICT}
    1: BOOL_CONSTRAINTS = STRICT
    1: UUID_CONSTRAINTS = STRICT
       
    1: DATE_TIME_CONSTRAINTS = {*NUMERIC_CONSTRAINTS, *STRICT}
    1: TIMEDELTA_CONSTRAINTS = {*NUMERIC_CONSTRAINTS, *STRICT}
    1: TIME_CONSTRAINTS = {*NUMERIC_CONSTRAINTS, *STRICT}
    1: LAX_OR_STRICT_CONSTRAINTS = STRICT
       
    1: UNION_CONSTRAINTS = {'union_mode'}
    1: URL_CONSTRAINTS = {
           'max_length',
           'allowed_schemes',
           'host_required',
           'default_host',
           'default_port',
           'default_path',
       }
       
    1: TEXT_SCHEMA_TYPES = ('str', 'bytes', 'url', 'multi-host-url')
    1: SEQUENCE_SCHEMA_TYPES = ('list', 'tuple', 'set', 'frozenset', 'generator', *TEXT_SCHEMA_TYPES)
    1: NUMERIC_SCHEMA_TYPES = ('float', 'int', 'date', 'time', 'timedelta', 'datetime')
       
    1: CONSTRAINTS_TO_ALLOWED_SCHEMAS: dict[str, set[str]] = defaultdict(set)
    8: for constraint in STR_CONSTRAINTS:
    7:     CONSTRAINTS_TO_ALLOWED_SCHEMAS[constraint].update(TEXT_SCHEMA_TYPES)
    4: for constraint in BYTES_CONSTRAINTS:
    3:     CONSTRAINTS_TO_ALLOWED_SCHEMAS[constraint].update(('bytes',))
    4: for constraint in LIST_CONSTRAINTS:
    3:     CONSTRAINTS_TO_ALLOWED_SCHEMAS[constraint].update(('list',))
    4: for constraint in TUPLE_CONSTRAINTS:
    3:     CONSTRAINTS_TO_ALLOWED_SCHEMAS[constraint].update(('tuple',))
    4: for constraint in SET_CONSTRAINTS:
    3:     CONSTRAINTS_TO_ALLOWED_SCHEMAS[constraint].update(('set', 'frozenset'))
    4: for constraint in DICT_CONSTRAINTS:
    3:     CONSTRAINTS_TO_ALLOWED_SCHEMAS[constraint].update(('dict',))
    4: for constraint in GENERATOR_CONSTRAINTS:
    3:     CONSTRAINTS_TO_ALLOWED_SCHEMAS[constraint].update(('generator',))
    8: for constraint in FLOAT_CONSTRAINTS:
    7:     CONSTRAINTS_TO_ALLOWED_SCHEMAS[constraint].update(('float',))
    8: for constraint in INT_CONSTRAINTS:
    7:     CONSTRAINTS_TO_ALLOWED_SCHEMAS[constraint].update(('int',))
    8: for constraint in DATE_TIME_CONSTRAINTS:
    7:     CONSTRAINTS_TO_ALLOWED_SCHEMAS[constraint].update(('date', 'time', 'datetime'))
    8: for constraint in TIMEDELTA_CONSTRAINTS:
    7:     CONSTRAINTS_TO_ALLOWED_SCHEMAS[constraint].update(('timedelta',))
    8: for constraint in TIME_CONSTRAINTS:
    7:     CONSTRAINTS_TO_ALLOWED_SCHEMAS[constraint].update(('time',))
   22: for schema_type in (*TEXT_SCHEMA_TYPES, *SEQUENCE_SCHEMA_TYPES, *NUMERIC_SCHEMA_TYPES, 'typed-dict', 'model'):
   21:     CONSTRAINTS_TO_ALLOWED_SCHEMAS['strict'].add(schema_type)
    2: for constraint in UNION_CONSTRAINTS:
    1:     CONSTRAINTS_TO_ALLOWED_SCHEMAS[constraint].update(('union',))
    7: for constraint in URL_CONSTRAINTS:
    6:     CONSTRAINTS_TO_ALLOWED_SCHEMAS[constraint].update(('url', 'multi-host-url'))
    2: for constraint in BOOL_CONSTRAINTS:
    1:     CONSTRAINTS_TO_ALLOWED_SCHEMAS[constraint].update(('bool',))
    2: for constraint in UUID_CONSTRAINTS:
    1:     CONSTRAINTS_TO_ALLOWED_SCHEMAS[constraint].update(('uuid',))
    2: for constraint in LAX_OR_STRICT_CONSTRAINTS:
    1:     CONSTRAINTS_TO_ALLOWED_SCHEMAS[constraint].update(('lax-or-strict',))
       
       
    1: def add_js_update_schema(s: cs.CoreSchema, f: Callable[[], dict[str, Any]]) -> None:
>>>>>>     def update_js_schema(s: cs.CoreSchema, handler: GetJsonSchemaHandler) -> dict[str, Any]:
>>>>>>         js_schema = handler(s)
>>>>>>         js_schema.update(f())
>>>>>>         return js_schema
       
>>>>>>     if 'metadata' in s:
>>>>>>         metadata = s['metadata']
>>>>>>         if 'pydantic_js_functions' in s:
>>>>>>             metadata['pydantic_js_functions'].append(update_js_schema)
               else:
>>>>>>             metadata['pydantic_js_functions'] = [update_js_schema]
           else:
>>>>>>         s['metadata'] = {'pydantic_js_functions': [update_js_schema]}
       
       
    1: def as_jsonable_value(v: Any) -> Any:
>>>>>>     if type(v) not in (int, str, float, bytes, bool, type(None)):
>>>>>>         return to_jsonable_python(v)
>>>>>>     return v
       
       
    1: def expand_grouped_metadata(annotations: Iterable[Any]) -> Iterable[Any]:
           """Expand the annotations.
       
           Args:
               annotations: An iterable of annotations.
       
           Returns:
               An iterable of expanded annotations.
       
           Example:
               ```py
               from annotated_types import Ge, Len
       
               from pydantic._internal._known_annotated_metadata import expand_grouped_metadata
       
               print(list(expand_grouped_metadata([Ge(4), Len(5)])))
               #> [Ge(ge=4), MinLen(min_length=5)]
               ```
           """
 3997:     import annotated_types as at
       
 3997:     from pydantic.fields import FieldInfo  # circular import
       
 5078:     for annotation in annotations:
 1081:         if isinstance(annotation, at.GroupedMetadata):
>>>>>>             yield from annotation
 1081:         elif isinstance(annotation, FieldInfo):
>>>>>>             yield from annotation.metadata
                   # this is a bit problematic in that it results in duplicate metadata
                   # all of our "consumers" can handle it, but it is not ideal
                   # we probably should split up FieldInfo into:
                   # - annotated types metadata
                   # - individual metadata known only to Pydantic
>>>>>>             annotation = copy(annotation)
>>>>>>             annotation.metadata = []
>>>>>>             yield annotation
               else:
 1081:             yield annotation
       
       
    1: def apply_known_metadata(annotation: Any, schema: CoreSchema) -> CoreSchema | None:  # noqa: C901
           """Apply `annotation` to `schema` if it is an annotation we know about (Gt, Le, etc.).
           Otherwise return `None`.
       
           This does not handle all known annotations. If / when it does, it can always
           return a CoreSchema and return the unmodified schema if the annotation should be ignored.
       
           Assumes that GroupedMetadata has already been expanded via `expand_grouped_metadata`.
       
           Args:
               annotation: The annotation.
               schema: The schema.
       
           Returns:
               An updated schema with annotation if it is an annotation we know about, `None` otherwise.
       
           Raises:
               PydanticCustomError: If `Predicate` fails.
           """
  318:     import annotated_types as at
       
  318:     from . import _validators
       
  318:     schema = schema.copy()
  318:     schema_update, other_metadata = collect_known_metadata([annotation])
  318:     schema_type = schema['type']
  400:     for constraint, value in schema_update.items():
   82:         if constraint not in CONSTRAINTS_TO_ALLOWED_SCHEMAS:
>>>>>>             raise ValueError(f'Unknown constraint {constraint}')
   82:         allowed_schemas = CONSTRAINTS_TO_ALLOWED_SCHEMAS[constraint]
       
   82:         if schema_type in allowed_schemas:
   82:             if constraint == 'union_mode' and schema_type == 'union':
>>>>>>                 schema['mode'] = value  # type: ignore  # schema is UnionSchema
                   else:
   82:                 schema[constraint] = value
   82:             continue
       
>>>>>>         if constraint == 'allow_inf_nan' and value is False:
>>>>>>             return cs.no_info_after_validator_function(
>>>>>>                 _validators.forbid_inf_nan_check,
>>>>>>                 schema,
                   )
>>>>>>         elif constraint == 'pattern':
                   # insert a str schema to make sure the regex engine matches
>>>>>>             return cs.chain_schema(
>>>>>>                 [
>>>>>>                     schema,
>>>>>>                     cs.str_schema(pattern=value),
                       ]
                   )
>>>>>>         elif constraint == 'gt':
>>>>>>             s = cs.no_info_after_validator_function(
>>>>>>                 partial(_validators.greater_than_validator, gt=value),
>>>>>>                 schema,
                   )
>>>>>>             add_js_update_schema(s, lambda: {'gt': as_jsonable_value(value)})
>>>>>>             return s
>>>>>>         elif constraint == 'ge':
>>>>>>             return cs.no_info_after_validator_function(
>>>>>>                 partial(_validators.greater_than_or_equal_validator, ge=value),
>>>>>>                 schema,
                   )
>>>>>>         elif constraint == 'lt':
>>>>>>             return cs.no_info_after_validator_function(
>>>>>>                 partial(_validators.less_than_validator, lt=value),
>>>>>>                 schema,
                   )
>>>>>>         elif constraint == 'le':
>>>>>>             return cs.no_info_after_validator_function(
>>>>>>                 partial(_validators.less_than_or_equal_validator, le=value),
>>>>>>                 schema,
                   )
>>>>>>         elif constraint == 'multiple_of':
>>>>>>             return cs.no_info_after_validator_function(
>>>>>>                 partial(_validators.multiple_of_validator, multiple_of=value),
>>>>>>                 schema,
                   )
>>>>>>         elif constraint == 'min_length':
>>>>>>             s = cs.no_info_after_validator_function(
>>>>>>                 partial(_validators.min_length_validator, min_length=value),
>>>>>>                 schema,
                   )
>>>>>>             add_js_update_schema(s, lambda: {'minLength': (as_jsonable_value(value))})
>>>>>>             return s
>>>>>>         elif constraint == 'max_length':
>>>>>>             s = cs.no_info_after_validator_function(
>>>>>>                 partial(_validators.max_length_validator, max_length=value),
>>>>>>                 schema,
                   )
>>>>>>             add_js_update_schema(s, lambda: {'maxLength': (as_jsonable_value(value))})
>>>>>>             return s
>>>>>>         elif constraint == 'strip_whitespace':
>>>>>>             return cs.chain_schema(
>>>>>>                 [
>>>>>>                     schema,
>>>>>>                     cs.str_schema(strip_whitespace=True),
                       ]
                   )
>>>>>>         elif constraint == 'to_lower':
>>>>>>             return cs.chain_schema(
>>>>>>                 [
>>>>>>                     schema,
>>>>>>                     cs.str_schema(to_lower=True),
                       ]
                   )
>>>>>>         elif constraint == 'to_upper':
>>>>>>             return cs.chain_schema(
>>>>>>                 [
>>>>>>                     schema,
>>>>>>                     cs.str_schema(to_upper=True),
                       ]
                   )
>>>>>>         elif constraint == 'min_length':
>>>>>>             return cs.no_info_after_validator_function(
>>>>>>                 partial(_validators.min_length_validator, min_length=annotation.min_length),
>>>>>>                 schema,
                   )
>>>>>>         elif constraint == 'max_length':
>>>>>>             return cs.no_info_after_validator_function(
>>>>>>                 partial(_validators.max_length_validator, max_length=annotation.max_length),
>>>>>>                 schema,
                   )
               else:
>>>>>>             raise RuntimeError(f'Unable to apply constraint {constraint} to schema {schema_type}')
       
  318:     for annotation in other_metadata:
  236:         if isinstance(annotation, at.Gt):
>>>>>>             return cs.no_info_after_validator_function(
>>>>>>                 partial(_validators.greater_than_validator, gt=annotation.gt),
>>>>>>                 schema,
                   )
  236:         elif isinstance(annotation, at.Ge):
>>>>>>             return cs.no_info_after_validator_function(
>>>>>>                 partial(_validators.greater_than_or_equal_validator, ge=annotation.ge),
>>>>>>                 schema,
                   )
  236:         elif isinstance(annotation, at.Lt):
>>>>>>             return cs.no_info_after_validator_function(
>>>>>>                 partial(_validators.less_than_validator, lt=annotation.lt),
>>>>>>                 schema,
                   )
  236:         elif isinstance(annotation, at.Le):
>>>>>>             return cs.no_info_after_validator_function(
>>>>>>                 partial(_validators.less_than_or_equal_validator, le=annotation.le),
>>>>>>                 schema,
                   )
  236:         elif isinstance(annotation, at.MultipleOf):
>>>>>>             return cs.no_info_after_validator_function(
>>>>>>                 partial(_validators.multiple_of_validator, multiple_of=annotation.multiple_of),
>>>>>>                 schema,
                   )
  236:         elif isinstance(annotation, at.MinLen):
>>>>>>             return cs.no_info_after_validator_function(
>>>>>>                 partial(_validators.min_length_validator, min_length=annotation.min_length),
>>>>>>                 schema,
                   )
  236:         elif isinstance(annotation, at.MaxLen):
>>>>>>             return cs.no_info_after_validator_function(
>>>>>>                 partial(_validators.max_length_validator, max_length=annotation.max_length),
>>>>>>                 schema,
                   )
  236:         elif isinstance(annotation, at.Predicate):
>>>>>>             predicate_name = f'{annotation.func.__qualname__} ' if hasattr(annotation.func, '__qualname__') else ''
       
>>>>>>             def val_func(v: Any) -> Any:
                       # annotation.func may also raise an exception, let it pass through
>>>>>>                 if not annotation.func(v):
>>>>>>                     raise PydanticCustomError(
>>>>>>                         'predicate_failed',
>>>>>>                         f'Predicate {predicate_name}failed',  # type: ignore
                           )
>>>>>>                 return v
       
>>>>>>             return cs.no_info_after_validator_function(val_func, schema)
               # ignore any other unknown metadata
  236:         return None
       
   82:     return schema
       
       
    1: def collect_known_metadata(annotations: Iterable[Any]) -> tuple[dict[str, Any], list[Any]]:
           """Split `annotations` into known metadata and unknown annotations.
       
           Args:
               annotations: An iterable of annotations.
       
           Returns:
               A tuple contains a dict of known metadata and a list of unknown annotations.
       
           Example:
               ```py
               from annotated_types import Gt, Len
       
               from pydantic._internal._known_annotated_metadata import collect_known_metadata
       
               print(collect_known_metadata([Gt(1), Len(42), ...]))
               #> ({'gt': 1, 'min_length': 42}, [Ellipsis])
               ```
           """
 2879:     import annotated_types as at
       
 2879:     annotations = expand_grouped_metadata(annotations)
       
 2879:     res: dict[str, Any] = {}
 2879:     remaining: list[Any] = []
 3637:     for annotation in annotations:
               # isinstance(annotation, PydanticMetadata) also covers ._fields:_PydanticGeneralMetadata
  758:         if isinstance(annotation, PydanticMetadata):
>>>>>>             res.update(annotation.__dict__)
               # we don't use dataclasses.asdict because that recursively calls asdict on the field values
  758:         elif isinstance(annotation, at.MinLen):
    2:             res.update({'min_length': annotation.min_length})
  756:         elif isinstance(annotation, at.MaxLen):
>>>>>>             res.update({'max_length': annotation.max_length})
  756:         elif isinstance(annotation, at.Gt):
   18:             res.update({'gt': annotation.gt})
  738:         elif isinstance(annotation, at.Ge):
  144:             res.update({'ge': annotation.ge})
  594:         elif isinstance(annotation, at.Lt):
>>>>>>             res.update({'lt': annotation.lt})
  594:         elif isinstance(annotation, at.Le):
>>>>>>             res.update({'le': annotation.le})
  594:         elif isinstance(annotation, at.MultipleOf):
>>>>>>             res.update({'multiple_of': annotation.multiple_of})
  594:         elif isinstance(annotation, type) and issubclass(annotation, PydanticMetadata):
                   # also support PydanticMetadata classes being used without initialisation,
                   # e.g. `Annotated[int, Strict]` as well as `Annotated[int, Strict()]`
>>>>>>             res.update({k: v for k, v in vars(annotation).items() if not k.startswith('_')})
               else:
  594:             remaining.append(annotation)
           # Nones can sneak in but pydantic-core will reject them
           # it'd be nice to clean things up so we don't put in None (we probably don't _need_ to, it was just easier)
           # but this is simple enough to kick that can down the road
 5922:     res = {k: v for k, v in res.items() if v is not None}
 2879:     return res, remaining
       
       
    1: def check_metadata(metadata: dict[str, Any], allowed: Iterable[str], source_type: Any) -> None:
           """A small utility function to validate that the given metadata can be applied to the target.
           More than saving lines of code, this gives us a consistent error message for all of our internal implementations.
       
           Args:
               metadata: A dict of metadata.
               allowed: An iterable of allowed metadata.
               source_type: The source type.
       
           Raises:
               TypeError: If there is metadatas that can't be applied on source type.
           """
  440:     unknown = metadata.keys() - set(allowed)
  440:     if unknown:
>>>>>>         raise TypeError(
>>>>>>             f'The following constraints cannot be applied to {source_type!r}: {", ".join([f"{k!r}" for k in unknown])}'
               )
