    1: """Private logic for creating models."""
    1: from __future__ import annotations as _annotations
       
    1: import operator
    1: import typing
    1: import warnings
    1: import weakref
    1: from abc import ABCMeta
    1: from functools import partial
    1: from types import FunctionType
    1: from typing import Any, Callable, Generic
       
    1: import typing_extensions
    1: from pydantic_core import PydanticUndefined, SchemaSerializer
    1: from typing_extensions import dataclass_transform, deprecated
       
    1: from ..errors import PydanticUndefinedAnnotation, PydanticUserError
    1: from ..plugin._schema_validator import create_schema_validator
    1: from ..warnings import GenericBeforeBaseModelWarning, PydanticDeprecatedSince20
    1: from ._config import ConfigWrapper
    1: from ._decorators import DecoratorInfos, PydanticDescriptorProxy, get_attribute_from_bases
    1: from ._fields import collect_model_fields, is_valid_field_name, is_valid_privateattr_name
    1: from ._generate_schema import GenerateSchema
    1: from ._generics import PydanticGenericMetadata, get_model_typevars_map
    1: from ._mock_val_ser import MockValSer, set_model_mocks
    1: from ._schema_generation_shared import CallbackGetCoreSchemaHandler
    1: from ._signature import generate_pydantic_signature
    1: from ._typing_extra import get_cls_types_namespace, is_annotated, is_classvar, parent_frame_namespace
    1: from ._utils import ClassAttribute, SafeGetItemProxy
    1: from ._validate_call import ValidateCallWrapper
       
    1: if typing.TYPE_CHECKING:
>>>>>>     from ..fields import Field as PydanticModelField
>>>>>>     from ..fields import FieldInfo, ModelPrivateAttr
>>>>>>     from ..main import BaseModel
       else:
           # See PyCharm issues https://youtrack.jetbrains.com/issue/PY-21915
           # and https://youtrack.jetbrains.com/issue/PY-51428
    1:     DeprecationWarning = PydanticDeprecatedSince20
    1:     PydanticModelField = object()
       
    1: object_setattr = object.__setattr__
       
       
    2: class _ModelNamespaceDict(dict):
    1:     """A dictionary subclass that intercepts attribute setting on model classes and
           warns about overriding of decorators.
           """
       
    1:     def __setitem__(self, k: str, v: object) -> None:
  487:         existing: Any = self.get(k, None)
  487:         if existing and v is not existing and isinstance(existing, PydanticDescriptorProxy):
>>>>>>             warnings.warn(f'`{k}` overrides an existing Pydantic `{existing.decorator_info.decorator_repr}` decorator')
       
  487:         return super().__setitem__(k, v)
       
       
    2: @dataclass_transform(kw_only_default=True, field_specifiers=(PydanticModelField,))
    1: class ModelMetaclass(ABCMeta):
    1:     def __new__(
               mcs,
               cls_name: str,
               bases: tuple[type[Any], ...],
               namespace: dict[str, Any],
               __pydantic_generic_metadata__: PydanticGenericMetadata | None = None,
               __pydantic_reset_parent_namespace__: bool = True,
               _create_model_module: str | None = None,
               **kwargs: Any,
           ) -> type:
               """Metaclass for creating Pydantic models.
       
               Args:
                   cls_name: The name of the class to be created.
                   bases: The base classes of the class to be created.
                   namespace: The attribute dictionary of the class to be created.
                   __pydantic_generic_metadata__: Metadata for generic models.
                   __pydantic_reset_parent_namespace__: Reset parent namespace.
                   _create_model_module: The module of the class to be created, if created by `create_model`.
                   **kwargs: Catch-all for any other keyword arguments.
       
               Returns:
                   The new class created by the metaclass.
               """
               # Note `ModelMetaclass` refers to `BaseModel`, but is also used to *create* `BaseModel`, so we rely on the fact
               # that `BaseModel` itself won't have any bases, but any subclass of it will, to determine whether the `__new__`
               # call we're in the middle of is for the `BaseModel` class.
   40:         if bases:
   39:             base_field_names, class_vars, base_private_attributes = mcs._collect_bases_data(bases)
       
   39:             config_wrapper = ConfigWrapper.for_model(bases, namespace, kwargs)
   39:             namespace['model_config'] = config_wrapper.config_dict
   78:             private_attributes = inspect_namespace(
   39:                 namespace, config_wrapper.ignored_types, class_vars, base_field_names
                   )
   39:             if private_attributes:
>>>>>>                 original_model_post_init = get_model_post_init(namespace, bases)
>>>>>>                 if original_model_post_init is not None:
                           # if there are private_attributes and a model_post_init function, we handle both
       
>>>>>>                     def wrapped_model_post_init(self: BaseModel, __context: Any) -> None:
                               """We need to both initialize private attributes and call the user-defined model_post_init
                               method.
                               """
>>>>>>                         init_private_attributes(self, __context)
>>>>>>                         original_model_post_init(self, __context)
       
>>>>>>                     namespace['model_post_init'] = wrapped_model_post_init
                       else:
>>>>>>                     namespace['model_post_init'] = init_private_attributes
       
   39:             namespace['__class_vars__'] = class_vars
   39:             namespace['__private_attributes__'] = {**base_private_attributes, **private_attributes}
       
   39:             cls: type[BaseModel] = super().__new__(mcs, cls_name, bases, namespace, **kwargs)  # type: ignore
       
   39:             from ..main import BaseModel
       
   39:             mro = cls.__mro__
   39:             if Generic in mro and mro.index(Generic) < mro.index(BaseModel):
>>>>>>                 warnings.warn(
>>>>>>                     GenericBeforeBaseModelWarning(
>>>>>>                         'Classes should inherit from `BaseModel` before generic classes (e.g. `typing.Generic[T]`) '
                               'for pydantic generics to work properly.'
                           ),
>>>>>>                     stacklevel=2,
                       )
       
   39:             cls.__pydantic_custom_init__ = not getattr(cls.__init__, '__pydantic_base_init__', False)
   39:             cls.__pydantic_post_init__ = None if cls.model_post_init is BaseModel.model_post_init else 'model_post_init'
       
   39:             cls.__pydantic_decorators__ = DecoratorInfos.build(cls)
       
                   # Use the getattr below to grab the __parameters__ from the `typing.Generic` parent class
   39:             if __pydantic_generic_metadata__:
>>>>>>                 cls.__pydantic_generic_metadata__ = __pydantic_generic_metadata__
                   else:
   39:                 parent_parameters = getattr(cls, '__pydantic_generic_metadata__', {}).get('parameters', ())
   39:                 parameters = getattr(cls, '__parameters__', None) or parent_parameters
   39:                 if parameters and parent_parameters and not all(x in parameters for x in parent_parameters):
>>>>>>                     combined_parameters = parent_parameters + tuple(x for x in parameters if x not in parent_parameters)
>>>>>>                     parameters_str = ', '.join([str(x) for x in combined_parameters])
>>>>>>                     generic_type_label = f'typing.Generic[{parameters_str}]'
>>>>>>                     error_message = (
>>>>>>                         f'All parameters must be present on typing.Generic;'
>>>>>>                         f' you should inherit from {generic_type_label}.'
                           )
>>>>>>                     if Generic not in bases:  # pragma: no cover
                               # We raise an error here not because it is desirable, but because some cases are mishandled.
                               # It would be nice to remove this error and still have things behave as expected, it's just
                               # challenging because we are using a custom `__class_getitem__` to parametrize generic models,
                               # and not returning a typing._GenericAlias from it.
>>>>>>                         bases_str = ', '.join([x.__name__ for x in bases] + [generic_type_label])
>>>>>>                         error_message += (
>>>>>>                             f' Note: `typing.Generic` must go last: `class {cls.__name__}({bases_str}): ...`)'
                               )
>>>>>>                     raise TypeError(error_message)
       
   39:                 cls.__pydantic_generic_metadata__ = {
   39:                     'origin': None,
   39:                     'args': (),
   39:                     'parameters': parameters,
                       }
       
   39:             cls.__pydantic_complete__ = False  # Ensure this specific class gets completed
       
                   # preserve `__set_name__` protocol defined in https://peps.python.org/pep-0487
                   # for attributes not in `new_namespace` (e.g. private attributes)
   39:             for name, obj in private_attributes.items():
>>>>>>                 obj.__set_name__(cls, name)
       
   39:             if __pydantic_reset_parent_namespace__:
   37:                 cls.__pydantic_parent_namespace__ = build_lenient_weakvaluedict(parent_frame_namespace())
   39:             parent_namespace = getattr(cls, '__pydantic_parent_namespace__', None)
   39:             if isinstance(parent_namespace, dict):
   37:                 parent_namespace = unpack_lenient_weakvaluedict(parent_namespace)
       
   39:             types_namespace = get_cls_types_namespace(cls, parent_namespace)
   39:             set_model_fields(cls, bases, config_wrapper, types_namespace)
       
   39:             if config_wrapper.frozen and '__hash__' not in namespace:
>>>>>>                 set_default_hash_func(cls, bases)
       
   78:             complete_model_class(
   39:                 cls,
   39:                 cls_name,
   39:                 config_wrapper,
   39:                 raise_errors=False,
   39:                 types_namespace=types_namespace,
   39:                 create_model_module=_create_model_module,
                   )
       
                   # If this is placed before the complete_model_class call above,
                   # the generic computed fields return type is set to PydanticUndefined
   78:             cls.model_computed_fields = {k: v.info for k, v in cls.__pydantic_decorators__.computed_fields.items()}
       
                   # using super(cls, cls) on the next line ensures we only call the parent class's __pydantic_init_subclass__
                   # I believe the `type: ignore` is only necessary because mypy doesn't realize that this code branch is
                   # only hit for _proper_ subclasses of BaseModel
   39:             super(cls, cls).__pydantic_init_subclass__(**kwargs)  # type: ignore[misc]
   39:             return cls
               else:
                   # this is the BaseModel class itself being created, no logic required
    1:             return super().__new__(mcs, cls_name, bases, namespace, **kwargs)
       
    1:     if not typing.TYPE_CHECKING:  # pragma: no branch
               # We put `__getattr__` in a non-TYPE_CHECKING block because otherwise, mypy allows arbitrary attribute access
       
    1:         def __getattr__(self, item: str) -> Any:
                   """This is necessary to keep attribute access working for class attribute access."""
 1439:             private_attributes = self.__dict__.get('__private_attributes__')
 1439:             if private_attributes and item in private_attributes:
>>>>>>                 return private_attributes[item]
 1439:             if item == '__pydantic_core_schema__':
                       # This means the class didn't get a schema generated for it, likely because there was an undefined reference
>>>>>>                 maybe_mock_validator = getattr(self, '__pydantic_validator__', None)
>>>>>>                 if isinstance(maybe_mock_validator, MockValSer):
>>>>>>                     rebuilt_validator = maybe_mock_validator.rebuild()
>>>>>>                     if rebuilt_validator is not None:
                               # In this case, a validator was built, and so `__pydantic_core_schema__` should now be set
>>>>>>                         return getattr(self, '__pydantic_core_schema__')
 1439:             raise AttributeError(item)
       
    1:     @classmethod
    1:     def __prepare__(cls, *args: Any, **kwargs: Any) -> dict[str, object]:
   40:         return _ModelNamespaceDict()
       
    1:     def __instancecheck__(self, instance: Any) -> bool:
               """Avoid calling ABC _abc_subclasscheck unless we're pretty sure.
       
               See #3829 and python/cpython#92810
               """
   10:         return hasattr(instance, '__pydantic_validator__') and super().__instancecheck__(instance)
       
    1:     @staticmethod
    1:     def _collect_bases_data(bases: tuple[type[Any], ...]) -> tuple[set[str], set[str], dict[str, ModelPrivateAttr]]:
   39:         from ..main import BaseModel
       
   39:         field_names: set[str] = set()
   39:         class_vars: set[str] = set()
   39:         private_attributes: dict[str, ModelPrivateAttr] = {}
   78:         for base in bases:
   39:             if issubclass(base, BaseModel) and base is not BaseModel:
                       # model_fields might not be defined yet in the case of generics, so we use getattr here:
   11:                 field_names.update(getattr(base, 'model_fields', {}).keys())
   11:                 class_vars.update(base.__class_vars__)
   11:                 private_attributes.update(base.__private_attributes__)
   39:         return field_names, class_vars, private_attributes
       
    1:     @property
    1:     @deprecated('The `__fields__` attribute is deprecated, use `model_fields` instead.', category=None)
    1:     def __fields__(self) -> dict[str, FieldInfo]:
>>>>>>         warnings.warn(
>>>>>>             'The `__fields__` attribute is deprecated, use `model_fields` instead.', PydanticDeprecatedSince20
               )
>>>>>>         return self.model_fields  # type: ignore
       
    1:     def __dir__(self) -> list[str]:
>>>>>>         attributes = list(super().__dir__())
>>>>>>         if '__fields__' in attributes:
>>>>>>             attributes.remove('__fields__')
>>>>>>         return attributes
       
       
    1: def init_private_attributes(self: BaseModel, __context: Any) -> None:
           """This function is meant to behave like a BaseModel method to initialise private attributes.
       
           It takes context as an argument since that's what pydantic-core passes when calling it.
       
           Args:
               self: The BaseModel instance.
               __context: The context.
           """
>>>>>>     if getattr(self, '__pydantic_private__', None) is None:
>>>>>>         pydantic_private = {}
>>>>>>         for name, private_attr in self.__private_attributes__.items():
>>>>>>             default = private_attr.get_default()
>>>>>>             if default is not PydanticUndefined:
>>>>>>                 pydantic_private[name] = default
>>>>>>         object_setattr(self, '__pydantic_private__', pydantic_private)
       
       
    1: def get_model_post_init(namespace: dict[str, Any], bases: tuple[type[Any], ...]) -> Callable[..., Any] | None:
           """Get the `model_post_init` method from the namespace or the class bases, or `None` if not defined."""
>>>>>>     if 'model_post_init' in namespace:
>>>>>>         return namespace['model_post_init']
       
>>>>>>     from ..main import BaseModel
       
>>>>>>     model_post_init = get_attribute_from_bases(bases, 'model_post_init')
>>>>>>     if model_post_init is not BaseModel.model_post_init:
>>>>>>         return model_post_init
       
       
    1: def inspect_namespace(  # noqa C901
           namespace: dict[str, Any],
           ignored_types: tuple[type[Any], ...],
           base_class_vars: set[str],
           base_class_fields: set[str],
       ) -> dict[str, ModelPrivateAttr]:
           """Iterate over the namespace and:
           * gather private attributes
           * check for items which look like fields but are not (e.g. have no annotation) and warn.
       
           Args:
               namespace: The attribute dictionary of the class to be created.
               ignored_types: A tuple of ignore types.
               base_class_vars: A set of base class class variables.
               base_class_fields: A set of base class fields.
       
           Returns:
               A dict contains private attributes info.
       
           Raises:
               TypeError: If there is a `__root__` field in model.
               NameError: If private attribute name is invalid.
               PydanticUserError:
                   - If a field does not have a type annotation.
                   - If a field on base class was overridden by a non-annotated attribute.
           """
   39:     from ..fields import FieldInfo, ModelPrivateAttr, PrivateAttr
       
   39:     all_ignored_types = ignored_types + default_ignored_types()
       
   39:     private_attributes: dict[str, ModelPrivateAttr] = {}
   39:     raw_annotations = namespace.get('__annotations__', {})
       
   39:     if '__root__' in raw_annotations or '__root__' in namespace:
>>>>>>         raise TypeError("To define root models, use `pydantic.RootModel` rather than a field called '__root__'")
       
   39:     ignored_names: set[str] = set()
  368:     for var_name, value in list(namespace.items()):
  329:         if var_name == 'model_config':
   39:             continue
  290:         elif (
  290:             isinstance(value, type)
>>>>>>             and value.__module__ == namespace['__module__']
>>>>>>             and value.__qualname__.startswith(namespace['__qualname__'])
               ):
                   # `value` is a nested type defined in this namespace; don't error
>>>>>>             continue
  290:         elif isinstance(value, all_ignored_types) or value.__class__.__module__ == 'functools':
>>>>>>             ignored_names.add(var_name)
>>>>>>             continue
  290:         elif isinstance(value, ModelPrivateAttr):
>>>>>>             if var_name.startswith('__'):
>>>>>>                 raise NameError(
>>>>>>                     'Private attributes must not use dunder names;'
>>>>>>                     f' use a single underscore prefix instead of {var_name!r}.'
                       )
>>>>>>             elif is_valid_field_name(var_name):
>>>>>>                 raise NameError(
>>>>>>                     'Private attributes must not use valid field names;'
>>>>>>                     f' use sunder names, e.g. {"_" + var_name!r} instead of {var_name!r}.'
                       )
>>>>>>             private_attributes[var_name] = value
>>>>>>             del namespace[var_name]
  290:         elif isinstance(value, FieldInfo) and not is_valid_field_name(var_name):
>>>>>>             suggested_name = var_name.lstrip('_') or 'my_field'  # don't suggest '' for all-underscore name
>>>>>>             raise NameError(
>>>>>>                 f'Fields must not use names with leading underscores;'
>>>>>>                 f' e.g., use {suggested_name!r} instead of {var_name!r}.'
                   )
       
  290:         elif var_name.startswith('__'):
  116:             continue
  174:         elif is_valid_privateattr_name(var_name):
>>>>>>             if var_name not in raw_annotations or not is_classvar(raw_annotations[var_name]):
>>>>>>                 private_attributes[var_name] = PrivateAttr(default=value)
>>>>>>                 del namespace[var_name]
  174:         elif var_name in base_class_vars:
>>>>>>             continue
  174:         elif var_name not in raw_annotations:
>>>>>>             if var_name in base_class_fields:
>>>>>>                 raise PydanticUserError(
>>>>>>                     f'Field {var_name!r} defined on a base class was overridden by a non-annotated attribute. '
                           f'All field definitions, including overrides, require a type annotation.',
>>>>>>                     code='model-field-overridden',
                       )
>>>>>>             elif isinstance(value, FieldInfo):
>>>>>>                 raise PydanticUserError(
>>>>>>                     f'Field {var_name!r} requires a type annotation', code='model-field-missing-annotation'
                       )
                   else:
>>>>>>                 raise PydanticUserError(
>>>>>>                     f'A non-annotated attribute was detected: `{var_name} = {value!r}`. All model fields require a '
>>>>>>                     f'type annotation; if `{var_name}` is not meant to be a field, you may be able to resolve this '
                           f"error by annotating it as a `ClassVar` or updating `model_config['ignored_types']`.",
>>>>>>                     code='model-field-missing-annotation',
                       )
       
  239:     for ann_name, ann_type in raw_annotations.items():
  200:         if (
  200:             is_valid_privateattr_name(ann_name)
>>>>>>             and ann_name not in private_attributes
>>>>>>             and ann_name not in ignored_names
>>>>>>             and not is_classvar(ann_type)
>>>>>>             and ann_type not in all_ignored_types
>>>>>>             and getattr(ann_type, '__module__', None) != 'functools'
               ):
>>>>>>             if is_annotated(ann_type):
>>>>>>                 _, *metadata = typing_extensions.get_args(ann_type)
>>>>>>                 private_attr = next((v for v in metadata if isinstance(v, ModelPrivateAttr)), None)
>>>>>>                 if private_attr is not None:
>>>>>>                     private_attributes[ann_name] = private_attr
>>>>>>                     continue
>>>>>>             private_attributes[ann_name] = PrivateAttr()
       
   39:     return private_attributes
       
       
    1: def set_default_hash_func(cls: type[BaseModel], bases: tuple[type[Any], ...]) -> None:
>>>>>>     base_hash_func = get_attribute_from_bases(bases, '__hash__')
>>>>>>     new_hash_func = make_hash_func(cls)
>>>>>>     if base_hash_func in {None, object.__hash__} or getattr(base_hash_func, '__code__', None) == new_hash_func.__code__:
               # If `__hash__` is some default, we generate a hash function.
               # It will be `None` if not overridden from BaseModel.
               # It may be `object.__hash__` if there is another
               # parent class earlier in the bases which doesn't override `__hash__` (e.g. `typing.Generic`).
               # It may be a value set by `set_default_hash_func` if `cls` is a subclass of another frozen model.
               # In the last case we still need a new hash function to account for new `model_fields`.
>>>>>>         cls.__hash__ = new_hash_func
       
       
    1: def make_hash_func(cls: type[BaseModel]) -> Any:
>>>>>>     getter = operator.itemgetter(*cls.model_fields.keys()) if cls.model_fields else lambda _: 0
       
>>>>>>     def hash_func(self: Any) -> int:
>>>>>>         try:
>>>>>>             return hash(getter(self.__dict__))
>>>>>>         except KeyError:
                   # In rare cases (such as when using the deprecated copy method), the __dict__ may not contain
                   # all model fields, which is how we can get here.
                   # getter(self.__dict__) is much faster than any 'safe' method that accounts for missing keys,
                   # and wrapping it in a `try` doesn't slow things down much in the common case.
>>>>>>             return hash(getter(SafeGetItemProxy(self.__dict__)))
       
>>>>>>     return hash_func
       
       
    1: def set_model_fields(
           cls: type[BaseModel], bases: tuple[type[Any], ...], config_wrapper: ConfigWrapper, types_namespace: dict[str, Any]
       ) -> None:
           """Collect and set `cls.model_fields` and `cls.__class_vars__`.
       
           Args:
               cls: BaseModel or dataclass.
               bases: Parents of the class, generally `cls.__bases__`.
               config_wrapper: The config wrapper instance.
               types_namespace: Optional extra namespace to look for types in.
           """
   39:     typevars_map = get_model_typevars_map(cls)
   39:     fields, class_vars = collect_model_fields(cls, bases, config_wrapper, types_namespace, typevars_map=typevars_map)
       
   39:     cls.model_fields = fields
   39:     cls.__class_vars__.update(class_vars)
       
   39:     for k in class_vars:
               # Class vars should not be private attributes
               #     We remove them _here_ and not earlier because we rely on inspecting the class to determine its classvars,
               #     but private attributes are determined by inspecting the namespace _prior_ to class creation.
               #     In the case that a classvar with a leading-'_' is defined via a ForwardRef (e.g., when using
               #     `__future__.annotations`), we want to remove the private attribute which was detected _before_ we knew it
               #     evaluated to a classvar
       
>>>>>>         value = cls.__private_attributes__.pop(k, None)
>>>>>>         if value is not None and value.default is not PydanticUndefined:
>>>>>>             setattr(cls, k, value.default)
       
       
    1: def complete_model_class(
           cls: type[BaseModel],
           cls_name: str,
           config_wrapper: ConfigWrapper,
           *,
    1:     raise_errors: bool = True,
           types_namespace: dict[str, Any] | None,
    1:     create_model_module: str | None = None,
       ) -> bool:
           """Finish building a model class.
       
           This logic must be called after class has been created since validation functions must be bound
           and `get_type_hints` requires a class object.
       
           Args:
               cls: BaseModel or dataclass.
               cls_name: The model or dataclass name.
               config_wrapper: The config wrapper instance.
               raise_errors: Whether to raise errors.
               types_namespace: Optional extra namespace to look for types in.
               create_model_module: The module of the class to be created, if created by `create_model`.
       
           Returns:
               `True` if the model is successfully completed, else `False`.
       
           Raises:
               PydanticUndefinedAnnotation: If `PydanticUndefinedAnnotation` occurs in`__get_pydantic_core_schema__`
                   and `raise_errors=True`.
           """
   42:     typevars_map = get_model_typevars_map(cls)
   84:     gen_schema = GenerateSchema(
   42:         config_wrapper,
   42:         types_namespace,
   42:         typevars_map,
           )
       
   84:     handler = CallbackGetCoreSchemaHandler(
   42:         partial(gen_schema.generate_schema, from_dunder_get_core_schema=False),
   42:         gen_schema,
   42:         ref_mode='unpack',
           )
       
   42:     if config_wrapper.defer_build:
>>>>>>         set_model_mocks(cls, cls_name)
>>>>>>         return False
       
   42:     try:
   42:         schema = cls.__get_pydantic_core_schema__(cls, handler)
    6:     except PydanticUndefinedAnnotation as e:
    6:         if raise_errors:
>>>>>>             raise
    6:         set_model_mocks(cls, cls_name, f'`{e.name}`')
    6:         return False
       
   36:     core_config = config_wrapper.core_config(cls)
       
   36:     try:
   36:         schema = gen_schema.clean_schema(schema)
>>>>>>     except gen_schema.CollectedInvalid:
>>>>>>         set_model_mocks(cls, cls_name)
>>>>>>         return False
       
           # debug(schema)
   36:     cls.__pydantic_core_schema__ = schema
       
   72:     cls.__pydantic_validator__ = create_schema_validator(
   36:         schema,
   36:         cls,
   36:         create_model_module or cls.__module__,
   36:         cls.__qualname__,
   36:         'create_model' if create_model_module else 'BaseModel',
   36:         core_config,
   36:         config_wrapper.plugin_settings,
           )
   36:     cls.__pydantic_serializer__ = SchemaSerializer(schema, core_config)
   36:     cls.__pydantic_complete__ = True
       
           # set __signature__ attr only for model class, but not for its instances
   72:     cls.__signature__ = ClassAttribute(
   36:         '__signature__',
   36:         generate_pydantic_signature(init=cls.__init__, fields=cls.model_fields, config_wrapper=config_wrapper),
           )
   36:     return True
       
       
    2: class _PydanticWeakRef:
    1:     """Wrapper for `weakref.ref` that enables `pickle` serialization.
       
           Cloudpickle fails to serialize `weakref.ref` objects due to an arcane error related
           to abstract base classes (`abc.ABC`). This class works around the issue by wrapping
           `weakref.ref` instead of subclassing it.
       
           See https://github.com/pydantic/pydantic/issues/6763 for context.
       
           Semantics:
               - If not pickled, behaves the same as a `weakref.ref`.
               - If pickled along with the referenced object, the same `weakref.ref` behavior
                 will be maintained between them after unpickling.
               - If pickled without the referenced object, after unpickling the underlying
                 reference will be cleared (`__call__` will always return `None`).
           """
       
    1:     def __init__(self, obj: Any):
 2082:         if obj is None:
                   # The object will be `None` upon deserialization if the serialized weakref
                   # had lost its underlying object.
   37:             self._wr = None
               else:
 2045:             self._wr = weakref.ref(obj)
       
    1:     def __call__(self) -> Any:
 1840:         if self._wr is None:
   40:             return None
               else:
 1800:             return self._wr()
       
    1:     def __reduce__(self) -> tuple[Callable, tuple[weakref.ReferenceType | None]]:
>>>>>>         return _PydanticWeakRef, (self(),)
       
       
    1: def build_lenient_weakvaluedict(d: dict[str, Any] | None) -> dict[str, Any] | None:
           """Takes an input dictionary, and produces a new value that (invertibly) replaces the values with weakrefs.
       
           We can't just use a WeakValueDictionary because many types (including int, str, etc.) can't be stored as values
           in a WeakValueDictionary.
       
           The `unpack_lenient_weakvaluedict` function can be used to reverse this operation.
           """
   40:     if d is None:
>>>>>>         return None
   40:     result = {}
 2122:     for k, v in d.items():
 2082:         try:
 2082:             proxy = _PydanticWeakRef(v)
  242:         except TypeError:
  242:             proxy = v
 2082:         result[k] = proxy
   40:     return result
       
       
    1: def unpack_lenient_weakvaluedict(d: dict[str, Any] | None) -> dict[str, Any] | None:
           """Inverts the transform performed by `build_lenient_weakvaluedict`."""
   40:     if d is None:
>>>>>>         return None
       
   40:     result = {}
 2122:     for k, v in d.items():
 2082:         if isinstance(v, _PydanticWeakRef):
 1840:             v = v()
 1840:             if v is not None:
 1800:                 result[k] = v
               else:
  242:             result[k] = v
   40:     return result
       
       
    1: def default_ignored_types() -> tuple[type[Any], ...]:
   39:     from ..fields import ComputedFieldInfo
       
   39:     return (
   39:         FunctionType,
   39:         property,
   39:         classmethod,
   39:         staticmethod,
   39:         PydanticDescriptorProxy,
   39:         ComputedFieldInfo,
   39:         ValidateCallWrapper,
           )
