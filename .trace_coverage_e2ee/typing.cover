       """
       The typing module: Support for gradual typing as defined by PEP 484.
       
       At large scale, the structure of the module is following:
       * Imports and exports, all public names should be explicitly added to __all__.
       * Internal helper functions: these should never be used in code outside this module.
       * _SpecialForm and its instances (special forms): Any, NoReturn, ClassVar, Union, Optional
       * Two classes whose instances can be type arguments in addition to types: ForwardRef and TypeVar
       * The core of internal generics API: _GenericAlias and _VariadicGenericAlias, the latter is
         currently only used by Tuple and Callable. All subscripted types like X[int], Union[int, str],
         etc., are instances of either of these classes.
       * The public counterpart of the generics API consists of two classes: Generic and Protocol.
       * Public helper functions: get_type_hints, overload, cast, no_type_check,
         no_type_check_decorator.
       * Generic aliases for collections.abc ABCs and few additional protocols.
       * Special types: NewType, NamedTuple, TypedDict.
       * Wrapper submodules for re and io related types.
       """
       
>>>>>> from abc import abstractmethod, ABCMeta
>>>>>> import collections
>>>>>> import collections.abc
>>>>>> import contextlib
>>>>>> import functools
>>>>>> import operator
>>>>>> import re as stdlib_re  # Avoid confusion with the re we export.
>>>>>> import sys
>>>>>> import types
>>>>>> from types import WrapperDescriptorType, MethodWrapperType, MethodDescriptorType, GenericAlias
       
       # Please keep __all__ alphabetized within each category.
>>>>>> __all__ = [
           # Super-special typing primitives.
           'Annotated',
           'Any',
           'Callable',
           'ClassVar',
           'Final',
           'ForwardRef',
           'Generic',
           'Literal',
           'Optional',
           'Protocol',
           'Tuple',
           'Type',
           'TypeVar',
           'Union',
       
           # ABCs (from collections.abc).
           'AbstractSet',  # collections.abc.Set.
           'ByteString',
           'Container',
           'ContextManager',
           'Hashable',
           'ItemsView',
           'Iterable',
           'Iterator',
           'KeysView',
           'Mapping',
           'MappingView',
           'MutableMapping',
           'MutableSequence',
           'MutableSet',
           'Sequence',
           'Sized',
           'ValuesView',
           'Awaitable',
           'AsyncIterator',
           'AsyncIterable',
           'Coroutine',
           'Collection',
           'AsyncGenerator',
           'AsyncContextManager',
       
           # Structural checks, a.k.a. protocols.
           'Reversible',
           'SupportsAbs',
           'SupportsBytes',
           'SupportsComplex',
           'SupportsFloat',
           'SupportsIndex',
           'SupportsInt',
           'SupportsRound',
       
           # Concrete collection types.
           'ChainMap',
           'Counter',
           'Deque',
           'Dict',
           'DefaultDict',
           'List',
           'OrderedDict',
           'Set',
           'FrozenSet',
           'NamedTuple',  # Not really a type.
           'TypedDict',  # Not really a type.
           'Generator',
        
           # Other concrete types.
           'BinaryIO',
           'IO',
           'Match',
           'Pattern',
           'TextIO',
       
           # One-off things.
           'AnyStr',
           'cast',
           'final',
           'get_args',
           'get_origin',
           'get_type_hints',
           'NewType',
           'no_type_check',
           'no_type_check_decorator',
           'NoReturn',
           'overload',
           'runtime_checkable',
           'Text',
           'TYPE_CHECKING',
       ]
       
       # The pseudo-submodules 're' and 'io' are part of the public
       # namespace, but excluded from __all__ because they might stomp on
       # legitimate imports of those modules.
       
       
>>>>>> def _type_convert(arg):
           """For converting None to type(None), and strings to ForwardRef."""
 4267:     if arg is None:
   76:         return type(None)
 4191:     if isinstance(arg, str):
 1007:         return ForwardRef(arg)
 3184:     return arg
       
       
>>>>>> def _type_check(arg, msg, is_argument=True):
           """Check that the argument is a type, and return it (internal helper).
       
           As a special case, accept None and return type(None) instead. Also wrap strings
           into ForwardRef instances. Consider several corner cases, for example plain
           special forms like Union are not valid, while Union[int, str] is OK, etc.
           The msg argument is a human-readable error message, e.g::
       
               "Union[arg, ...]: arg should be a type."
       
           We append the repr() of the actual value (truncated to 100 chars).
           """
 4152:     invalid_generic_forms = (Generic, Protocol)
 4152:     if is_argument:
 4152:         invalid_generic_forms = invalid_generic_forms + (ClassVar, Final)
       
 4152:     arg = _type_convert(arg)
 5315:     if (isinstance(arg, _GenericAlias) and
 1163:             arg.__origin__ in invalid_generic_forms):
>>>>>>         raise TypeError(f"{arg} is not valid as type argument")
 4152:     if arg in (Any, NoReturn):
  198:         return arg
 3954:     if isinstance(arg, _SpecialForm) or arg in (Generic, Protocol):
>>>>>>         raise TypeError(f"Plain {arg} is not valid as type argument")
 3954:     if isinstance(arg, (type, TypeVar, ForwardRef)):
 2785:         return arg
 1169:     if not callable(arg):
>>>>>>         raise TypeError(f"{msg} Got {arg!r:.100}.")
 1169:     return arg
       
       
>>>>>> def _type_repr(obj):
           """Return the repr() of an object, special-casing types (internal helper).
       
           If obj is a type, we return a shorter version than the default
           type.__repr__, based on the module and qualified name, which is
           typically enough to uniquely identify a type.  For everything
           else, we fall back on repr(obj).
           """
  898:     if isinstance(obj, types.GenericAlias):
>>>>>>         return repr(obj)
  898:     if isinstance(obj, type):
  553:         if obj.__module__ == 'builtins':
  296:             return obj.__qualname__
  257:         return f'{obj.__module__}.{obj.__qualname__}'
  345:     if obj is ...:
>>>>>>         return('...')
  345:     if isinstance(obj, types.FunctionType):
>>>>>>         return obj.__name__
  345:     return repr(obj)
       
       
>>>>>> def _collect_type_vars(types):
           """Collect all type variable contained in types in order of
           first appearance (lexicographic order). For example::
       
               _collect_type_vars((T, List[S, T])) == (T, S)
           """
   25:     tvars = []
   66:     for t in types:
   41:         if isinstance(t, TypeVar) and t not in tvars:
    2:             tvars.append(t)
   41:         if isinstance(t, (_GenericAlias, GenericAlias)):
   32:             tvars.extend([t for t in t.__parameters__ if t not in tvars])
   25:     return tuple(tvars)
       
       
>>>>>> def _check_generic(cls, parameters, elen):
           """Check correct count for parameters of a generic cls (internal helper).
           This gives a nice error message in case of count mismatch.
           """
    8:     if not elen:
>>>>>>         raise TypeError(f"{cls} is not a generic class")
    8:     alen = len(parameters)
    8:     if alen != elen:
>>>>>>         raise TypeError(f"Too {'many' if alen > elen else 'few'} parameters for {cls};"
>>>>>>                         f" actual {alen}, expected {elen}")
       
       
>>>>>> def _deduplicate(params):
           # Weed out strict duplicates, preserving the first of each occurrence.
  556:     all_params = set(params)
  556:     if len(all_params) < len(params):
>>>>>>         new_params = []
>>>>>>         for t in params:
>>>>>>             if t in all_params:
>>>>>>                 new_params.append(t)
>>>>>>                 all_params.remove(t)
>>>>>>         params = new_params
>>>>>>         assert not all_params, all_params
  556:     return params
       
       
>>>>>> def _remove_dups_flatten(parameters):
           """An internal helper for Union creation and substitution: flatten Unions
           among parameters, then remove duplicates.
           """
           # Flatten out Union[Union[...], ...].
  544:     params = []
 1894:     for p in parameters:
 1350:         if isinstance(p, _UnionGenericAlias):
   66:             params.extend(p.__args__)
 1284:         elif isinstance(p, tuple) and len(p) > 0 and p[0] is Union:
>>>>>>             params.extend(p[1:])
               else:
 1284:             params.append(p)
       
  544:     return tuple(_deduplicate(params))
       
       
>>>>>> def _flatten_literal_params(parameters):
           """An internal helper for Literal creation: flatten Literals among parameters"""
   12:     params = []
  202:     for p in parameters:
  190:         if isinstance(p, _LiteralGenericAlias):
>>>>>>             params.extend(p.__args__)
               else:
  190:             params.append(p)
   12:     return tuple(params)
       
       
>>>>>> _cleanups = []
       
       
>>>>>> def _tp_cache(func=None, /, *, typed=False):
           """Internal wrapper caching __getitem__ of generic types with a fallback to
           original function for non-hashable arguments.
           """
    3:     def decorator(func):
    3:         cached = functools.lru_cache(typed=typed)(func)
    3:         _cleanups.append(cached.cache_clear)
       
    3:         @functools.wraps(func)
    3:         def inner(*args, **kwds):
12629:             try:
12629:                 return cached(*args, **kwds)
    3:             except TypeError:
    3:                 pass  # All real errors (not unhashable args) are raised below.
    3:             return func(*args, **kwds)
    3:         return inner
       
    3:     if func is not None:
    3:         return decorator(func)
       
>>>>>>     return decorator
       
>>>>>> def _eval_type(t, globalns, localns, recursive_guard=frozenset()):
           """Evaluate all forward references in the given type t.
           For use of globalns and localns see the docstring for get_type_hints().
           recursive_guard is used to prevent prevent infinite recursion
           with recursive ForwardRef.
           """
 1095:     if isinstance(t, ForwardRef):
   55:         return t._evaluate(globalns, localns, recursive_guard)
 1040:     if isinstance(t, (_GenericAlias, GenericAlias)):
 1495:         ev_args = tuple(_eval_type(a, globalns, localns, recursive_guard) for a in t.__args__)
  349:         if ev_args == t.__args__:
  314:             return t
   35:         if isinstance(t, GenericAlias):
>>>>>>             return GenericAlias(t.__origin__, ev_args)
               else:
   35:             return t.copy_with(ev_args)
  639:     return t
       
       
>>>>>> class _Final:
           """Mixin to prohibit subclassing"""
       
>>>>>>     __slots__ = ('__weakref__',)
       
>>>>>>     def __init_subclass__(self, /, *args, **kwds):
    9:         if '_root' not in kwds:
>>>>>>             raise TypeError("Cannot subclass special typing classes")
       
>>>>>> class _Immutable:
           """Mixin to indicate that object should not be copied."""
>>>>>>     __slots__ = ()
       
>>>>>>     def __copy__(self):
>>>>>>         return self
       
>>>>>>     def __deepcopy__(self, memo):
>>>>>>         return self
       
       
       # Internal indicator of special typing constructs.
       # See __doc__ instance attribute for specific docs.
>>>>>> class _SpecialForm(_Final, _root=True):
>>>>>>     __slots__ = ('_name', '__doc__', '_getitem')
       
>>>>>>     def __init__(self, getitem):
    9:         self._getitem = getitem
    9:         self._name = getitem.__name__
    9:         self.__doc__ = getitem.__doc__
       
>>>>>>     def __mro_entries__(self, bases):
>>>>>>         raise TypeError(f"Cannot subclass {self!r}")
       
>>>>>>     def __repr__(self):
 2530:         return 'typing.' + self._name
       
>>>>>>     def __reduce__(self):
>>>>>>         return self._name
       
>>>>>>     def __call__(self, *args, **kwds):
>>>>>>         raise TypeError(f"Cannot instantiate {self!r}")
       
>>>>>>     def __instancecheck__(self, obj):
>>>>>>         raise TypeError(f"{self} cannot be used with isinstance()")
       
>>>>>>     def __subclasscheck__(self, cls):
>>>>>>         raise TypeError(f"{self} cannot be used with issubclass()")
       
>>>>>>     @_tp_cache
>>>>>>     def __getitem__(self, parameters):
  783:         return self._getitem(self, parameters)
       
       
>>>>>> class _LiteralSpecialForm(_SpecialForm, _root=True):
>>>>>>     @_tp_cache(typed=True)
>>>>>>     def __getitem__(self, parameters):
   12:         return self._getitem(self, parameters)
       
       
>>>>>> @_SpecialForm
>>>>>> def Any(self, parameters):
           """Special type indicating an unconstrained type.
       
           - Any is compatible with every type.
           - Any assumed to have all methods.
           - All values assumed to be instances of Any.
       
           Note that all the above statements are true from the point of view of
           static type checkers. At runtime, Any should not be used with instance
           or class checks.
           """
>>>>>>     raise TypeError(f"{self} is not subscriptable")
       
>>>>>> @_SpecialForm
>>>>>> def NoReturn(self, parameters):
           """Special type indicating functions that never return.
           Example::
       
             from typing import NoReturn
       
             def stop() -> NoReturn:
                 raise Exception('no way')
       
           This type is invalid in other positions, e.g., ``List[NoReturn]``
           will fail in static type checkers.
           """
>>>>>>     raise TypeError(f"{self} is not subscriptable")
       
>>>>>> @_SpecialForm
>>>>>> def ClassVar(self, parameters):
           """Special type construct to mark class variables.
       
           An annotation wrapped in ClassVar indicates that a given
           attribute is intended to be used as a class variable and
           should not be set on instances of that class. Usage::
       
             class Starship:
                 stats: ClassVar[Dict[str, int]] = {} # class variable
                 damage: int = 10                     # instance variable
       
           ClassVar accepts only types and cannot be further subscribed.
       
           Note that ClassVar is not a class itself, and should not
           be used with isinstance() or issubclass().
           """
    6:     item = _type_check(parameters, f'{self} accepts only single type.')
    6:     return _GenericAlias(self, (item,))
       
>>>>>> @_SpecialForm
>>>>>> def Final(self, parameters):
           """Special typing construct to indicate final names to type checkers.
       
           A final name cannot be re-assigned or overridden in a subclass.
           For example:
       
             MAX_SIZE: Final = 9000
             MAX_SIZE += 1  # Error reported by type checker
       
             class Connection:
                 TIMEOUT: Final[int] = 10
       
             class FastConnector(Connection):
                 TIMEOUT = 1  # Error reported by type checker
       
           There is no runtime checking of these properties.
           """
>>>>>>     item = _type_check(parameters, f'{self} accepts only single type.')
>>>>>>     return _GenericAlias(self, (item,))
       
>>>>>> @_SpecialForm
>>>>>> def Union(self, parameters):
           """Union type; Union[X, Y] means either X or Y.
       
           To define a union, use e.g. Union[int, str].  Details:
           - The arguments must be types and there must be at least one.
           - None as an argument is a special case and is replaced by
             type(None).
           - Unions of unions are flattened, e.g.::
       
               Union[Union[int, str], float] == Union[int, str, float]
       
           - Unions of a single argument vanish, e.g.::
       
               Union[int] == int  # The constructor actually returns int
       
           - Redundant arguments are skipped, e.g.::
       
               Union[int, str, int] == Union[int, str]
       
           - When comparing unions, the argument order is ignored, e.g.::
       
               Union[int, str] == Union[str, int]
       
           - You cannot subclass or instantiate a union.
           - You can use Optional[X] as a shorthand for Union[X, None].
           """
  544:     if parameters == ():
>>>>>>         raise TypeError("Cannot take a Union of no types.")
  544:     if not isinstance(parameters, tuple):
>>>>>>         parameters = (parameters,)
  544:     msg = "Union[arg, ...]: each arg must be a type."
 2438:     parameters = tuple(_type_check(p, msg) for p in parameters)
  544:     parameters = _remove_dups_flatten(parameters)
  544:     if len(parameters) == 1:
>>>>>>         return parameters[0]
  544:     return _UnionGenericAlias(self, parameters)
       
>>>>>> @_SpecialForm
>>>>>> def Optional(self, parameters):
           """Optional type.
       
           Optional[X] is equivalent to Union[X, None].
           """
  233:     arg = _type_check(parameters, f"{self} requires a single type.")
  233:     return Union[arg, type(None)]
       
>>>>>> @_LiteralSpecialForm
>>>>>> def Literal(self, parameters):
           """Special typing form to define literal types (a.k.a. value types).
       
           This form can be used to indicate to type checkers that the corresponding
           variable or function parameter has a value equivalent to the provided
           literal (or one of several literals):
       
             def validate_simple(data: Any) -> Literal[True]:  # always returns True
                 ...
       
             MODE = Literal['r', 'rb', 'w', 'wb']
             def open_helper(file: str, mode: MODE) -> str:
                 ...
       
             open_helper('/some/path', 'r')  # Passes type check
             open_helper('/other/path', 'typo')  # Error in type checker
       
           Literal[...] cannot be subclassed. At runtime, an arbitrary value
           is allowed as type argument to Literal[...], but type checkers may
           impose restrictions.
           """
           # There is no '_type_check' call because arguments to Literal[...] are
           # values, not types.
   12:     if not isinstance(parameters, tuple):
    3:         parameters = (parameters,)
       
   12:     parameters = _flatten_literal_params(parameters)
       
   12:     try:
  214:         parameters = tuple(p for p, _ in _deduplicate(list(_value_and_type_iter(parameters))))
>>>>>>     except TypeError:  # unhashable parameters
>>>>>>         pass
       
   12:     return _LiteralGenericAlias(self, parameters)
       
       
>>>>>> class ForwardRef(_Final, _root=True):
           """Internal wrapper to hold a forward reference."""
       
>>>>>>     __slots__ = ('__forward_arg__', '__forward_code__',
                        '__forward_evaluated__', '__forward_value__',
                        '__forward_is_argument__')
       
>>>>>>     def __init__(self, arg, is_argument=True):
 1008:         if not isinstance(arg, str):
>>>>>>             raise TypeError(f"Forward reference must be a string -- got {arg!r}")
 1008:         try:
 1008:             code = compile(arg, '<string>', 'eval')
>>>>>>         except SyntaxError:
>>>>>>             raise SyntaxError(f"Forward reference must be an expression -- got {arg!r}")
 1008:         self.__forward_arg__ = arg
 1008:         self.__forward_code__ = code
 1008:         self.__forward_evaluated__ = False
 1008:         self.__forward_value__ = None
 1008:         self.__forward_is_argument__ = is_argument
       
>>>>>>     def _evaluate(self, globalns, localns, recursive_guard):
   55:         if self.__forward_arg__ in recursive_guard:
>>>>>>             return self
   55:         if not self.__forward_evaluated__ or localns is not globalns:
   55:             if globalns is None and localns is None:
>>>>>>                 globalns = localns = {}
   55:             elif globalns is None:
>>>>>>                 globalns = localns
   55:             elif localns is None:
   34:                 localns = globalns
   77:             type_ =_type_check(
   55:                 eval(self.__forward_code__, globalns, localns),
   22:                 "Forward references must evaluate to types.",
   22:                 is_argument=self.__forward_is_argument__,
                   )
   44:             self.__forward_value__ = _eval_type(
   22:                 type_, globalns, localns, recursive_guard | {self.__forward_arg__}
                   )
   22:             self.__forward_evaluated__ = True
   22:         return self.__forward_value__
       
>>>>>>     def __eq__(self, other):
 4126:         if not isinstance(other, ForwardRef):
 4126:             return NotImplemented
>>>>>>         if self.__forward_evaluated__ and other.__forward_evaluated__:
>>>>>>             return (self.__forward_arg__ == other.__forward_arg__ and
>>>>>>                     self.__forward_value__ == other.__forward_value__)
>>>>>>         return self.__forward_arg__ == other.__forward_arg__
       
>>>>>>     def __hash__(self):
  911:         return hash(self.__forward_arg__)
       
>>>>>>     def __repr__(self):
   20:         return f'ForwardRef({self.__forward_arg__!r})'
       
       
>>>>>> class TypeVar(_Final, _Immutable, _root=True):
           """Type variable.
       
           Usage::
       
             T = TypeVar('T')  # Can be anything
             A = TypeVar('A', str, bytes)  # Must be str or bytes
       
           Type variables exist primarily for the benefit of static type
           checkers.  They serve as the parameters for generic types as well
           as for generic function definitions.  See class Generic for more
           information on generic types.  Generic functions work as follows:
       
             def repeat(x: T, n: int) -> List[T]:
                 '''Return a list containing n references to x.'''
                 return [x]*n
       
             def longest(x: A, y: A) -> A:
                 '''Return the longest of two strings.'''
                 return x if len(x) >= len(y) else y
       
           The latter example's signature is essentially the overloading
           of (str, str) -> str and (bytes, bytes) -> bytes.  Also note
           that if the arguments are instances of some subclass of str,
           the return type is still plain str.
       
           At runtime, isinstance(x, T) and issubclass(C, T) will raise TypeError.
       
           Type variables defined with covariant=True or contravariant=True
           can be used to declare covariant or contravariant generic types.
           See PEP 484 for more details. By default generic types are invariant
           in all type variables.
       
           Type variables can be introspected. e.g.:
       
             T.__name__ == 'T'
             T.__constraints__ == ()
             T.__covariant__ == False
             T.__contravariant__ = False
             A.__constraints__ == (str, bytes)
       
           Note that only type variables defined in global scope can be pickled.
           """
       
>>>>>>     __slots__ = ('__name__', '__bound__', '__constraints__',
                        '__covariant__', '__contravariant__', '__dict__')
       
>>>>>>     def __init__(self, name, *constraints, bound=None,
>>>>>>                  covariant=False, contravariant=False):
  288:         self.__name__ = name
  288:         if covariant and contravariant:
>>>>>>             raise ValueError("Bivariant types are not supported.")
  288:         self.__covariant__ = bool(covariant)
  288:         self.__contravariant__ = bool(contravariant)
  288:         if constraints and bound is not None:
>>>>>>             raise TypeError("Constraints cannot be combined with bound=...")
  288:         if constraints and len(constraints) == 1:
>>>>>>             raise TypeError("A single constraint is not allowed")
  288:         msg = "TypeVar(name, constraint, ...): constraints must be types."
  600:         self.__constraints__ = tuple(_type_check(t, msg) for t in constraints)
  288:         if bound:
  190:             self.__bound__ = _type_check(bound, "Bound must be a type.")
               else:
   98:             self.__bound__ = None
  288:         try:
  288:             def_mod = sys._getframe(1).f_globals.get('__name__', '__main__')  # for pickling
>>>>>>         except (AttributeError, ValueError):
>>>>>>             def_mod = None
  288:         if def_mod != 'typing':
  288:             self.__module__ = def_mod
       
>>>>>>     def __repr__(self):
>>>>>>         if self.__covariant__:
>>>>>>             prefix = '+'
>>>>>>         elif self.__contravariant__:
>>>>>>             prefix = '-'
               else:
>>>>>>             prefix = '~'
>>>>>>         return prefix + self.__name__
       
>>>>>>     def __reduce__(self):
>>>>>>         return self.__name__
       
       
>>>>>> def _is_dunder(attr):
25859:     return attr.startswith('__') and attr.endswith('__')
       
>>>>>> class _BaseGenericAlias(_Final, _root=True):
           """The central part of internal API.
       
           This represents a generic version of type 'origin' with type arguments 'params'.
           There are two kind of these aliases: user defined and special. The special ones
           are wrappers around builtin collections and ABCs in collections.abc. These must
           have 'name' always set. If 'inst' is False, then the alias can't be instantiated,
           this is used by e.g. typing.List and typing.Dict.
           """
>>>>>>     def __init__(self, origin, *, inst=True, name=None):
 1843:         self._inst = inst
 1843:         self._name = name
 1843:         self.__origin__ = origin
 1843:         self.__slots__ = None  # This is not documented.
       
>>>>>>     def __call__(self, *args, **kwargs):
    5:         if not self._inst:
>>>>>>             raise TypeError(f"Type {self._name} cannot be instantiated; "
>>>>>>                             f"use {self.__origin__.__name__}() instead")
    5:         result = self.__origin__(*args, **kwargs)
    5:         try:
    5:             result.__orig_class__ = self
    5:         except AttributeError:
    5:             pass
    5:         return result
       
>>>>>>     def __mro_entries__(self, bases):
   39:         res = []
   39:         if self.__origin__ not in bases:
   39:             res.append(self.__origin__)
   39:         i = bases.index(self)
   39:         for b in bases[i+1:]:
    5:             if isinstance(b, _BaseGenericAlias) or issubclass(b, Generic):
    5:                 break
               else:
   34:             res.append(Generic)
   39:         return tuple(res)
       
>>>>>>     def __getattr__(self, attr):
               # We are careful for copy and pickle.
               # Also for simplicity we just don't relay all dunder names
13164:         if '__origin__' in self.__dict__ and not _is_dunder(attr):
 4217:             return getattr(self.__origin__, attr)
 8947:         raise AttributeError(attr)
       
>>>>>>     def __setattr__(self, attr, val):
12695:         if _is_dunder(attr) or attr in ('_name', '_inst', '_nparams'):
12695:             super().__setattr__(attr, val)
               else:
>>>>>>             setattr(self.__origin__, attr, val)
       
>>>>>>     def __instancecheck__(self, obj):
 3338:         return self.__subclasscheck__(type(obj))
       
>>>>>>     def __subclasscheck__(self, cls):
>>>>>>         raise TypeError("Subscripted generics cannot be used with"
                               " class and instance checks")
       
       
       # Special typing constructs Union, Optional, Generic, Callable and Tuple
       # use three special attributes for internal bookkeeping of generic types:
       # * __parameters__ is a tuple of unique free type parameters of a generic
       #   type, for example, Dict[T, T].__parameters__ == (T,);
       # * __origin__ keeps a reference to a type that was subscripted,
       #   e.g., Union[T, int].__origin__ == Union, or the non-generic version of
       #   the type.
       # * __args__ is a tuple of all arguments used in subscripting,
       #   e.g., Dict[T, int].__args__ == (T, int).
       
       
>>>>>> class _GenericAlias(_BaseGenericAlias, _root=True):
>>>>>>     def __init__(self, origin, params, *, inst=True, name=None):
 1839:         super().__init__(origin, inst=inst, name=name)
 1839:         if not isinstance(params, tuple):
  385:             params = (params,)
12621:         self.__args__ = tuple(... if a is _TypingEllipsis else
 3534:                               () if a is _TypingEmpty else
 8924:                               a for a in params)
 1839:         self.__parameters__ = _collect_type_vars(params)
 1839:         if not name:
 1275:             self.__module__ = origin.__module__
       
>>>>>>     def __eq__(self, other):
 7084:         if not isinstance(other, _GenericAlias):
 7021:             return NotImplemented
  126:         return (self.__origin__ == other.__origin__
   53:                 and self.__args__ == other.__args__)
       
>>>>>>     def __hash__(self):
 6321:         return hash((self.__origin__, self.__args__))
       
>>>>>>     @_tp_cache
>>>>>>     def __getitem__(self, params):
   21:         if self.__origin__ in (Generic, Protocol):
                   # Can't subscript Generic[...] or Protocol[...].
>>>>>>             raise TypeError(f"Cannot subscript already-subscripted {self}")
   21:         if not isinstance(params, tuple):
    9:             params = (params,)
   21:         msg = "Parameters to generic types must be types."
   63:         params = tuple(_type_check(p, msg) for p in params)
   21:         _check_generic(self, params, len(self.__parameters__))
       
   21:         subst = dict(zip(self.__parameters__, params))
   21:         new_args = []
   76:         for arg in self.__args__:
   55:             if isinstance(arg, TypeVar):
   14:                 arg = subst[arg]
   41:             elif isinstance(arg, (_GenericAlias, GenericAlias)):
   25:                 subparams = arg.__parameters__
   25:                 if subparams:
   42:                     subargs = tuple(subst[x] for x in subparams)
   14:                     arg = arg[subargs]
   55:             new_args.append(arg)
   21:         return self.copy_with(tuple(new_args))
       
>>>>>>     def copy_with(self, params):
   26:         return self.__class__(self.__origin__, params, name=self._name, inst=self._inst)
       
>>>>>>     def __repr__(self):
  382:         if self._name:
  247:             name = 'typing.' + self._name
               else:
  135:             name = _type_repr(self.__origin__)
 1417:         args = ", ".join([_type_repr(a) for a in self.__args__])
  382:         return f'{name}[{args}]'
       
>>>>>>     def __reduce__(self):
>>>>>>         if self._name:
>>>>>>             origin = globals()[self._name]
               else:
>>>>>>             origin = self.__origin__
>>>>>>         args = tuple(self.__args__)
>>>>>>         if len(args) == 1 and not isinstance(args[0], tuple):
>>>>>>             args, = args
>>>>>>         return operator.getitem, (origin, args)
       
>>>>>>     def __mro_entries__(self, bases):
  374:         if self._name:  # generic version of an ABC or built-in class
   39:             return super().__mro_entries__(bases)
  335:         if self.__origin__ is Generic:
   69:             if Protocol in bases:
    1:                 return ()
   68:             i = bases.index(self)
   83:             for b in bases[i+1:]:
   19:                 if isinstance(b, _BaseGenericAlias) and b is not self:
    4:                     return ()
  330:         return (self.__origin__,)
       
       
       # _nparams is the number of accepted parameters, e.g. 0 for Hashable,
       # 1 for List and 2 for Dict.  It may be -1 if variable number of
       # parameters are accepted (needs custom __getitem__).
       
>>>>>> class _SpecialGenericAlias(_BaseGenericAlias, _root=True):
>>>>>>     def __init__(self, origin, nparams, *, inst=True, name=None):
    4:         if name is None:
    2:             name = origin.__name__
    4:         super().__init__(origin, inst=inst, name=name)
    4:         self._nparams = nparams
    4:         if origin.__module__ == 'builtins':
>>>>>>             self.__doc__ = f'A generic version of {origin.__qualname__}.'
               else:
    4:             self.__doc__ = f'A generic version of {origin.__module__}.{origin.__qualname__}.'
       
>>>>>>     @_tp_cache
>>>>>>     def __getitem__(self, params):
  342:         if not isinstance(params, tuple):
  220:             params = (params,)
  342:         msg = "Parameters to generic types must be types."
 1159:         params = tuple(_type_check(p, msg) for p in params)
  342:         _check_generic(self, params, self._nparams)
  342:         return self.copy_with(params)
       
>>>>>>     def copy_with(self, params):
  892:         return _GenericAlias(self.__origin__, params,
  446:                              name=self._name, inst=self._inst)
       
>>>>>>     def __repr__(self):
>>>>>>         return 'typing.' + self._name
       
>>>>>>     def __subclasscheck__(self, cls):
 5014:         if isinstance(cls, _SpecialGenericAlias):
>>>>>>             return issubclass(cls.__origin__, self.__origin__)
 5014:         if not isinstance(cls, _GenericAlias):
 5014:             return issubclass(cls, self.__origin__)
>>>>>>         return super().__subclasscheck__(cls)
       
>>>>>>     def __reduce__(self):
>>>>>>         return self._name
       
       
>>>>>> class _CallableGenericAlias(_GenericAlias, _root=True):
>>>>>>     def __repr__(self):
    1:         assert self._name == 'Callable'
    1:         if len(self.__args__) == 2 and self.__args__[0] is Ellipsis:
>>>>>>             return super().__repr__()
    3:         return (f'typing.Callable'
    3:                 f'[[{", ".join([_type_repr(a) for a in self.__args__[:-1]])}], '
    1:                 f'{_type_repr(self.__args__[-1])}]')
       
>>>>>>     def __reduce__(self):
>>>>>>         args = self.__args__
>>>>>>         if not (len(args) == 2 and args[0] is ...):
>>>>>>             args = list(args[:-1]), args[-1]
>>>>>>         return operator.getitem, (Callable, args)
       
       
>>>>>> class _CallableType(_SpecialGenericAlias, _root=True):
>>>>>>     def copy_with(self, params):
  200:         return _CallableGenericAlias(self.__origin__, params,
  100:                                      name=self._name, inst=self._inst)
       
>>>>>>     def __getitem__(self, params):
  385:         if not isinstance(params, tuple) or len(params) != 2:
>>>>>>             raise TypeError("Callable must be used as "
                                   "Callable[[arg, ...], result].")
  385:         args, result = params
               # This relaxes what args can be on purpose to allow things like
               # PEP 612 ParamSpec.  Responsibility for whether a user is using
               # Callable[...] properly is deferred to static type checkers.
  385:         if isinstance(args, list):
  201:             params = (tuple(args), result)
               else:
  184:             params = (args, result)
  385:         return self.__getitem_inner__(params)
       
>>>>>>     @_tp_cache
>>>>>>     def __getitem_inner__(self, params):
  100:         args, result = params
  100:         msg = "Callable[args, result]: result must be a type."
  100:         result = _type_check(result, msg)
  100:         if args is Ellipsis:
    5:             return self.copy_with((_TypingEllipsis, result))
   95:         if not isinstance(args, tuple):
>>>>>>             args = (args,)
  305:         args = tuple(_type_convert(arg) for arg in args)
   95:         params = args + (result,)
   95:         return self.copy_with(params)
       
       
>>>>>> class _TupleType(_SpecialGenericAlias, _root=True):
>>>>>>     @_tp_cache
>>>>>>     def __getitem__(self, params):
  104:         if params == ():
    1:             return self.copy_with((_TypingEmpty,))
  103:         if not isinstance(params, tuple):
    3:             params = (params,)
  103:         if len(params) == 2 and params[1] is ...:
   13:             msg = "Tuple[t, ...]: t must be a type."
   13:             p = _type_check(params[0], msg)
   13:             return self.copy_with((p, _TypingEllipsis))
   90:         msg = "Tuple[t0, t1, ...]: each t must be a type."
  419:         params = tuple(_type_check(p, msg) for p in params)
   90:         return self.copy_with(params)
       
       
>>>>>> class _UnionGenericAlias(_GenericAlias, _root=True):
>>>>>>     def copy_with(self, params):
   30:         return Union[params]
       
>>>>>>     def __eq__(self, other):
18764:         if not isinstance(other, _UnionGenericAlias):
18741:             return NotImplemented
   23:         return set(self.__args__) == set(other.__args__)
       
>>>>>>     def __hash__(self):
 7183:         return hash(frozenset(self.__args__))
       
>>>>>>     def __repr__(self):
  152:         args = self.__args__
  152:         if len(args) == 2:
  149:             if args[0] is type(None):
>>>>>>                 return f'typing.Optional[{_type_repr(args[1])}]'
  149:             elif args[1] is type(None):
   18:                 return f'typing.Optional[{_type_repr(args[0])}]'
  134:         return super().__repr__()
       
       
>>>>>> def _value_and_type_iter(parameters):
  269:     return ((p, type(p)) for p in parameters)
       
       
>>>>>> class _LiteralGenericAlias(_GenericAlias, _root=True):
       
>>>>>>     def __eq__(self, other):
>>>>>>         if not isinstance(other, _LiteralGenericAlias):
>>>>>>             return NotImplemented
       
>>>>>>         return set(_value_and_type_iter(self.__args__)) == set(_value_and_type_iter(other.__args__))
       
>>>>>>     def __hash__(self):
    2:         return hash(frozenset(_value_and_type_iter(self.__args__)))
       
       
>>>>>> class Generic:
           """Abstract base class for generic types.
       
           A generic type is typically declared by inheriting from
           this class parameterized with one or more type variables.
           For example, a generic mapping type might be defined as::
       
             class Mapping(Generic[KT, VT]):
                 def __getitem__(self, key: KT) -> VT:
                     ...
                 # Etc.
       
           This class can then be used as follows::
       
             def lookup_name(mapping: Mapping[KT, VT], key: KT, default: VT) -> VT:
                 try:
                     return mapping[key]
                 except KeyError:
                     return default
           """
>>>>>>     __slots__ = ()
>>>>>>     _is_protocol = False
       
>>>>>>     @_tp_cache
>>>>>>     def __class_getitem__(cls, params):
  281:         if not isinstance(params, tuple):
  276:             params = (params,)
  281:         if not params and cls is not Tuple:
>>>>>>             raise TypeError(
>>>>>>                 f"Parameter list to {cls.__qualname__}[...] cannot be empty")
  281:         msg = "Parameters to generic types must be types."
  848:         params = tuple(_type_check(p, msg) for p in params)
  281:         if cls in (Generic, Protocol):
                   # Generic and Protocol can only be subscripted with unique type variables.
  195:             if not all(isinstance(p, TypeVar) for p in params):
>>>>>>                 raise TypeError(
>>>>>>                     f"Parameters to {cls.__name__}[...] must all be type variables")
   64:             if len(set(params)) != len(params):
>>>>>>                 raise TypeError(
>>>>>>                     f"Parameters to {cls.__name__}[...] must all be unique")
               else:
                   # Subscripting a regular Generic subclass.
  217:             _check_generic(cls, params, len(cls.__parameters__))
  281:         return _GenericAlias(cls, params)
       
>>>>>>     def __init_subclass__(cls, *args, **kwargs):
  709:         super().__init_subclass__(*args, **kwargs)
  709:         tvars = []
  709:         if '__orig_bases__' in cls.__dict__:
  317:             error = Generic in cls.__orig_bases__
               else:
  392:             error = Generic in cls.__bases__ and cls.__name__ != 'Protocol'
  709:         if error:
>>>>>>             raise TypeError("Cannot inherit from plain Generic")
  709:         if '__orig_bases__' in cls.__dict__:
  317:             tvars = _collect_type_vars(cls.__orig_bases__)
                   # Look for Generic[T1, ..., Tn].
                   # If found, tvars must be a subset of it.
                   # If not found, tvars is it.
                   # Also check for and reject plain Generic,
                   # and reject multiple Generic[...].
  317:             gvars = None
  823:             for base in cls.__orig_bases__:
  867:                 if (isinstance(base, _GenericAlias) and
  361:                         base.__origin__ is Generic):
   69:                     if gvars is not None:
>>>>>>                         raise TypeError(
>>>>>>                             "Cannot inherit from Generic[...] multiple types.")
   69:                     gvars = base.__parameters__
  317:             if gvars is not None:
   69:                 tvarset = set(tvars)
   69:                 gvarset = set(gvars)
   69:                 if not tvarset <= gvarset:
>>>>>>                     s_vars = ', '.join(str(t) for t in tvars if t not in gvarset)
>>>>>>                     s_args = ', '.join(str(g) for g in gvars)
>>>>>>                     raise TypeError(f"Some type variables ({s_vars}) are"
>>>>>>                                     f" not listed in Generic[{s_args}]")
   69:                 tvars = gvars
  709:         cls.__parameters__ = tuple(tvars)
       
       
>>>>>> class _TypingEmpty:
           """Internal placeholder for () or []. Used by TupleMeta and CallableMeta
           to allow empty list/tuple in specific places, without allowing them
           to sneak in where prohibited.
           """
       
       
>>>>>> class _TypingEllipsis:
           """Internal placeholder for ... (ellipsis)."""
       
       
>>>>>> _TYPING_INTERNALS = ['__parameters__', '__orig_bases__',  '__orig_class__',
                            '_is_protocol', '_is_runtime_protocol']
       
>>>>>> _SPECIAL_NAMES = ['__abstractmethods__', '__annotations__', '__dict__', '__doc__',
                         '__init__', '__module__', '__new__', '__slots__',
                         '__subclasshook__', '__weakref__', '__class_getitem__']
       
       # These special attributes will be not collected as protocol members.
>>>>>> EXCLUDED_ATTRIBUTES = _TYPING_INTERNALS + _SPECIAL_NAMES + ['_MutableMapping__marker']
       
       
>>>>>> def _get_protocol_attrs(cls):
           """Collect protocol members from a protocol class objects.
       
           This includes names actually defined in the class dictionary, as well
           as names that appear in annotations. Special names (above) are skipped.
           """
 2546:     attrs = set()
10184:     for base in cls.__mro__[:-1]:  # without object
 7638:         if base.__name__ in ('Protocol', 'Generic'):
 5092:             continue
 2546:         annotations = getattr(base, '__annotations__', {})
35644:         for attr in list(base.__dict__.keys()) + list(annotations.keys()):
33098:             if not attr.startswith('_abc_') and attr not in EXCLUDED_ATTRIBUTES:
 7638:                 attrs.add(attr)
 2546:     return attrs
       
       
>>>>>> def _is_callable_members_only(cls):
           # PEP 544 prohibits using issubclass() with protocols that have non-method members.
 3837:     return all(callable(getattr(cls, attr, None)) for attr in _get_protocol_attrs(cls))
       
       
>>>>>> def _no_init(self, *args, **kwargs):
    1:     if type(self)._is_protocol:
>>>>>>         raise TypeError('Protocols cannot be instantiated')
       
       
>>>>>> def _allow_reckless_class_cheks():
           """Allow instance and class checks for special stdlib modules.
       
           The abc and functools modules indiscriminately call isinstance() and
           issubclass() on the whole MRO of a user class, which may contain protocols.
           """
   12:     try:
   12:         return sys._getframe(3).f_globals['__name__'] in ['abc', 'functools']
>>>>>>     except (AttributeError, ValueError):  # For platforms without _getframe().
>>>>>>         return True
       
       
>>>>>> _PROTO_WHITELIST = {
>>>>>>     'collections.abc': [
               'Callable', 'Awaitable', 'Iterable', 'Iterator', 'AsyncIterable',
               'Hashable', 'Sized', 'Container', 'Collection', 'Reversible',
           ],
>>>>>>     'contextlib': ['AbstractContextManager', 'AbstractAsyncContextManager'],
       }
       
       
>>>>>> class _ProtocolMeta(ABCMeta):
           # This metaclass is really unfortunate and exists only because of
           # the lack of __instancehook__.
>>>>>>     def __instancecheck__(cls, instance):
               # We need this method for situations where attributes are
               # assigned in __init__.
 2534:         if ((not getattr(cls, '_is_protocol', False) or
 1267:                 _is_callable_members_only(cls)) and
>>>>>>                 issubclass(instance.__class__, cls)):
>>>>>>             return True
 1267:         if cls._is_protocol:
 7602:             if all(hasattr(instance, attr) and
                           # All *methods* can be blocked by setting them to None.
 1267:                     (not callable(getattr(cls, attr, None)) or
 1267:                      getattr(instance, attr) is not None)
 3801:                     for attr in _get_protocol_attrs(cls)):
>>>>>>                 return True
 1267:         return super().__instancecheck__(instance)
       
       
>>>>>> class Protocol(Generic, metaclass=_ProtocolMeta):
           """Base class for protocol classes.
       
           Protocol classes are defined as::
       
               class Proto(Protocol):
                   def meth(self) -> int:
                       ...
       
           Such classes are primarily used with static type checkers that recognize
           structural subtyping (static duck-typing), for example::
       
               class C:
                   def meth(self) -> int:
                       return 0
       
               def func(x: Proto) -> int:
                   return x.meth()
       
               func(C())  # Passes static type check
       
           See PEP 544 for details. Protocol classes decorated with
           @typing.runtime_checkable act as simple-minded runtime protocols that check
           only the presence of given attributes, ignoring their type signatures.
           Protocol classes can be generic, they are defined as::
       
               class GenProto(Protocol[T]):
                   def meth(self) -> T:
                       ...
           """
>>>>>>     __slots__ = ()
>>>>>>     _is_protocol = True
>>>>>>     _is_runtime_protocol = False
       
>>>>>>     def __init_subclass__(cls, *args, **kwargs):
   17:         super().__init_subclass__(*args, **kwargs)
       
               # Determine if this is a protocol or a concrete subclass.
   17:         if not cls.__dict__.get('_is_protocol', False):
   42:             cls._is_protocol = any(b is Protocol for b in cls.__bases__)
       
               # Set (or override) the protocol subclass hook.
   17:         def _proto_hook(other):
   48:             if not cls.__dict__.get('_is_protocol', False):
   36:                 return NotImplemented
       
                   # First, perform various sanity checks.
   12:             if not getattr(cls, '_is_runtime_protocol', False):
>>>>>>                 if _allow_reckless_class_cheks():
>>>>>>                     return NotImplemented
>>>>>>                 raise TypeError("Instance and class checks can only be used with"
                                       " @runtime_checkable protocols")
   12:             if not _is_callable_members_only(cls):
   12:                 if _allow_reckless_class_cheks():
   12:                     return NotImplemented
>>>>>>                 raise TypeError("Protocols with non-method members"
                                       " don't support issubclass()")
>>>>>>             if not isinstance(other, type):
                       # Same error message as for issubclass(1, int).
>>>>>>                 raise TypeError('issubclass() arg 1 must be a class')
       
                   # Second, perform the actual structural compatibility check.
>>>>>>             for attr in _get_protocol_attrs(cls):
>>>>>>                 for base in other.__mro__:
                           # Check if the members appears in the class dictionary...
>>>>>>                     if attr in base.__dict__:
>>>>>>                         if base.__dict__[attr] is None:
>>>>>>                             return NotImplemented
>>>>>>                         break
       
                           # ...or in annotations, if it is a sub-protocol.
>>>>>>                     annotations = getattr(base, '__annotations__', {})
>>>>>>                     if (isinstance(annotations, collections.abc.Mapping) and
>>>>>>                             attr in annotations and
>>>>>>                             issubclass(other, Generic) and other._is_protocol):
>>>>>>                         break
                       else:
>>>>>>                     return NotImplemented
>>>>>>             return True
       
   17:         if '__subclasshook__' not in cls.__dict__:
   17:             cls.__subclasshook__ = _proto_hook
       
               # We have nothing more to do for non-protocols...
   17:         if not cls._is_protocol:
    6:             return
       
               # ... otherwise check consistency of bases, and prohibit instantiation.
   24:         for base in cls.__bases__:
   50:             if not (base in (object, Generic) or
   13:                     base.__module__ in _PROTO_WHITELIST and
    2:                     base.__name__ in _PROTO_WHITELIST[base.__module__] or
   22:                     issubclass(base, Generic) and base._is_protocol):
>>>>>>                 raise TypeError('Protocols can only inherit from other'
>>>>>>                                 ' protocols, got %r' % base)
   11:         cls.__init__ = _no_init
       
       
>>>>>> class _AnnotatedAlias(_GenericAlias, _root=True):
           """Runtime representation of an annotated type.
       
           At its core 'Annotated[t, dec1, dec2, ...]' is an alias for the type 't'
           with extra annotations. The alias behaves like a normal typing alias,
           instantiating is the same as instantiating the underlying type, binding
           it to types is also the same.
           """
>>>>>>     def __init__(self, origin, metadata):
  385:         if isinstance(origin, _AnnotatedAlias):
>>>>>>             metadata = origin.__metadata__ + metadata
>>>>>>             origin = origin.__origin__
  385:         super().__init__(origin, origin)
  385:         self.__metadata__ = metadata
       
>>>>>>     def copy_with(self, params):
>>>>>>         assert len(params) == 1
>>>>>>         new_type = params[0]
>>>>>>         return _AnnotatedAlias(new_type, self.__metadata__)
       
>>>>>>     def __repr__(self):
  180:         return "typing.Annotated[{}, {}]".format(
   90:             _type_repr(self.__origin__),
  270:             ", ".join(repr(a) for a in self.__metadata__)
               )
       
>>>>>>     def __reduce__(self):
>>>>>>         return operator.getitem, (
>>>>>>             Annotated, (self.__origin__,) + self.__metadata__
               )
       
>>>>>>     def __eq__(self, other):
   36:         if not isinstance(other, _AnnotatedAlias):
   36:             return NotImplemented
>>>>>>         return (self.__origin__ == other.__origin__
>>>>>>                 and self.__metadata__ == other.__metadata__)
       
>>>>>>     def __hash__(self):
   24:         return hash((self.__origin__, self.__metadata__))
       
       
>>>>>> class Annotated:
           """Add context specific metadata to a type.
       
           Example: Annotated[int, runtime_check.Unsigned] indicates to the
           hypothetical runtime_check module that this type is an unsigned int.
           Every other consumer of this type can ignore this metadata and treat
           this type as int.
       
           The first argument to Annotated must be a valid type.
       
           Details:
       
           - It's an error to call `Annotated` with less than two arguments.
           - Nested Annotated are flattened::
       
               Annotated[Annotated[T, Ann1, Ann2], Ann3] == Annotated[T, Ann1, Ann2, Ann3]
       
           - Instantiating an annotated type is equivalent to instantiating the
           underlying type::
       
               Annotated[C, Ann1](5) == C(5)
       
           - Annotated can be used as a generic type alias::
       
               Optimized = Annotated[T, runtime.Optimize()]
               Optimized[int] == Annotated[int, runtime.Optimize()]
       
               OptimizedList = Annotated[List[T], runtime.Optimize()]
               OptimizedList[int] == Annotated[List[int], runtime.Optimize()]
           """
       
>>>>>>     __slots__ = ()
       
>>>>>>     def __new__(cls, *args, **kwargs):
>>>>>>         raise TypeError("Type Annotated cannot be instantiated.")
       
>>>>>>     @_tp_cache
>>>>>>     def __class_getitem__(cls, params):
  385:         if not isinstance(params, tuple) or len(params) < 2:
>>>>>>             raise TypeError("Annotated[...] should be used "
                                   "with at least two arguments (a type and an "
                                   "annotation).")
  385:         msg = "Annotated[t, ...]: t must be a type."
  385:         origin = _type_check(params[0], msg)
  385:         metadata = tuple(params[1:])
  385:         return _AnnotatedAlias(origin, metadata)
       
>>>>>>     def __init_subclass__(cls, *args, **kwargs):
>>>>>>         raise TypeError(
>>>>>>             "Cannot subclass {}.Annotated".format(cls.__module__)
               )
       
       
>>>>>> def runtime_checkable(cls):
           """Mark a protocol class as a runtime protocol.
       
           Such protocol can be used with isinstance() and issubclass().
           Raise TypeError if applied to a non-protocol class.
           This allows a simple-minded structural check very similar to
           one trick ponies in collections.abc such as Iterable.
           For example::
       
               @runtime_checkable
               class Closable(Protocol):
                   def close(self): ...
       
               assert isinstance(open('/some/file'), Closable)
       
           Warning: this will check only the presence of the required methods,
           not their type signatures!
           """
    1:     if not issubclass(cls, Generic) or not cls._is_protocol:
>>>>>>         raise TypeError('@runtime_checkable can be only applied to protocol classes,'
>>>>>>                         ' got %r' % cls)
    1:     cls._is_runtime_protocol = True
    1:     return cls
       
       
>>>>>> def cast(typ, val):
           """Cast a value to a type.
       
           This returns the value unchanged.  To the type checker this
           signals that the return value has the designated type, but at
           runtime we intentionally don't check anything (we want this
           to be as fast as possible).
           """
17232:     return val
       
       
>>>>>> def _get_defaults(func):
           """Internal helper to extract the default arguments, by name."""
>>>>>>     try:
>>>>>>         code = func.__code__
>>>>>>     except AttributeError:
               # Some built-in functions don't have __code__, __defaults__, etc.
>>>>>>         return {}
>>>>>>     pos_count = code.co_argcount
>>>>>>     arg_names = code.co_varnames
>>>>>>     arg_names = arg_names[:pos_count]
>>>>>>     defaults = func.__defaults__ or ()
>>>>>>     kwdefaults = func.__kwdefaults__
>>>>>>     res = dict(kwdefaults) if kwdefaults else {}
>>>>>>     pos_offset = pos_count - len(defaults)
>>>>>>     for name, value in zip(arg_names[pos_offset:], defaults):
>>>>>>         assert name not in res
>>>>>>         res[name] = value
>>>>>>     return res
       
       
>>>>>> _allowed_types = (types.FunctionType, types.BuiltinFunctionType,
>>>>>>                   types.MethodType, types.ModuleType,
>>>>>>                   WrapperDescriptorType, MethodWrapperType, MethodDescriptorType)
       
       
>>>>>> def get_type_hints(obj, globalns=None, localns=None, include_extras=False):
           """Return type hints for an object.
       
           This is often the same as obj.__annotations__, but it handles
           forward references encoded as string literals, adds Optional[t] if a
           default value equal to None is set and recursively replaces all
           'Annotated[T, ...]' with 'T' (unless 'include_extras=True').
       
           The argument may be a module, class, method, or function. The annotations
           are returned as a dictionary. For classes, annotations include also
           inherited members.
       
           TypeError is raised if the argument is not of a type that can contain
           annotations, and an empty dictionary is returned if no annotations are
           present.
       
           BEWARE -- the behavior of globalns and localns is counterintuitive
           (unless you are familiar with how eval() and exec() work).  The
           search order is locals first, then globals.
       
           - If no dict arguments are passed, an attempt is made to use the
             globals from obj (or the respective module's globals for classes),
             and these are also used as the locals.  If the object does not appear
             to have globals, an empty dictionary is used.
       
           - If one dict argument is passed, it is used for both globals and
             locals.
       
           - If two dict arguments are passed, they specify globals and
             locals, respectively.
           """
       
>>>>>>     if getattr(obj, '__no_type_check__', None):
>>>>>>         return {}
           # Classes require a special treatment.
>>>>>>     if isinstance(obj, type):
>>>>>>         hints = {}
>>>>>>         for base in reversed(obj.__mro__):
>>>>>>             if globalns is None:
>>>>>>                 base_globals = sys.modules[base.__module__].__dict__
                   else:
>>>>>>                 base_globals = globalns
>>>>>>             ann = base.__dict__.get('__annotations__', {})
>>>>>>             for name, value in ann.items():
>>>>>>                 if value is None:
>>>>>>                     value = type(None)
>>>>>>                 if isinstance(value, str):
>>>>>>                     value = ForwardRef(value, is_argument=False)
>>>>>>                 value = _eval_type(value, base_globals, localns)
>>>>>>                 hints[name] = value
>>>>>>         return hints if include_extras else {k: _strip_annotations(t) for k, t in hints.items()}
       
>>>>>>     if globalns is None:
>>>>>>         if isinstance(obj, types.ModuleType):
>>>>>>             globalns = obj.__dict__
               else:
>>>>>>             nsobj = obj
                   # Find globalns for the unwrapped object.
>>>>>>             while hasattr(nsobj, '__wrapped__'):
>>>>>>                 nsobj = nsobj.__wrapped__
>>>>>>             globalns = getattr(nsobj, '__globals__', {})
>>>>>>         if localns is None:
>>>>>>             localns = globalns
>>>>>>     elif localns is None:
>>>>>>         localns = globalns
>>>>>>     hints = getattr(obj, '__annotations__', None)
>>>>>>     if hints is None:
               # Return empty annotations for something that _could_ have them.
>>>>>>         if isinstance(obj, _allowed_types):
>>>>>>             return {}
               else:
>>>>>>             raise TypeError('{!r} is not a module, class, method, '
>>>>>>                             'or function.'.format(obj))
>>>>>>     defaults = _get_defaults(obj)
>>>>>>     hints = dict(hints)
>>>>>>     for name, value in hints.items():
>>>>>>         if value is None:
>>>>>>             value = type(None)
>>>>>>         if isinstance(value, str):
>>>>>>             value = ForwardRef(value)
>>>>>>         value = _eval_type(value, globalns, localns)
>>>>>>         if name in defaults and defaults[name] is None:
>>>>>>             value = Optional[value]
>>>>>>         hints[name] = value
>>>>>>     return hints if include_extras else {k: _strip_annotations(t) for k, t in hints.items()}
       
       
>>>>>> def _strip_annotations(t):
           """Strips the annotations from a given type.
           """
>>>>>>     if isinstance(t, _AnnotatedAlias):
>>>>>>         return _strip_annotations(t.__origin__)
>>>>>>     if isinstance(t, _GenericAlias):
>>>>>>         stripped_args = tuple(_strip_annotations(a) for a in t.__args__)
>>>>>>         if stripped_args == t.__args__:
>>>>>>             return t
>>>>>>         return t.copy_with(stripped_args)
>>>>>>     if isinstance(t, GenericAlias):
>>>>>>         stripped_args = tuple(_strip_annotations(a) for a in t.__args__)
>>>>>>         if stripped_args == t.__args__:
>>>>>>             return t
>>>>>>         return GenericAlias(t.__origin__, stripped_args)
>>>>>>     return t
       
       
>>>>>> def get_origin(tp):
           """Get the unsubscripted version of a type.
       
           This supports generic types, Callable, Tuple, Union, Literal, Final, ClassVar
           and Annotated. Return None for unsupported types. Examples::
       
               get_origin(Literal[42]) is Literal
               get_origin(int) is None
               get_origin(ClassVar[int]) is ClassVar
               get_origin(Generic) is Generic
               get_origin(Generic[T]) is Generic
               get_origin(Union[T, int]) is Union
               get_origin(List[Tuple[T, T]][int]) == list
           """
>>>>>>     if isinstance(tp, _AnnotatedAlias):
>>>>>>         return Annotated
>>>>>>     if isinstance(tp, (_BaseGenericAlias, GenericAlias)):
>>>>>>         return tp.__origin__
>>>>>>     if tp is Generic:
>>>>>>         return Generic
>>>>>>     return None
       
       
>>>>>> def get_args(tp):
           """Get type arguments with all substitutions performed.
       
           For unions, basic simplifications used by Union constructor are performed.
           Examples::
               get_args(Dict[str, int]) == (str, int)
               get_args(int) == ()
               get_args(Union[int, Union[T, int], str][int]) == (int, str)
               get_args(Union[int, Tuple[T, int]][str]) == (int, Tuple[str, int])
               get_args(Callable[[], T][int]) == ([], int)
           """
>>>>>>     if isinstance(tp, _AnnotatedAlias):
>>>>>>         return (tp.__origin__,) + tp.__metadata__
>>>>>>     if isinstance(tp, (_GenericAlias, GenericAlias)):
>>>>>>         res = tp.__args__
>>>>>>         if tp.__origin__ is collections.abc.Callable and res[0] is not Ellipsis:
>>>>>>             res = (list(res[:-1]), res[-1])
>>>>>>         return res
>>>>>>     return ()
       
       
>>>>>> def no_type_check(arg):
           """Decorator to indicate that annotations are not type hints.
       
           The argument must be a class or function; if it is a class, it
           applies recursively to all methods and classes defined in that class
           (but not to methods defined in its superclasses or subclasses).
       
           This mutates the function(s) or class(es) in place.
           """
    2:     if isinstance(arg, type):
>>>>>>         arg_attrs = arg.__dict__.copy()
>>>>>>         for attr, val in arg.__dict__.items():
>>>>>>             if val in arg.__bases__ + (arg,):
>>>>>>                 arg_attrs.pop(attr)
>>>>>>         for obj in arg_attrs.values():
>>>>>>             if isinstance(obj, types.FunctionType):
>>>>>>                 obj.__no_type_check__ = True
>>>>>>             if isinstance(obj, type):
>>>>>>                 no_type_check(obj)
    2:     try:
    2:         arg.__no_type_check__ = True
>>>>>>     except TypeError:  # built-in classes
>>>>>>         pass
    2:     return arg
       
       
>>>>>> def no_type_check_decorator(decorator):
           """Decorator to give another decorator the @no_type_check effect.
       
           This wraps the decorator with something that wraps the decorated
           function in @no_type_check.
           """
       
>>>>>>     @functools.wraps(decorator)
>>>>>>     def wrapped_decorator(*args, **kwds):
>>>>>>         func = decorator(*args, **kwds)
>>>>>>         func = no_type_check(func)
>>>>>>         return func
       
>>>>>>     return wrapped_decorator
       
       
>>>>>> def _overload_dummy(*args, **kwds):
           """Helper for @overload to raise when called."""
>>>>>>     raise NotImplementedError(
>>>>>>         "You should not call an overloaded function. "
               "A series of @overload-decorated functions "
               "outside a stub module should always be followed "
               "by an implementation that is not @overload-ed.")
       
       
>>>>>> def overload(func):
           """Decorator for overloaded functions/methods.
       
           In a stub file, place two or more stub definitions for the same
           function in a row, each decorated with @overload.  For example:
       
             @overload
             def utf8(value: None) -> None: ...
             @overload
             def utf8(value: bytes) -> bytes: ...
             @overload
             def utf8(value: str) -> bytes: ...
       
           In a non-stub file (i.e. a regular .py file), do the same but
           follow it with an implementation.  The implementation should *not*
           be decorated with @overload.  For example:
       
             @overload
             def utf8(value: None) -> None: ...
             @overload
             def utf8(value: bytes) -> bytes: ...
             @overload
             def utf8(value: str) -> bytes: ...
             def utf8(value):
                 # implementation goes here
           """
  368:     return _overload_dummy
       
       
>>>>>> def final(f):
           """A decorator to indicate final methods and final classes.
       
           Use this decorator to indicate to type checkers that the decorated
           method cannot be overridden, and decorated class cannot be subclassed.
           For example:
       
             class Base:
                 @final
                 def done(self) -> None:
                     ...
             class Sub(Base):
                 def done(self) -> None:  # Error reported by type checker
                       ...
       
             @final
             class Leaf:
                 ...
             class Other(Leaf):  # Error reported by type checker
                 ...
       
           There is no runtime checking of these properties.
           """
    3:     return f
       
       
       # Some unconstrained type variables.  These are used by the container types.
       # (These are not for export.)
>>>>>> T = TypeVar('T')  # Any type.
>>>>>> KT = TypeVar('KT')  # Key type.
>>>>>> VT = TypeVar('VT')  # Value type.
>>>>>> T_co = TypeVar('T_co', covariant=True)  # Any type covariant containers.
>>>>>> V_co = TypeVar('V_co', covariant=True)  # Any type covariant containers.
>>>>>> VT_co = TypeVar('VT_co', covariant=True)  # Value type covariant containers.
>>>>>> T_contra = TypeVar('T_contra', contravariant=True)  # Ditto contravariant.
       # Internal type variable used for Type[].
>>>>>> CT_co = TypeVar('CT_co', covariant=True, bound=type)
       
       # A useful type variable with constraints.  This represents string types.
       # (This one *is* for export!)
>>>>>> AnyStr = TypeVar('AnyStr', bytes, str)
       
       
       # Various ABCs mimicking those in collections.abc.
>>>>>> _alias = _SpecialGenericAlias
       
>>>>>> Hashable = _alias(collections.abc.Hashable, 0)  # Not generic.
>>>>>> Awaitable = _alias(collections.abc.Awaitable, 1)
>>>>>> Coroutine = _alias(collections.abc.Coroutine, 3)
>>>>>> AsyncIterable = _alias(collections.abc.AsyncIterable, 1)
>>>>>> AsyncIterator = _alias(collections.abc.AsyncIterator, 1)
>>>>>> Iterable = _alias(collections.abc.Iterable, 1)
>>>>>> Iterator = _alias(collections.abc.Iterator, 1)
>>>>>> Reversible = _alias(collections.abc.Reversible, 1)
>>>>>> Sized = _alias(collections.abc.Sized, 0)  # Not generic.
>>>>>> Container = _alias(collections.abc.Container, 1)
>>>>>> Collection = _alias(collections.abc.Collection, 1)
>>>>>> Callable = _CallableType(collections.abc.Callable, 2)
>>>>>> Callable.__doc__ = \
>>>>>>     """Callable type; Callable[[int], str] is a function of (int) -> str.
       
           The subscription syntax must always be used with exactly two
           values: the argument list and the return type.  The argument list
           must be a list of types or ellipsis; the return type must be a single type.
       
           There is no syntax to indicate optional or keyword arguments,
           such function types are rarely used as callback types.
           """
>>>>>> AbstractSet = _alias(collections.abc.Set, 1, name='AbstractSet')
>>>>>> MutableSet = _alias(collections.abc.MutableSet, 1)
       # NOTE: Mapping is only covariant in the value type.
>>>>>> Mapping = _alias(collections.abc.Mapping, 2)
>>>>>> MutableMapping = _alias(collections.abc.MutableMapping, 2)
>>>>>> Sequence = _alias(collections.abc.Sequence, 1)
>>>>>> MutableSequence = _alias(collections.abc.MutableSequence, 1)
>>>>>> ByteString = _alias(collections.abc.ByteString, 0)  # Not generic
       # Tuple accepts variable number of parameters.
>>>>>> Tuple = _TupleType(tuple, -1, inst=False, name='Tuple')
>>>>>> Tuple.__doc__ = \
>>>>>>     """Tuple type; Tuple[X, Y] is the cross-product type of X and Y.
       
           Example: Tuple[T1, T2] is a tuple of two elements corresponding
           to type variables T1 and T2.  Tuple[int, float, str] is a tuple
           of an int, a float and a string.
       
           To specify a variable-length tuple of homogeneous type, use Tuple[T, ...].
           """
>>>>>> List = _alias(list, 1, inst=False, name='List')
>>>>>> Deque = _alias(collections.deque, 1, name='Deque')
>>>>>> Set = _alias(set, 1, inst=False, name='Set')
>>>>>> FrozenSet = _alias(frozenset, 1, inst=False, name='FrozenSet')
>>>>>> MappingView = _alias(collections.abc.MappingView, 1)
>>>>>> KeysView = _alias(collections.abc.KeysView, 1)
>>>>>> ItemsView = _alias(collections.abc.ItemsView, 2)
>>>>>> ValuesView = _alias(collections.abc.ValuesView, 1)
>>>>>> ContextManager = _alias(contextlib.AbstractContextManager, 1, name='ContextManager')
>>>>>> AsyncContextManager = _alias(contextlib.AbstractAsyncContextManager, 1, name='AsyncContextManager')
>>>>>> Dict = _alias(dict, 2, inst=False, name='Dict')
>>>>>> DefaultDict = _alias(collections.defaultdict, 2, name='DefaultDict')
>>>>>> OrderedDict = _alias(collections.OrderedDict, 2)
>>>>>> Counter = _alias(collections.Counter, 1)
>>>>>> ChainMap = _alias(collections.ChainMap, 2)
>>>>>> Generator = _alias(collections.abc.Generator, 3)
>>>>>> AsyncGenerator = _alias(collections.abc.AsyncGenerator, 2)
>>>>>> Type = _alias(type, 1, inst=False, name='Type')
>>>>>> Type.__doc__ = \
>>>>>>     """A special construct usable to annotate class objects.
       
           For example, suppose we have the following classes::
       
             class User: ...  # Abstract base for User classes
             class BasicUser(User): ...
             class ProUser(User): ...
             class TeamUser(User): ...
       
           And a function that takes a class argument that's a subclass of
           User and returns an instance of the corresponding class::
       
             U = TypeVar('U', bound=User)
             def new_user(user_class: Type[U]) -> U:
                 user = user_class()
                 # (Here we could write the user object to a database)
                 return user
       
             joe = new_user(BasicUser)
       
           At this point the type checker knows that joe has type BasicUser.
           """
       
       
>>>>>> @runtime_checkable
>>>>>> class SupportsInt(Protocol):
           """An ABC with one abstract method __int__."""
>>>>>>     __slots__ = ()
       
>>>>>>     @abstractmethod
>>>>>>     def __int__(self) -> int:
>>>>>>         pass
       
       
>>>>>> @runtime_checkable
>>>>>> class SupportsFloat(Protocol):
           """An ABC with one abstract method __float__."""
>>>>>>     __slots__ = ()
       
>>>>>>     @abstractmethod
>>>>>>     def __float__(self) -> float:
>>>>>>         pass
       
       
>>>>>> @runtime_checkable
>>>>>> class SupportsComplex(Protocol):
           """An ABC with one abstract method __complex__."""
>>>>>>     __slots__ = ()
       
>>>>>>     @abstractmethod
>>>>>>     def __complex__(self) -> complex:
>>>>>>         pass
       
       
>>>>>> @runtime_checkable
>>>>>> class SupportsBytes(Protocol):
           """An ABC with one abstract method __bytes__."""
>>>>>>     __slots__ = ()
       
>>>>>>     @abstractmethod
>>>>>>     def __bytes__(self) -> bytes:
>>>>>>         pass
       
       
>>>>>> @runtime_checkable
>>>>>> class SupportsIndex(Protocol):
           """An ABC with one abstract method __index__."""
>>>>>>     __slots__ = ()
       
>>>>>>     @abstractmethod
>>>>>>     def __index__(self) -> int:
>>>>>>         pass
       
       
>>>>>> @runtime_checkable
>>>>>> class SupportsAbs(Protocol[T_co]):
           """An ABC with one abstract method __abs__ that is covariant in its return type."""
>>>>>>     __slots__ = ()
       
>>>>>>     @abstractmethod
>>>>>>     def __abs__(self) -> T_co:
>>>>>>         pass
       
       
>>>>>> @runtime_checkable
>>>>>> class SupportsRound(Protocol[T_co]):
           """An ABC with one abstract method __round__ that is covariant in its return type."""
>>>>>>     __slots__ = ()
       
>>>>>>     @abstractmethod
>>>>>>     def __round__(self, ndigits: int = 0) -> T_co:
>>>>>>         pass
       
       
>>>>>> def _make_nmtuple(name, types, module, defaults = ()):
  171:     fields = [n for n, t in types]
  317:     types = {n: _type_check(t, f"field {n} annotation must be a type")
  146:              for n, t in types}
   50:     nm_tpl = collections.namedtuple(name, fields,
   25:                                     defaults=defaults, module=module)
   25:     nm_tpl.__annotations__ = nm_tpl.__new__.__annotations__ = types
   25:     return nm_tpl
       
       
       # attributes prohibited to set in NamedTuple class syntax
>>>>>> _prohibited = frozenset({'__new__', '__init__', '__slots__', '__getnewargs__',
                                '_fields', '_field_defaults',
                                '_make', '_replace', '_asdict', '_source'})
       
>>>>>> _special = frozenset({'__module__', '__name__', '__annotations__'})
       
       
>>>>>> class NamedTupleMeta(type):
       
>>>>>>     def __new__(cls, typename, bases, ns):
   24:         assert bases[0] is _NamedTuple
   24:         types = ns.get('__annotations__', {})
   24:         default_names = []
  141:         for field_name in types:
  117:             if field_name in ns:
   14:                 default_names.append(field_name)
  103:             elif default_names:
>>>>>>                 raise TypeError(f"Non-default namedtuple field {field_name} "
                                       f"cannot follow default field"
>>>>>>                                 f"{'s' if len(default_names) > 1 else ''} "
>>>>>>                                 f"{', '.join(default_names)}")
   48:         nm_tpl = _make_nmtuple(typename, types.items(),
   62:                                defaults=[ns[n] for n in default_names],
   24:                                module=ns['__module__'])
               # update from user namespace without overriding special namedtuple attributes
  201:         for key in ns:
  177:             if key in _prohibited:
>>>>>>                 raise AttributeError("Cannot overwrite NamedTuple attribute " + key)
  177:             elif key not in _special and key not in nm_tpl._fields:
  115:                 setattr(nm_tpl, key, ns[key])
   24:         return nm_tpl
       
       
>>>>>> def NamedTuple(typename, fields=None, /, **kwargs):
           """Typed version of namedtuple.
       
           Usage in Python versions >= 3.6::
       
               class Employee(NamedTuple):
                   name: str
                   id: int
       
           This is equivalent to::
       
               Employee = collections.namedtuple('Employee', ['name', 'id'])
       
           The resulting class has an extra __annotations__ attribute, giving a
           dict that maps field names to types.  (The field names are also in
           the _fields attribute, which is part of the namedtuple API.)
           Alternative equivalent keyword syntax is also accepted::
       
               Employee = NamedTuple('Employee', name=str, id=int)
       
           In Python versions <= 3.5 use::
       
               Employee = NamedTuple('Employee', [('name', str), ('id', int)])
           """
    1:     if fields is None:
>>>>>>         fields = kwargs.items()
    1:     elif kwargs:
>>>>>>         raise TypeError("Either list of fields or keywords"
                               " can be provided to NamedTuple, not both")
    1:     try:
    1:         module = sys._getframe(1).f_globals.get('__name__', '__main__')
>>>>>>     except (AttributeError, ValueError):
>>>>>>         module = None
    1:     return _make_nmtuple(typename, fields, module=module)
       
>>>>>> _NamedTuple = type.__new__(NamedTupleMeta, 'NamedTuple', (), {})
       
>>>>>> def _namedtuple_mro_entries(bases):
   24:     if len(bases) > 1:
>>>>>>         raise TypeError("Multiple inheritance with NamedTuple is not supported")
   24:     assert bases[0] is NamedTuple
   24:     return (_NamedTuple,)
       
>>>>>> NamedTuple.__mro_entries__ = _namedtuple_mro_entries
       
       
>>>>>> class _TypedDictMeta(type):
>>>>>>     def __new__(cls, name, bases, ns, total=True):
               """Create new typed dict class object.
       
               This method is called when TypedDict is subclassed,
               or when TypedDict is instantiated. This way
               TypedDict supports all three syntax forms described in its docstring.
               Subclasses and instances of TypedDict return actual dictionaries.
               """
   10:         for base in bases:
    5:             if type(base) is not _TypedDictMeta:
>>>>>>                 raise TypeError('cannot inherit from both a TypedDict type '
                                       'and a non-TypedDict base class')
    5:         tp_dict = type.__new__(_TypedDictMeta, name, (dict,), ns)
       
    5:         annotations = {}
    5:         own_annotations = ns.get('__annotations__', {})
    5:         own_annotation_keys = set(own_annotations.keys())
    5:         msg = "TypedDict('Name', {f0: t0, f1: t1, ...}); each t must be a type"
   36:         own_annotations = {
   26:             n: _type_check(tp, msg) for n, tp in own_annotations.items()
               }
    5:         required_keys = set()
    5:         optional_keys = set()
       
   10:         for base in bases:
    5:             annotations.update(base.__dict__.get('__annotations__', {}))
    5:             required_keys.update(base.__dict__.get('__required_keys__', ()))
    5:             optional_keys.update(base.__dict__.get('__optional_keys__', ()))
       
    5:         annotations.update(own_annotations)
    5:         if total:
    5:             required_keys.update(own_annotation_keys)
               else:
>>>>>>             optional_keys.update(own_annotation_keys)
       
    5:         tp_dict.__annotations__ = annotations
    5:         tp_dict.__required_keys__ = frozenset(required_keys)
    5:         tp_dict.__optional_keys__ = frozenset(optional_keys)
    5:         if not hasattr(tp_dict, '__total__'):
    5:             tp_dict.__total__ = total
    5:         return tp_dict
       
>>>>>>     __call__ = dict  # static method
       
>>>>>>     def __subclasscheck__(cls, other):
               # Typed dicts are only for static structural subtyping.
>>>>>>         raise TypeError('TypedDict does not support instance and class checks')
       
>>>>>>     __instancecheck__ = __subclasscheck__
       
       
>>>>>> def TypedDict(typename, fields=None, /, *, total=True, **kwargs):
           """A simple typed namespace. At runtime it is equivalent to a plain dict.
       
           TypedDict creates a dictionary type that expects all of its
           instances to have a certain set of keys, where each key is
           associated with a value of a consistent type. This expectation
           is not checked at runtime but is only enforced by type checkers.
           Usage::
       
               class Point2D(TypedDict):
                   x: int
                   y: int
                   label: str
       
               a: Point2D = {'x': 1, 'y': 2, 'label': 'good'}  # OK
               b: Point2D = {'z': 3, 'label': 'bad'}           # Fails type check
       
               assert Point2D(x=1, y=2, label='first') == dict(x=1, y=2, label='first')
       
           The type info can be accessed via the Point2D.__annotations__ dict, and
           the Point2D.__required_keys__ and Point2D.__optional_keys__ frozensets.
           TypedDict supports two additional equivalent forms::
       
               Point2D = TypedDict('Point2D', x=int, y=int, label=str)
               Point2D = TypedDict('Point2D', {'x': int, 'y': int, 'label': str})
       
           By default, all keys must be present in a TypedDict. It is possible
           to override this by specifying totality.
           Usage::
       
               class point2D(TypedDict, total=False):
                   x: int
                   y: int
       
           This means that a point2D TypedDict can have any of the keys omitted.A type
           checker is only expected to support a literal False or True as the value of
           the total argument. True is the default, and makes all items defined in the
           class body be required.
       
           The class syntax is only supported in Python 3.6+, while two other
           syntax forms work for Python 2.7 and 3.2+
           """
>>>>>>     if fields is None:
>>>>>>         fields = kwargs
>>>>>>     elif kwargs:
>>>>>>         raise TypeError("TypedDict takes either a dict or keyword arguments,"
                               " but not both")
       
>>>>>>     ns = {'__annotations__': dict(fields)}
>>>>>>     try:
               # Setting correct module is necessary to make typed dict classes pickleable.
>>>>>>         ns['__module__'] = sys._getframe(1).f_globals.get('__name__', '__main__')
>>>>>>     except (AttributeError, ValueError):
>>>>>>         pass
       
>>>>>>     return _TypedDictMeta(typename, (), ns, total=total)
       
>>>>>> _TypedDict = type.__new__(_TypedDictMeta, 'TypedDict', (), {})
    5: TypedDict.__mro_entries__ = lambda bases: (_TypedDict,)
       
       
>>>>>> def NewType(name, tp):
           """NewType creates simple unique types with almost zero
           runtime overhead. NewType(name, tp) is considered a subtype of tp
           by static type checkers. At runtime, NewType(name, tp) returns
           a dummy function that simply returns its argument. Usage::
       
               UserId = NewType('UserId', int)
       
               def name_by_id(user_id: UserId) -> str:
                   ...
       
               UserId('user')          # Fails type check
       
               name_by_id(42)          # Fails type check
               name_by_id(UserId(42))  # OK
       
               num = UserId(5) + 1     # type: int
           """
       
    4:     def new_type(x):
>>>>>>         return x
       
    4:     new_type.__name__ = name
    4:     new_type.__supertype__ = tp
    4:     return new_type
       
       
       # Python-version-specific alias (Python 2: unicode; Python 3: str)
>>>>>> Text = str
       
       
       # Constant that's True when type checking, but False here.
>>>>>> TYPE_CHECKING = False
       
       
>>>>>> class IO(Generic[AnyStr]):
           """Generic base class for TextIO and BinaryIO.
       
           This is an abstract, generic version of the return of open().
       
           NOTE: This does not distinguish between the different possible
           classes (text vs. binary, read vs. write vs. read/write,
           append-only, unbuffered).  The TextIO and BinaryIO subclasses
           below capture the distinctions between text vs. binary, which is
           pervasive in the interface; however we currently do not offer a
           way to track the other distinctions in the type system.
           """
       
>>>>>>     __slots__ = ()
       
>>>>>>     @property
>>>>>>     @abstractmethod
>>>>>>     def mode(self) -> str:
>>>>>>         pass
       
>>>>>>     @property
>>>>>>     @abstractmethod
>>>>>>     def name(self) -> str:
>>>>>>         pass
       
>>>>>>     @abstractmethod
>>>>>>     def close(self) -> None:
>>>>>>         pass
       
>>>>>>     @property
>>>>>>     @abstractmethod
>>>>>>     def closed(self) -> bool:
>>>>>>         pass
       
>>>>>>     @abstractmethod
>>>>>>     def fileno(self) -> int:
>>>>>>         pass
       
>>>>>>     @abstractmethod
>>>>>>     def flush(self) -> None:
>>>>>>         pass
       
>>>>>>     @abstractmethod
>>>>>>     def isatty(self) -> bool:
>>>>>>         pass
       
>>>>>>     @abstractmethod
>>>>>>     def read(self, n: int = -1) -> AnyStr:
>>>>>>         pass
       
>>>>>>     @abstractmethod
>>>>>>     def readable(self) -> bool:
>>>>>>         pass
       
>>>>>>     @abstractmethod
>>>>>>     def readline(self, limit: int = -1) -> AnyStr:
>>>>>>         pass
       
>>>>>>     @abstractmethod
>>>>>>     def readlines(self, hint: int = -1) -> List[AnyStr]:
>>>>>>         pass
       
>>>>>>     @abstractmethod
>>>>>>     def seek(self, offset: int, whence: int = 0) -> int:
>>>>>>         pass
       
>>>>>>     @abstractmethod
>>>>>>     def seekable(self) -> bool:
>>>>>>         pass
       
>>>>>>     @abstractmethod
>>>>>>     def tell(self) -> int:
>>>>>>         pass
       
>>>>>>     @abstractmethod
>>>>>>     def truncate(self, size: int = None) -> int:
>>>>>>         pass
       
>>>>>>     @abstractmethod
>>>>>>     def writable(self) -> bool:
>>>>>>         pass
       
>>>>>>     @abstractmethod
>>>>>>     def write(self, s: AnyStr) -> int:
>>>>>>         pass
       
>>>>>>     @abstractmethod
>>>>>>     def writelines(self, lines: List[AnyStr]) -> None:
>>>>>>         pass
       
>>>>>>     @abstractmethod
>>>>>>     def __enter__(self) -> 'IO[AnyStr]':
>>>>>>         pass
       
>>>>>>     @abstractmethod
>>>>>>     def __exit__(self, type, value, traceback) -> None:
>>>>>>         pass
       
       
>>>>>> class BinaryIO(IO[bytes]):
           """Typed version of the return of open() in binary mode."""
       
>>>>>>     __slots__ = ()
       
>>>>>>     @abstractmethod
>>>>>>     def write(self, s: Union[bytes, bytearray]) -> int:
>>>>>>         pass
       
>>>>>>     @abstractmethod
>>>>>>     def __enter__(self) -> 'BinaryIO':
>>>>>>         pass
       
       
>>>>>> class TextIO(IO[str]):
           """Typed version of the return of open() in text mode."""
       
>>>>>>     __slots__ = ()
       
>>>>>>     @property
>>>>>>     @abstractmethod
>>>>>>     def buffer(self) -> BinaryIO:
>>>>>>         pass
       
>>>>>>     @property
>>>>>>     @abstractmethod
>>>>>>     def encoding(self) -> str:
>>>>>>         pass
       
>>>>>>     @property
>>>>>>     @abstractmethod
>>>>>>     def errors(self) -> Optional[str]:
>>>>>>         pass
       
>>>>>>     @property
>>>>>>     @abstractmethod
>>>>>>     def line_buffering(self) -> bool:
>>>>>>         pass
       
>>>>>>     @property
>>>>>>     @abstractmethod
>>>>>>     def newlines(self) -> Any:
>>>>>>         pass
       
>>>>>>     @abstractmethod
>>>>>>     def __enter__(self) -> 'TextIO':
>>>>>>         pass
       
       
>>>>>> class io:
           """Wrapper namespace for IO generic classes."""
       
>>>>>>     __all__ = ['IO', 'TextIO', 'BinaryIO']
>>>>>>     IO = IO
>>>>>>     TextIO = TextIO
>>>>>>     BinaryIO = BinaryIO
       
       
>>>>>> io.__name__ = __name__ + '.io'
>>>>>> sys.modules[io.__name__] = io
       
>>>>>> Pattern = _alias(stdlib_re.Pattern, 1)
>>>>>> Match = _alias(stdlib_re.Match, 1)
       
>>>>>> class re:
           """Wrapper namespace for re type aliases."""
       
>>>>>>     __all__ = ['Pattern', 'Match']
>>>>>>     Pattern = Pattern
>>>>>>     Match = Match
       
       
>>>>>> re.__name__ = __name__ + '.re'
>>>>>> sys.modules[re.__name__] = re
