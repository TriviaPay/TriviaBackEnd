       # orm/persistence.py
       # Copyright (C) 2005-2024 the SQLAlchemy authors and contributors
       # <see AUTHORS file>
       #
       # This module is part of SQLAlchemy and is released under
       # the MIT License: https://www.opensource.org/licenses/mit-license.php
       # mypy: ignore-errors
       
       
    1: """private module containing functions used to emit INSERT, UPDATE
       and DELETE statements on behalf of a :class:`_orm.Mapper` and its descending
       mappers.
       
       The functions here are called only by the unit of work functions
       in unitofwork.py.
       
       """
    1: from __future__ import annotations
       
    1: from itertools import chain
    1: from itertools import groupby
    1: from itertools import zip_longest
    1: import operator
       
    1: from . import attributes
    1: from . import exc as orm_exc
    1: from . import loading
    1: from . import sync
    1: from .base import state_str
    1: from .. import exc as sa_exc
    1: from .. import future
    1: from .. import sql
    1: from .. import util
    1: from ..engine import cursor as _cursor
    1: from ..sql import operators
    1: from ..sql.elements import BooleanClauseList
    1: from ..sql.selectable import LABEL_STYLE_TABLENAME_PLUS_COL
       
       
    1: def save_obj(base_mapper, states, uowtransaction, single=False):
           """Issue ``INSERT`` and/or ``UPDATE`` statements for a list
           of objects.
       
           This is called within the context of a UOWTransaction during a
           flush operation, given a list of states to be flushed.  The
           base mapper in an inheritance hierarchy handles the inserts/
           updates for all descendant mappers.
       
           """
       
           # if batch=false, call _save_obj separately for each object
   41:     if not single and not base_mapper.batch:
>>>>>>         for state in _sort_states(base_mapper, states):
>>>>>>             save_obj(base_mapper, [state], uowtransaction, single=True)
>>>>>>         return
       
   41:     states_to_update = []
   41:     states_to_insert = []
       
   95:     for (
   54:         state,
   54:         dict_,
   54:         mapper,
   54:         connection,
   54:         has_identity,
   54:         row_switch,
   54:         update_version_id,
   41:     ) in _organize_states_for_save(base_mapper, states, uowtransaction):
   54:         if has_identity or row_switch:
    8:             states_to_update.append(
    4:                 (state, dict_, mapper, connection, update_version_id)
                   )
               else:
   50:             states_to_insert.append((state, dict_, mapper, connection))
       
   81:     for table, mapper in base_mapper._sorted_tables.items():
   41:         if table not in mapper._pks_by_table:
>>>>>>             continue
   41:         insert = _collect_insert_commands(table, states_to_insert)
       
   82:         update = _collect_update_commands(
   41:             uowtransaction, table, states_to_update
               )
       
   82:         _emit_update_statements(
   41:             base_mapper,
   41:             uowtransaction,
   41:             mapper,
   41:             table,
   41:             update,
               )
       
   82:         _emit_insert_statements(
   41:             base_mapper,
   41:             uowtransaction,
   41:             mapper,
   41:             table,
   41:             insert,
               )
       
   80:     _finalize_insert_update_commands(
   40:         base_mapper,
   40:         uowtransaction,
   80:         chain(
  169:             (
   49:                 (state, state_dict, mapper, connection, False)
   89:                 for (state, state_dict, mapper, connection) in states_to_insert
                   ),
  124:             (
    4:                 (state, state_dict, mapper, connection, True)
    4:                 for (
    4:                     state,
    4:                     state_dict,
    4:                     mapper,
    4:                     connection,
    4:                     update_version_id,
   40:                 ) in states_to_update
                   ),
               ),
           )
       
       
    1: def post_update(base_mapper, states, uowtransaction, post_update_cols):
           """Issue UPDATE statements on behalf of a relationship() which
           specifies post_update.
       
           """
       
>>>>>>     states_to_update = list(
>>>>>>         _organize_states_for_post_update(base_mapper, states, uowtransaction)
           )
       
>>>>>>     for table, mapper in base_mapper._sorted_tables.items():
>>>>>>         if table not in mapper._pks_by_table:
>>>>>>             continue
       
>>>>>>         update = (
>>>>>>             (
>>>>>>                 state,
>>>>>>                 state_dict,
>>>>>>                 sub_mapper,
>>>>>>                 connection,
                       (
>>>>>>                     mapper._get_committed_state_attr_by_column(
>>>>>>                         state, state_dict, mapper.version_id_col
                           )
>>>>>>                     if mapper.version_id_col is not None
>>>>>>                     else None
                       ),
                   )
>>>>>>             for state, state_dict, sub_mapper, connection in states_to_update
>>>>>>             if table in sub_mapper._pks_by_table
               )
       
>>>>>>         update = _collect_post_update_commands(
>>>>>>             base_mapper, uowtransaction, table, update, post_update_cols
               )
       
>>>>>>         _emit_post_update_statements(
>>>>>>             base_mapper,
>>>>>>             uowtransaction,
>>>>>>             mapper,
>>>>>>             table,
>>>>>>             update,
               )
       
       
    1: def delete_obj(base_mapper, states, uowtransaction):
           """Issue ``DELETE`` statements for a list of objects.
       
           This is called within the context of a UOWTransaction during a
           flush operation.
       
           """
       
   80:     states_to_delete = list(
   40:         _organize_states_for_delete(base_mapper, states, uowtransaction)
           )
       
   40:     table_to_mapper = base_mapper._sorted_tables
       
   80:     for table in reversed(list(table_to_mapper.keys())):
   40:         mapper = table_to_mapper[table]
   40:         if table not in mapper._pks_by_table:
>>>>>>             continue
   40:         elif mapper.inherits and mapper.passive_deletes:
>>>>>>             continue
       
   80:         delete = _collect_delete_commands(
   40:             base_mapper, uowtransaction, table, states_to_delete
               )
       
   80:         _emit_delete_statements(
   40:             base_mapper,
   40:             uowtransaction,
   40:             mapper,
   40:             table,
   40:             delete,
               )
       
   40:     for (
>>>>>>         state,
>>>>>>         state_dict,
>>>>>>         mapper,
>>>>>>         connection,
>>>>>>         update_version_id,
   40:     ) in states_to_delete:
>>>>>>         mapper.dispatch.after_delete(mapper, connection, state)
       
       
    1: def _organize_states_for_save(base_mapper, states, uowtransaction):
           """Make an initial pass across a set of states for INSERT or
           UPDATE.
       
           This includes splitting out into distinct lists for
           each, calling before_insert/before_update, obtaining
           key information for each state including its dictionary,
           mapper, the connection to use for the execution per state,
           and the identity flag.
       
           """
       
  136:     for state, dict_, mapper, connection in _connections_for_states(
   41:         base_mapper, uowtransaction, states
           ):
   54:         has_identity = bool(state.key)
       
   54:         instance_key = state.key or mapper._identity_key_from_state(state)
       
   54:         row_switch = update_version_id = None
       
               # call before_XXX extensions
   54:         if not has_identity:
   50:             mapper.dispatch.before_insert(mapper, connection, state)
               else:
    4:             mapper.dispatch.before_update(mapper, connection, state)
       
   54:         if mapper._validate_polymorphic_identity:
>>>>>>             mapper._validate_polymorphic_identity(mapper, state, dict_)
       
               # detect if we have a "pending" instance (i.e. has
               # no instance_key attached to it), and another instance
               # with the same identity key already exists as persistent.
               # convert to an UPDATE if so.
  104:         if (
   54:             not has_identity
   50:             and instance_key in uowtransaction.session.identity_map
               ):
>>>>>>             instance = uowtransaction.session.identity_map[instance_key]
>>>>>>             existing = attributes.instance_state(instance)
       
>>>>>>             if not uowtransaction.was_already_deleted(existing):
>>>>>>                 if not uowtransaction.is_deleted(existing):
>>>>>>                     util.warn(
>>>>>>                         "New instance %s with identity key %s conflicts "
                               "with persistent instance %s"
>>>>>>                         % (state_str(state), instance_key, state_str(existing))
                           )
                       else:
>>>>>>                     base_mapper._log_debug(
>>>>>>                         "detected row switch for identity %s.  "
                               "will update %s, remove %s from "
                               "transaction",
>>>>>>                         instance_key,
>>>>>>                         state_str(state),
>>>>>>                         state_str(existing),
                           )
       
                           # remove the "delete" flag from the existing element
>>>>>>                     uowtransaction.remove_state_actions(existing)
>>>>>>                     row_switch = existing
       
   54:         if (has_identity or row_switch) and mapper.version_id_col is not None:
>>>>>>             update_version_id = mapper._get_committed_state_attr_by_column(
>>>>>>                 row_switch if row_switch else state,
>>>>>>                 row_switch.dict if row_switch else dict_,
>>>>>>                 mapper.version_id_col,
                   )
       
   54:         yield (
   54:             state,
   54:             dict_,
   54:             mapper,
   54:             connection,
   54:             has_identity,
   54:             row_switch,
   54:             update_version_id,
               )
       
       
    1: def _organize_states_for_post_update(base_mapper, states, uowtransaction):
           """Make an initial pass across a set of states for UPDATE
           corresponding to post_update.
       
           This includes obtaining key information for each state
           including its dictionary, mapper, the connection to use for
           the execution per state.
       
           """
>>>>>>     return _connections_for_states(base_mapper, uowtransaction, states)
       
       
    1: def _organize_states_for_delete(base_mapper, states, uowtransaction):
           """Make an initial pass across a set of states for DELETE.
       
           This includes calling out before_delete and obtaining
           key information for each state including its dictionary,
           mapper, the connection to use for the execution per state.
       
           """
   80:     for state, dict_, mapper, connection in _connections_for_states(
   40:         base_mapper, uowtransaction, states
           ):
>>>>>>         mapper.dispatch.before_delete(mapper, connection, state)
       
>>>>>>         if mapper.version_id_col is not None:
>>>>>>             update_version_id = mapper._get_committed_state_attr_by_column(
>>>>>>                 state, dict_, mapper.version_id_col
                   )
               else:
>>>>>>             update_version_id = None
       
>>>>>>         yield (state, dict_, mapper, connection, update_version_id)
       
       
    1: def _collect_insert_commands(
           table,
           states_to_insert,
           *,
    1:     bulk=False,
    1:     return_defaults=False,
    1:     render_nulls=False,
    1:     include_bulk_keys=(),
       ):
           """Identify sets of values to use in INSERT statements for a
           list of states.
       
           """
   91:     for state, state_dict, mapper, connection in states_to_insert:
   50:         if table not in mapper._pks_by_table:
>>>>>>             continue
       
   50:         params = {}
   50:         value_params = {}
       
   50:         propkey_to_col = mapper._propkey_to_col[table]
       
   50:         eval_none = mapper._insert_cols_evaluating_none[table]
       
  272:         for propkey in set(propkey_to_col).intersection(state_dict):
  222:             value = state_dict[propkey]
  222:             col = propkey_to_col[propkey]
  222:             if value is None and col not in eval_none and not render_nulls:
    4:                 continue
  654:             elif not bulk and (
  218:                 hasattr(value, "__clause_element__")
  218:                 or isinstance(value, sql.ClauseElement)
                   ):
>>>>>>                 value_params[col] = (
>>>>>>                     value.__clause_element__()
>>>>>>                     if hasattr(value, "__clause_element__")
>>>>>>                     else value
                       )
                   else:
  218:                 params[col.key] = value
       
   50:         if not bulk:
                   # for all the columns that have no default and we don't have
                   # a value and where "None" is not a special value, add
                   # explicit None to the INSERT.   This is a legacy behavior
                   # which might be worth removing, as it should not be necessary
                   # and also produces confusion, given that "missing" and None
                   # now have distinct meanings
  667:             for colkey in (
  150:                 mapper._insert_cols_as_none[table]
   50:                 .difference(params)
  100:                 .difference([c.key for c in value_params])
                   ):
  617:                 params[colkey] = None
       
   50:         if not bulk or return_defaults:
                   # params are in terms of Column key objects, so
                   # compare to pk_keys_by_table
   50:             has_all_pks = mapper._pk_keys_by_table[table].issubset(params)
       
  100:             if mapper.base_mapper._prefer_eager_defaults(
   50:                 connection.dialect, table
                   ):
  150:                 has_all_defaults = mapper._server_default_col_keys[
   50:                     table
   50:                 ].issubset(params)
                   else:
>>>>>>                 has_all_defaults = True
               else:
>>>>>>             has_all_defaults = has_all_pks = True
       
  100:         if (
   50:             mapper.version_id_generator is not False
   50:             and mapper.version_id_col is not None
>>>>>>             and mapper.version_id_col in mapper._cols_by_table[table]
               ):
>>>>>>             params[mapper.version_id_col.key] = mapper.version_id_generator(
>>>>>>                 None
                   )
       
   50:         if bulk:
>>>>>>             if mapper._set_polymorphic_identity:
>>>>>>                 params.setdefault(
>>>>>>                     mapper._polymorphic_attr_key, mapper.polymorphic_identity
                       )
       
>>>>>>             if include_bulk_keys:
>>>>>>                 params.update((k, state_dict[k]) for k in include_bulk_keys)
       
   50:         yield (
   50:             state,
   50:             state_dict,
   50:             params,
   50:             mapper,
   50:             connection,
   50:             value_params,
   50:             has_all_pks,
   50:             has_all_defaults,
               )
       
       
    1: def _collect_update_commands(
           uowtransaction,
           table,
           states_to_update,
           *,
    1:     bulk=False,
    1:     use_orm_update_stmt=None,
    1:     include_bulk_keys=(),
       ):
           """Identify sets of values to use in UPDATE statements for a
           list of states.
       
           This function works intricately with the history system
           to determine exactly what values should be updated
           as well as how the row should be matched within an UPDATE
           statement.  Includes some tricky scenarios where the primary
           key of an object might have been changed.
       
           """
       
   45:     for (
    4:         state,
    4:         state_dict,
    4:         mapper,
    4:         connection,
    4:         update_version_id,
   41:     ) in states_to_update:
    4:         if table not in mapper._pks_by_table:
>>>>>>             continue
       
    4:         pks = mapper._pks_by_table[table]
       
    4:         if use_orm_update_stmt is not None:
                   # TODO: ordered values, etc
>>>>>>             value_params = use_orm_update_stmt._values
               else:
    4:             value_params = {}
       
    4:         propkey_to_col = mapper._propkey_to_col[table]
       
    4:         if bulk:
                   # keys here are mapped attribute keys, so
                   # look at mapper attribute keys for pk
>>>>>>             params = {
>>>>>>                 propkey_to_col[propkey].key: state_dict[propkey]
>>>>>>                 for propkey in set(propkey_to_col)
>>>>>>                 .intersection(state_dict)
>>>>>>                 .difference(mapper._pk_attr_keys_by_table[table])
                   }
>>>>>>             has_all_defaults = True
               else:
    4:             params = {}
   12:             for propkey in set(propkey_to_col).intersection(
    4:                 state.committed_state
                   ):
    4:                 value = state_dict[propkey]
    4:                 col = propkey_to_col[propkey]
       
    8:                 if hasattr(value, "__clause_element__") or isinstance(
    4:                     value, sql.ClauseElement
                       ):
>>>>>>                     value_params[col] = (
>>>>>>                         value.__clause_element__()
>>>>>>                         if hasattr(value, "__clause_element__")
>>>>>>                         else value
                           )
                       # guard against values that generate non-__nonzero__
                       # objects for __eq__()
    4:                 elif (
   12:                     state.manager[propkey].impl.is_equal(
    4:                         value, state.committed_state[propkey]
                           )
    4:                     is not True
                       ):
    4:                     params[col.key] = value
       
    4:             if mapper.base_mapper.eager_defaults is True:
>>>>>>                 has_all_defaults = (
>>>>>>                     mapper._server_onupdate_default_col_keys[table]
>>>>>>                 ).issubset(params)
                   else:
    4:                 has_all_defaults = True
       
    4:         if (
    4:             update_version_id is not None
>>>>>>             and mapper.version_id_col in mapper._cols_by_table[table]
               ):
>>>>>>             if not bulk and not (params or value_params):
                       # HACK: check for history in other tables, in case the
                       # history is only in a different table than the one
                       # where the version_id_col is.  This logic was lost
                       # from 0.9 -> 1.0.0 and restored in 1.0.6.
>>>>>>                 for prop in mapper._columntoproperty.values():
>>>>>>                     history = state.manager[prop.key].impl.get_history(
>>>>>>                         state, state_dict, attributes.PASSIVE_NO_INITIALIZE
                           )
>>>>>>                     if history.added:
>>>>>>                         break
                       else:
                           # no net change, break
>>>>>>                     continue
       
>>>>>>             col = mapper.version_id_col
>>>>>>             no_params = not params and not value_params
>>>>>>             params[col._label] = update_version_id
       
>>>>>>             if (
>>>>>>                 bulk or col.key not in params
>>>>>>             ) and mapper.version_id_generator is not False:
>>>>>>                 val = mapper.version_id_generator(update_version_id)
>>>>>>                 params[col.key] = val
>>>>>>             elif mapper.version_id_generator is False and no_params:
                       # no version id generator, no values set on the table,
                       # and version id wasn't manually incremented.
                       # set version id to itself so we get an UPDATE
                       # statement
>>>>>>                 params[col.key] = update_version_id
       
    4:         elif not (params or value_params):
>>>>>>             continue
       
    4:         has_all_pks = True
    4:         expect_pk_cascaded = False
    4:         if bulk:
                   # keys here are mapped attribute keys, so
                   # look at mapper attribute keys for pk
>>>>>>             pk_params = {
>>>>>>                 propkey_to_col[propkey]._label: state_dict.get(propkey)
>>>>>>                 for propkey in set(propkey_to_col).intersection(
>>>>>>                     mapper._pk_attr_keys_by_table[table]
                       )
                   }
>>>>>>             if util.NONE_SET.intersection(pk_params.values()):
>>>>>>                 raise sa_exc.InvalidRequestError(
>>>>>>                     f"No primary key value supplied for column(s) "
                           f"""{
>>>>>>                         ', '.join(
>>>>>>                             str(c) for c in pks if pk_params[c._label] is None
                               )
                           }; """
                           "per-row ORM Bulk UPDATE by Primary Key requires that "
                           "records contain primary key values",
>>>>>>                     code="bupq",
                       )
       
               else:
    4:             pk_params = {}
    8:             for col in pks:
    4:                 propkey = mapper._columntoproperty[col].key
       
    8:                 history = state.manager[propkey].impl.get_history(
    4:                     state, state_dict, attributes.PASSIVE_OFF
                       )
       
    4:                 if history.added:
>>>>>>                     if (
>>>>>>                         not history.deleted
>>>>>>                         or ("pk_cascaded", state, col)
>>>>>>                         in uowtransaction.attributes
                           ):
>>>>>>                         expect_pk_cascaded = True
>>>>>>                         pk_params[col._label] = history.added[0]
>>>>>>                         params.pop(col.key, None)
                           else:
                               # else, use the old value to locate the row
>>>>>>                         pk_params[col._label] = history.deleted[0]
>>>>>>                         if col in value_params:
>>>>>>                             has_all_pks = False
                       else:
    4:                     pk_params[col._label] = history.unchanged[0]
    4:                 if pk_params[col._label] is None:
>>>>>>                     raise orm_exc.FlushError(
>>>>>>                         "Can't update table %s using NULL for primary "
>>>>>>                         "key value on column %s" % (table, col)
                           )
       
    4:         if include_bulk_keys:
>>>>>>             params.update((k, state_dict[k]) for k in include_bulk_keys)
       
    4:         if params or value_params:
    4:             params.update(pk_params)
    4:             yield (
    4:                 state,
    4:                 state_dict,
    4:                 params,
    4:                 mapper,
    4:                 connection,
    4:                 value_params,
    4:                 has_all_defaults,
    4:                 has_all_pks,
                   )
>>>>>>         elif expect_pk_cascaded:
                   # no UPDATE occurs on this table, but we expect that CASCADE rules
                   # have changed the primary key of the row; propagate this event to
                   # other columns that expect to have been modified. this normally
                   # occurs after the UPDATE is emitted however we invoke it here
                   # explicitly in the absence of our invoking an UPDATE
>>>>>>             for m, equated_pairs in mapper._table_to_equated[table]:
>>>>>>                 sync.populate(
>>>>>>                     state,
>>>>>>                     m,
>>>>>>                     state,
>>>>>>                     m,
>>>>>>                     equated_pairs,
>>>>>>                     uowtransaction,
>>>>>>                     mapper.passive_updates,
                       )
       
       
    1: def _collect_post_update_commands(
           base_mapper, uowtransaction, table, states_to_update, post_update_cols
       ):
           """Identify sets of values to use in UPDATE statements for a
           list of states within a post_update operation.
       
           """
       
>>>>>>     for (
>>>>>>         state,
>>>>>>         state_dict,
>>>>>>         mapper,
>>>>>>         connection,
>>>>>>         update_version_id,
>>>>>>     ) in states_to_update:
               # assert table in mapper._pks_by_table
       
>>>>>>         pks = mapper._pks_by_table[table]
>>>>>>         params = {}
>>>>>>         hasdata = False
       
>>>>>>         for col in mapper._cols_by_table[table]:
>>>>>>             if col in pks:
>>>>>>                 params[col._label] = mapper._get_state_attr_by_column(
>>>>>>                     state, state_dict, col, passive=attributes.PASSIVE_OFF
                       )
       
>>>>>>             elif col in post_update_cols or col.onupdate is not None:
>>>>>>                 prop = mapper._columntoproperty[col]
>>>>>>                 history = state.manager[prop.key].impl.get_history(
>>>>>>                     state, state_dict, attributes.PASSIVE_NO_INITIALIZE
                       )
>>>>>>                 if history.added:
>>>>>>                     value = history.added[0]
>>>>>>                     params[col.key] = value
>>>>>>                     hasdata = True
>>>>>>         if hasdata:
>>>>>>             if (
>>>>>>                 update_version_id is not None
>>>>>>                 and mapper.version_id_col in mapper._cols_by_table[table]
                   ):
>>>>>>                 col = mapper.version_id_col
>>>>>>                 params[col._label] = update_version_id
       
>>>>>>                 if (
>>>>>>                     bool(state.key)
>>>>>>                     and col.key not in params
>>>>>>                     and mapper.version_id_generator is not False
                       ):
>>>>>>                     val = mapper.version_id_generator(update_version_id)
>>>>>>                     params[col.key] = val
>>>>>>             yield state, state_dict, mapper, connection, params
       
       
    1: def _collect_delete_commands(
           base_mapper, uowtransaction, table, states_to_delete
       ):
           """Identify values to use in DELETE statements for a list of
           states to be deleted."""
       
   40:     for (
>>>>>>         state,
>>>>>>         state_dict,
>>>>>>         mapper,
>>>>>>         connection,
>>>>>>         update_version_id,
   40:     ) in states_to_delete:
>>>>>>         if table not in mapper._pks_by_table:
>>>>>>             continue
       
>>>>>>         params = {}
>>>>>>         for col in mapper._pks_by_table[table]:
>>>>>>             params[col.key] = value = (
>>>>>>                 mapper._get_committed_state_attr_by_column(
>>>>>>                     state, state_dict, col
                       )
                   )
>>>>>>             if value is None:
>>>>>>                 raise orm_exc.FlushError(
>>>>>>                     "Can't delete from table %s "
                           "using NULL for primary "
>>>>>>                     "key value on column %s" % (table, col)
                       )
       
>>>>>>         if (
>>>>>>             update_version_id is not None
>>>>>>             and mapper.version_id_col in mapper._cols_by_table[table]
               ):
>>>>>>             params[mapper.version_id_col.key] = update_version_id
>>>>>>         yield params, connection
       
       
    1: def _emit_update_statements(
           base_mapper,
           uowtransaction,
           mapper,
           table,
           update,
           *,
    1:     bookkeeping=True,
    1:     use_orm_update_stmt=None,
    1:     enable_check_rowcount=True,
       ):
           """Emit UPDATE statements corresponding to value lists collected
           by _collect_update_commands()."""
       
   41:     needs_version_id = (
   41:         mapper.version_id_col is not None
>>>>>>         and mapper.version_id_col in mapper._cols_by_table[table]
           )
       
   41:     execution_options = {"compiled_cache": base_mapper._compiled_cache}
       
   41:     def update_stmt(existing_stmt=None):
    5:         clauses = BooleanClauseList._construct_raw(operators.and_)
       
   11:         for col in mapper._pks_by_table[table]:
   12:             clauses._append_inplace(
    6:                 col == sql.bindparam(col._label, type_=col.type)
                   )
       
    5:         if needs_version_id:
>>>>>>             clauses._append_inplace(
>>>>>>                 mapper.version_id_col
>>>>>>                 == sql.bindparam(
>>>>>>                     mapper.version_id_col._label,
>>>>>>                     type_=mapper.version_id_col.type,
                       )
                   )
       
    5:         if existing_stmt is not None:
>>>>>>             stmt = existing_stmt.where(clauses)
               else:
    5:             stmt = table.update().where(clauses)
    5:         return stmt
       
   41:     if use_orm_update_stmt is not None:
>>>>>>         cached_stmt = update_stmt(use_orm_update_stmt)
       
           else:
   41:         cached_stmt = base_mapper._memo(("update", table), update_stmt)
       
   45:     for (
    4:         (connection, paramkeys, hasvalue, has_all_defaults, has_all_pks),
    4:         records,
   82:     ) in groupby(
   41:         update,
   45:         lambda rec: (
    4:             rec[4],  # connection
    4:             set(rec[2]),  # set of parameter keys
    4:             bool(rec[5]),  # whether or not we have "value" parameters
    4:             rec[6],  # has_all_defaults
    4:             rec[7],  # has all pks
               ),
           ):
    4:         rows = 0
    4:         records = list(records)
       
    4:         statement = cached_stmt
       
    4:         if use_orm_update_stmt is not None:
>>>>>>             statement = statement._annotate(
>>>>>>                 {
>>>>>>                     "_emit_update_table": table,
>>>>>>                     "_emit_update_mapper": mapper,
                       }
                   )
       
    4:         return_defaults = False
       
    4:         if not has_all_pks:
>>>>>>             statement = statement.return_defaults(*mapper._pks_by_table[table])
>>>>>>             return_defaults = True
       
    8:         if (
    4:             bookkeeping
    4:             and not has_all_defaults
>>>>>>             and mapper.base_mapper.eager_defaults is True
                   # change as of #8889 - if RETURNING is not going to be used anyway,
                   # (applies to MySQL, MariaDB which lack UPDATE RETURNING) ensure
                   # we can do an executemany UPDATE which is more efficient
>>>>>>             and table.implicit_returning
>>>>>>             and connection.dialect.update_returning
               ):
>>>>>>             statement = statement.return_defaults(
>>>>>>                 *mapper._server_onupdate_default_cols[table]
                   )
>>>>>>             return_defaults = True
       
    4:         if mapper._version_id_has_server_side_value:
>>>>>>             statement = statement.return_defaults(mapper.version_id_col)
>>>>>>             return_defaults = True
       
    4:         assert_singlerow = connection.dialect.supports_sane_rowcount
       
    4:         assert_multirow = (
    4:             assert_singlerow
    4:             and connection.dialect.supports_sane_multi_rowcount
               )
       
               # change as of #8889 - if RETURNING is not going to be used anyway,
               # (applies to MySQL, MariaDB which lack UPDATE RETURNING) ensure
               # we can do an executemany UPDATE which is more efficient
    4:         allow_executemany = not return_defaults and not needs_version_id
       
    4:         if hasvalue:
>>>>>>             for (
>>>>>>                 state,
>>>>>>                 state_dict,
>>>>>>                 params,
>>>>>>                 mapper,
>>>>>>                 connection,
>>>>>>                 value_params,
>>>>>>                 has_all_defaults,
>>>>>>                 has_all_pks,
>>>>>>             ) in records:
>>>>>>                 c = connection.execute(
>>>>>>                     statement.values(value_params),
>>>>>>                     params,
>>>>>>                     execution_options=execution_options,
                       )
>>>>>>                 if bookkeeping:
>>>>>>                     _postfetch(
>>>>>>                         mapper,
>>>>>>                         uowtransaction,
>>>>>>                         table,
>>>>>>                         state,
>>>>>>                         state_dict,
>>>>>>                         c,
>>>>>>                         c.context.compiled_parameters[0],
>>>>>>                         value_params,
>>>>>>                         True,
>>>>>>                         c.returned_defaults,
                           )
>>>>>>                 rows += c.rowcount
>>>>>>                 check_rowcount = enable_check_rowcount and assert_singlerow
               else:
    4:             if not allow_executemany:
>>>>>>                 check_rowcount = enable_check_rowcount and assert_singlerow
>>>>>>                 for (
>>>>>>                     state,
>>>>>>                     state_dict,
>>>>>>                     params,
>>>>>>                     mapper,
>>>>>>                     connection,
>>>>>>                     value_params,
>>>>>>                     has_all_defaults,
>>>>>>                     has_all_pks,
>>>>>>                 ) in records:
>>>>>>                     c = connection.execute(
>>>>>>                         statement, params, execution_options=execution_options
                           )
       
                           # TODO: why with bookkeeping=False?
>>>>>>                     if bookkeeping:
>>>>>>                         _postfetch(
>>>>>>                             mapper,
>>>>>>                             uowtransaction,
>>>>>>                             table,
>>>>>>                             state,
>>>>>>                             state_dict,
>>>>>>                             c,
>>>>>>                             c.context.compiled_parameters[0],
>>>>>>                             value_params,
>>>>>>                             True,
>>>>>>                             c.returned_defaults,
                               )
>>>>>>                     rows += c.rowcount
                   else:
   12:                 multiparams = [rec[2] for rec in records]
       
    8:                 check_rowcount = enable_check_rowcount and (
    4:                     assert_multirow
>>>>>>                     or (assert_singlerow and len(multiparams) == 1)
                       )
       
    8:                 c = connection.execute(
    4:                     statement, multiparams, execution_options=execution_options
                       )
       
    4:                 rows += c.rowcount
       
    8:                 for (
    4:                     state,
    4:                     state_dict,
    4:                     params,
    4:                     mapper,
    4:                     connection,
    4:                     value_params,
    4:                     has_all_defaults,
    4:                     has_all_pks,
    4:                 ) in records:
    4:                     if bookkeeping:
    8:                         _postfetch(
    4:                             mapper,
    4:                             uowtransaction,
    4:                             table,
    4:                             state,
    4:                             state_dict,
    4:                             c,
    4:                             c.context.compiled_parameters[0],
    4:                             value_params,
    4:                             True,
                                   (
    4:                                 c.returned_defaults
    4:                                 if not c.context.executemany
>>>>>>                                 else None
                                   ),
                               )
       
    4:         if check_rowcount:
    4:             if rows != len(records):
>>>>>>                 raise orm_exc.StaleDataError(
>>>>>>                     "UPDATE statement on table '%s' expected to "
                           "update %d row(s); %d were matched."
>>>>>>                     % (table.description, len(records), rows)
                       )
       
>>>>>>         elif needs_version_id:
>>>>>>             util.warn(
>>>>>>                 "Dialect %s does not support updated rowcount "
                       "- versioning cannot be verified."
>>>>>>                 % c.dialect.dialect_description
                   )
       
       
    1: def _emit_insert_statements(
           base_mapper,
           uowtransaction,
           mapper,
           table,
           insert,
           *,
    1:     bookkeeping=True,
    1:     use_orm_insert_stmt=None,
    1:     execution_options=None,
       ):
           """Emit INSERT statements corresponding to value lists collected
           by _collect_insert_commands()."""
       
   41:     if use_orm_insert_stmt is not None:
>>>>>>         cached_stmt = use_orm_insert_stmt
>>>>>>         exec_opt = util.EMPTY_DICT
       
               # if a user query with RETURNING was passed, we definitely need
               # to use RETURNING.
>>>>>>         returning_is_required_anyway = bool(use_orm_insert_stmt._returning)
>>>>>>         deterministic_results_reqd = (
>>>>>>             returning_is_required_anyway
>>>>>>             and use_orm_insert_stmt._sort_by_parameter_order
>>>>>>         ) or bookkeeping
           else:
   41:         returning_is_required_anyway = False
   41:         deterministic_results_reqd = bookkeeping
   41:         cached_stmt = base_mapper._memo(("insert", table), table.insert)
   41:         exec_opt = {"compiled_cache": base_mapper._compiled_cache}
       
   41:     if execution_options:
>>>>>>         execution_options = util.EMPTY_DICT.merge_with(
>>>>>>             exec_opt, execution_options
               )
           else:
   41:         execution_options = exec_opt
       
   41:     return_result = None
       
   77:     for (
   37:         (connection, _, hasvalue, has_all_pks, has_all_defaults),
   37:         records,
   82:     ) in groupby(
   41:         insert,
   91:         lambda rec: (
   50:             rec[4],  # connection
   50:             set(rec[2]),  # parameter keys
   50:             bool(rec[5]),  # whether we have "value" parameters
   50:             rec[6],
   50:             rec[7],
               ),
           ):
   37:         statement = cached_stmt
       
   37:         if use_orm_insert_stmt is not None:
>>>>>>             statement = statement._annotate(
>>>>>>                 {
>>>>>>                     "_emit_insert_table": table,
>>>>>>                     "_emit_insert_mapper": mapper,
                       }
                   )
       
  151:         if (
                   (
   37:                 not bookkeeping
                       or (
   37:                     has_all_defaults
>>>>>>                     or not base_mapper._prefer_eager_defaults(
>>>>>>                         connection.dialect, table
                           )
>>>>>>                     or not table.implicit_returning
>>>>>>                     or not connection.dialect.insert_returning
                       )
                   )
   37:             and not returning_is_required_anyway
   37:             and has_all_pks
    3:             and not hasvalue
               ):
                   # the "we don't need newly generated values back" section.
                   # here we have all the PKs, all the defaults or we don't want
                   # to fetch them, or the dialect doesn't support RETURNING at all
                   # so we have to post-fetch / use lastrowid anyway.
    3:             records = list(records)
    9:             multiparams = [rec[2] for rec in records]
       
    6:             result = connection.execute(
    3:                 statement, multiparams, execution_options=execution_options
                   )
    2:             if bookkeeping:
    4:                 for (
    2:                     (
    2:                         state,
    2:                         state_dict,
    2:                         params,
    2:                         mapper_rec,
    2:                         conn,
    2:                         value_params,
    2:                         has_all_pks,
    2:                         has_all_defaults,
                           ),
    2:                     last_inserted_params,
    2:                 ) in zip(records, result.context.compiled_parameters):
    2:                     if state:
    4:                         _postfetch(
    2:                             mapper_rec,
    2:                             uowtransaction,
    2:                             table,
    2:                             state,
    2:                             state_dict,
    2:                             result,
    2:                             last_inserted_params,
    2:                             value_params,
    2:                             False,
                                   (
    2:                                 result.returned_defaults
    2:                                 if not result.context.executemany
>>>>>>                                 else None
                                   ),
                               )
                           else:
>>>>>>                         _postfetch_bulk_save(mapper_rec, state_dict, table)
       
               else:
                   # here, we need defaults and/or pk values back or we otherwise
                   # know that we are using RETURNING in any case
       
   34:             records = list(records)
       
  136:             if returning_is_required_anyway or (
  102:                 table.implicit_returning and not hasvalue and len(records) > 1
                   ):
   24:                 if (
   12:                     deterministic_results_reqd
   12:                     and connection.dialect.insert_executemany_returning_sort_by_parameter_order  # noqa: E501
                       ) or (
>>>>>>                     not deterministic_results_reqd
>>>>>>                     and connection.dialect.insert_executemany_returning
                       ):
   12:                     do_executemany = True
>>>>>>                 elif returning_is_required_anyway:
>>>>>>                     if deterministic_results_reqd:
>>>>>>                         dt = " with RETURNING and sort by parameter order"
                           else:
>>>>>>                         dt = " with RETURNING"
>>>>>>                     raise sa_exc.InvalidRequestError(
>>>>>>                         f"Can't use explicit RETURNING for bulk INSERT "
                               f"operation with "
>>>>>>                         f"{connection.dialect.dialect_description} backend; "
>>>>>>                         f"executemany{dt} is not enabled for this dialect."
                           )
                       else:
>>>>>>                     do_executemany = False
                   else:
   22:                 do_executemany = False
       
   34:             if use_orm_insert_stmt is None:
   34:                 if (
   34:                     not has_all_defaults
>>>>>>                     and base_mapper._prefer_eager_defaults(
>>>>>>                         connection.dialect, table
                           )
                       ):
>>>>>>                     statement = statement.return_defaults(
>>>>>>                         *mapper._server_default_cols[table],
>>>>>>                         sort_by_parameter_order=bookkeeping,
                           )
       
   34:             if mapper.version_id_col is not None:
>>>>>>                 statement = statement.return_defaults(
>>>>>>                     mapper.version_id_col,
>>>>>>                     sort_by_parameter_order=bookkeeping,
                       )
   34:             elif do_executemany:
   36:                 statement = statement.return_defaults(
   24:                     *table.primary_key, sort_by_parameter_order=bookkeeping
                       )
       
   34:             if do_executemany:
   49:                 multiparams = [rec[2] for rec in records]
       
   24:                 result = connection.execute(
   12:                     statement, multiparams, execution_options=execution_options
                       )
       
   12:                 if use_orm_insert_stmt is not None:
>>>>>>                     if return_result is None:
>>>>>>                         return_result = result
                           else:
>>>>>>                         return_result = return_result.splice_vertically(result)
       
   12:                 if bookkeeping:
   37:                     for (
   25:                         (
   25:                             state,
   25:                             state_dict,
   25:                             params,
   25:                             mapper_rec,
   25:                             conn,
   25:                             value_params,
   25:                             has_all_pks,
   25:                             has_all_defaults,
                               ),
   25:                         last_inserted_params,
   25:                         inserted_primary_key,
   25:                         returned_defaults,
   24:                     ) in zip_longest(
   12:                         records,
   12:                         result.context.compiled_parameters,
   12:                         result.inserted_primary_key_rows,
   12:                         result.returned_defaults_rows or (),
                           ):
   25:                         if inserted_primary_key is None:
                                   # this is a real problem and means that we didn't
                                   # get back as many PK rows.  we can't continue
                                   # since this indicates PK rows were missing, which
                                   # means we likely mis-populated records starting
                                   # at that point with incorrectly matched PK
                                   # values.
>>>>>>                             raise orm_exc.FlushError(
>>>>>>                                 "Multi-row INSERT statement for %s did not "
                                       "produce "
                                       "the correct number of INSERTed rows for "
                                       "RETURNING.  Ensure there are no triggers or "
                                       "special driver issues preventing INSERT from "
>>>>>>                                 "functioning properly." % mapper_rec
                                   )
       
   75:                         for pk, col in zip(
   25:                             inserted_primary_key,
   25:                             mapper._pks_by_table[table],
                               ):
   25:                             prop = mapper_rec._columntoproperty[col]
   25:                             if state_dict.get(prop.key) is None:
   25:                                 state_dict[prop.key] = pk
       
   25:                         if state:
   50:                             _postfetch(
   25:                                 mapper_rec,
   25:                                 uowtransaction,
   25:                                 table,
   25:                                 state,
   25:                                 state_dict,
   25:                                 result,
   25:                                 last_inserted_params,
   25:                                 value_params,
   25:                                 False,
   25:                                 returned_defaults,
                                   )
                               else:
>>>>>>                             _postfetch_bulk_save(mapper_rec, state_dict, table)
                   else:
   22:                 assert not returning_is_required_anyway
       
   44:                 for (
   22:                     state,
   22:                     state_dict,
   22:                     params,
   22:                     mapper_rec,
   22:                     connection,
   22:                     value_params,
   22:                     has_all_pks,
   22:                     has_all_defaults,
   22:                 ) in records:
   22:                     if value_params:
>>>>>>                         result = connection.execute(
>>>>>>                             statement.values(value_params),
>>>>>>                             params,
>>>>>>                             execution_options=execution_options,
                               )
                           else:
   44:                         result = connection.execute(
   22:                             statement,
   22:                             params,
   22:                             execution_options=execution_options,
                               )
       
   22:                     primary_key = result.inserted_primary_key
   22:                     if primary_key is None:
>>>>>>                         raise orm_exc.FlushError(
>>>>>>                             "Single-row INSERT statement for %s "
                                   "did not produce a "
                                   "new primary key result "
                                   "being invoked.  Ensure there are no triggers or "
                                   "special driver issues preventing INSERT from "
>>>>>>                             "functioning properly." % (mapper_rec,)
                               )
   66:                     for pk, col in zip(
   22:                         primary_key, mapper._pks_by_table[table]
                           ):
   22:                         prop = mapper_rec._columntoproperty[col]
   44:                         if (
   22:                             col in value_params
   22:                             or state_dict.get(prop.key) is None
                               ):
   22:                             state_dict[prop.key] = pk
   22:                     if bookkeeping:
   22:                         if state:
   44:                             _postfetch(
   22:                                 mapper_rec,
   22:                                 uowtransaction,
   22:                                 table,
   22:                                 state,
   22:                                 state_dict,
   22:                                 result,
   22:                                 result.context.compiled_parameters[0],
   22:                                 value_params,
   22:                                 False,
                                       (
   22:                                     result.returned_defaults
   22:                                     if not result.context.executemany
>>>>>>                                     else None
                                       ),
                                   )
                               else:
>>>>>>                             _postfetch_bulk_save(mapper_rec, state_dict, table)
       
   40:     if use_orm_insert_stmt is not None:
>>>>>>         if return_result is None:
>>>>>>             return _cursor.null_dml_result()
               else:
>>>>>>             return return_result
       
       
    1: def _emit_post_update_statements(
           base_mapper, uowtransaction, mapper, table, update
       ):
           """Emit UPDATE statements corresponding to value lists collected
           by _collect_post_update_commands()."""
       
>>>>>>     execution_options = {"compiled_cache": base_mapper._compiled_cache}
       
>>>>>>     needs_version_id = (
>>>>>>         mapper.version_id_col is not None
>>>>>>         and mapper.version_id_col in mapper._cols_by_table[table]
           )
       
>>>>>>     def update_stmt():
>>>>>>         clauses = BooleanClauseList._construct_raw(operators.and_)
       
>>>>>>         for col in mapper._pks_by_table[table]:
>>>>>>             clauses._append_inplace(
>>>>>>                 col == sql.bindparam(col._label, type_=col.type)
                   )
       
>>>>>>         if needs_version_id:
>>>>>>             clauses._append_inplace(
>>>>>>                 mapper.version_id_col
>>>>>>                 == sql.bindparam(
>>>>>>                     mapper.version_id_col._label,
>>>>>>                     type_=mapper.version_id_col.type,
                       )
                   )
       
>>>>>>         stmt = table.update().where(clauses)
       
>>>>>>         return stmt
       
>>>>>>     statement = base_mapper._memo(("post_update", table), update_stmt)
       
>>>>>>     if mapper._version_id_has_server_side_value:
>>>>>>         statement = statement.return_defaults(mapper.version_id_col)
       
           # execute each UPDATE in the order according to the original
           # list of states to guarantee row access order, but
           # also group them into common (connection, cols) sets
           # to support executemany().
>>>>>>     for key, records in groupby(
>>>>>>         update,
>>>>>>         lambda rec: (rec[3], set(rec[4])),  # connection  # parameter keys
           ):
>>>>>>         rows = 0
       
>>>>>>         records = list(records)
>>>>>>         connection = key[0]
       
>>>>>>         assert_singlerow = connection.dialect.supports_sane_rowcount
>>>>>>         assert_multirow = (
>>>>>>             assert_singlerow
>>>>>>             and connection.dialect.supports_sane_multi_rowcount
               )
>>>>>>         allow_executemany = not needs_version_id or assert_multirow
       
>>>>>>         if not allow_executemany:
>>>>>>             check_rowcount = assert_singlerow
>>>>>>             for state, state_dict, mapper_rec, connection, params in records:
>>>>>>                 c = connection.execute(
>>>>>>                     statement, params, execution_options=execution_options
                       )
       
>>>>>>                 _postfetch_post_update(
>>>>>>                     mapper_rec,
>>>>>>                     uowtransaction,
>>>>>>                     table,
>>>>>>                     state,
>>>>>>                     state_dict,
>>>>>>                     c,
>>>>>>                     c.context.compiled_parameters[0],
                       )
>>>>>>                 rows += c.rowcount
               else:
>>>>>>             multiparams = [
>>>>>>                 params
>>>>>>                 for state, state_dict, mapper_rec, conn, params in records
                   ]
       
>>>>>>             check_rowcount = assert_multirow or (
>>>>>>                 assert_singlerow and len(multiparams) == 1
                   )
       
>>>>>>             c = connection.execute(
>>>>>>                 statement, multiparams, execution_options=execution_options
                   )
       
>>>>>>             rows += c.rowcount
>>>>>>             for state, state_dict, mapper_rec, connection, params in records:
>>>>>>                 _postfetch_post_update(
>>>>>>                     mapper_rec,
>>>>>>                     uowtransaction,
>>>>>>                     table,
>>>>>>                     state,
>>>>>>                     state_dict,
>>>>>>                     c,
>>>>>>                     c.context.compiled_parameters[0],
                       )
       
>>>>>>         if check_rowcount:
>>>>>>             if rows != len(records):
>>>>>>                 raise orm_exc.StaleDataError(
>>>>>>                     "UPDATE statement on table '%s' expected to "
                           "update %d row(s); %d were matched."
>>>>>>                     % (table.description, len(records), rows)
                       )
       
>>>>>>         elif needs_version_id:
>>>>>>             util.warn(
>>>>>>                 "Dialect %s does not support updated rowcount "
                       "- versioning cannot be verified."
>>>>>>                 % c.dialect.dialect_description
                   )
       
       
    1: def _emit_delete_statements(
           base_mapper, uowtransaction, mapper, table, delete
       ):
           """Emit DELETE statements corresponding to value lists collected
           by _collect_delete_commands()."""
       
   40:     need_version_id = (
   40:         mapper.version_id_col is not None
>>>>>>         and mapper.version_id_col in mapper._cols_by_table[table]
           )
       
   40:     def delete_stmt():
    5:         clauses = BooleanClauseList._construct_raw(operators.and_)
       
   11:         for col in mapper._pks_by_table[table]:
   12:             clauses._append_inplace(
    6:                 col == sql.bindparam(col.key, type_=col.type)
                   )
       
    5:         if need_version_id:
>>>>>>             clauses._append_inplace(
>>>>>>                 mapper.version_id_col
>>>>>>                 == sql.bindparam(
>>>>>>                     mapper.version_id_col.key, type_=mapper.version_id_col.type
                       )
                   )
       
    5:         return table.delete().where(clauses)
       
   40:     statement = base_mapper._memo(("delete", table), delete_stmt)
   40:     for connection, recs in groupby(delete, lambda rec: rec[1]):  # connection
>>>>>>         del_objects = [params for params, connection in recs]
       
>>>>>>         execution_options = {"compiled_cache": base_mapper._compiled_cache}
>>>>>>         expected = len(del_objects)
>>>>>>         rows_matched = -1
>>>>>>         only_warn = False
       
>>>>>>         if (
>>>>>>             need_version_id
>>>>>>             and not connection.dialect.supports_sane_multi_rowcount
               ):
>>>>>>             if connection.dialect.supports_sane_rowcount:
>>>>>>                 rows_matched = 0
                       # execute deletes individually so that versioned
                       # rows can be verified
>>>>>>                 for params in del_objects:
>>>>>>                     c = connection.execute(
>>>>>>                         statement, params, execution_options=execution_options
                           )
>>>>>>                     rows_matched += c.rowcount
                   else:
>>>>>>                 util.warn(
>>>>>>                     "Dialect %s does not support deleted rowcount "
                           "- versioning cannot be verified."
>>>>>>                     % connection.dialect.dialect_description
                       )
>>>>>>                 connection.execute(
>>>>>>                     statement, del_objects, execution_options=execution_options
                       )
               else:
>>>>>>             c = connection.execute(
>>>>>>                 statement, del_objects, execution_options=execution_options
                   )
       
>>>>>>             if not need_version_id:
>>>>>>                 only_warn = True
       
>>>>>>             rows_matched = c.rowcount
       
>>>>>>         if (
>>>>>>             base_mapper.confirm_deleted_rows
>>>>>>             and rows_matched > -1
>>>>>>             and expected != rows_matched
                   and (
>>>>>>                 connection.dialect.supports_sane_multi_rowcount
>>>>>>                 or len(del_objects) == 1
                   )
               ):
                   # TODO: why does this "only warn" if versioning is turned off,
                   # whereas the UPDATE raises?
>>>>>>             if only_warn:
>>>>>>                 util.warn(
>>>>>>                     "DELETE statement on table '%s' expected to "
                           "delete %d row(s); %d were matched.  Please set "
                           "confirm_deleted_rows=False within the mapper "
                           "configuration to prevent this warning."
>>>>>>                     % (table.description, expected, rows_matched)
                       )
                   else:
>>>>>>                 raise orm_exc.StaleDataError(
>>>>>>                     "DELETE statement on table '%s' expected to "
                           "delete %d row(s); %d were matched.  Please set "
                           "confirm_deleted_rows=False within the mapper "
                           "configuration to prevent this warning."
>>>>>>                     % (table.description, expected, rows_matched)
                       )
       
       
    1: def _finalize_insert_update_commands(base_mapper, uowtransaction, states):
           """finalize state on states that have been inserted or updated,
           including calling after_insert/after_update events.
       
           """
   93:     for state, state_dict, mapper, connection, has_identity in states:
   53:         if mapper._readonly_props:
>>>>>>             readonly = state.unmodified_intersection(
>>>>>>                 [
>>>>>>                     p.key
>>>>>>                     for p in mapper._readonly_props
                           if (
>>>>>>                         p.expire_on_flush
>>>>>>                         and (not p.deferred or p.key in state.dict)
                           )
                           or (
>>>>>>                         not p.expire_on_flush
>>>>>>                         and not p.deferred
>>>>>>                         and p.key not in state.dict
                           )
                       ]
                   )
>>>>>>             if readonly:
>>>>>>                 state._expire_attributes(state.dict, readonly)
       
               # if eager_defaults option is enabled, load
               # all expired cols.  Else if we have a version_id_col, make sure
               # it isn't expired.
   53:         toload_now = []
       
               # this is specifically to emit a second SELECT for eager_defaults,
               # so only if it's set to True, not "auto"
   53:         if base_mapper.eager_defaults is True:
>>>>>>             toload_now.extend(
>>>>>>                 state._unloaded_non_object.intersection(
>>>>>>                     mapper._server_default_plus_onupdate_propkeys
                       )
                   )
       
   53:         if (
   53:             mapper.version_id_col is not None
>>>>>>             and mapper.version_id_generator is False
               ):
>>>>>>             if mapper._version_id_prop.key in state.unloaded:
>>>>>>                 toload_now.extend([mapper._version_id_prop.key])
       
   53:         if toload_now:
>>>>>>             state.key = base_mapper._identity_key_from_state(state)
>>>>>>             stmt = future.select(mapper).set_label_style(
>>>>>>                 LABEL_STYLE_TABLENAME_PLUS_COL
                   )
>>>>>>             loading.load_on_ident(
>>>>>>                 uowtransaction.session,
>>>>>>                 stmt,
>>>>>>                 state.key,
>>>>>>                 refresh_state=state,
>>>>>>                 only_load_props=toload_now,
                   )
       
               # call after_XXX extensions
   53:         if not has_identity:
   49:             mapper.dispatch.after_insert(mapper, connection, state)
               else:
    4:             mapper.dispatch.after_update(mapper, connection, state)
       
   53:         if (
   53:             mapper.version_id_generator is False
>>>>>>             and mapper.version_id_col is not None
               ):
>>>>>>             if state_dict[mapper._version_id_prop.key] is None:
>>>>>>                 raise orm_exc.FlushError(
>>>>>>                     "Instance does not contain a non-NULL version value"
                       )
       
       
    1: def _postfetch_post_update(
           mapper, uowtransaction, table, state, dict_, result, params
       ):
>>>>>>     needs_version_id = (
>>>>>>         mapper.version_id_col is not None
>>>>>>         and mapper.version_id_col in mapper._cols_by_table[table]
           )
       
>>>>>>     if not uowtransaction.is_deleted(state):
               # post updating after a regular INSERT or UPDATE, do a full postfetch
>>>>>>         prefetch_cols = result.context.compiled.prefetch
>>>>>>         postfetch_cols = result.context.compiled.postfetch
>>>>>>     elif needs_version_id:
               # post updating before a DELETE with a version_id_col, need to
               # postfetch just version_id_col
>>>>>>         prefetch_cols = postfetch_cols = ()
           else:
               # post updating before a DELETE without a version_id_col,
               # don't need to postfetch
>>>>>>         return
       
>>>>>>     if needs_version_id:
>>>>>>         prefetch_cols = list(prefetch_cols) + [mapper.version_id_col]
       
>>>>>>     refresh_flush = bool(mapper.class_manager.dispatch.refresh_flush)
>>>>>>     if refresh_flush:
>>>>>>         load_evt_attrs = []
       
>>>>>>     for c in prefetch_cols:
>>>>>>         if c.key in params and c in mapper._columntoproperty:
>>>>>>             dict_[mapper._columntoproperty[c].key] = params[c.key]
>>>>>>             if refresh_flush:
>>>>>>                 load_evt_attrs.append(mapper._columntoproperty[c].key)
       
>>>>>>     if refresh_flush and load_evt_attrs:
>>>>>>         mapper.class_manager.dispatch.refresh_flush(
>>>>>>             state, uowtransaction, load_evt_attrs
               )
       
>>>>>>     if postfetch_cols:
>>>>>>         state._expire_attributes(
>>>>>>             state.dict,
>>>>>>             [
>>>>>>                 mapper._columntoproperty[c].key
>>>>>>                 for c in postfetch_cols
>>>>>>                 if c in mapper._columntoproperty
                   ],
               )
       
       
    1: def _postfetch(
           mapper,
           uowtransaction,
           table,
           state,
           dict_,
           result,
           params,
           value_params,
           isupdate,
           returned_defaults,
       ):
           """Expire attributes in need of newly persisted database state,
           after an INSERT or UPDATE statement has proceeded for that
           state."""
       
   53:     prefetch_cols = result.context.compiled.prefetch
   53:     postfetch_cols = result.context.compiled.postfetch
   53:     returning_cols = result.context.compiled.effective_returning
       
   53:     if (
   53:         mapper.version_id_col is not None
>>>>>>         and mapper.version_id_col in mapper._cols_by_table[table]
           ):
>>>>>>         prefetch_cols = list(prefetch_cols) + [mapper.version_id_col]
       
   53:     refresh_flush = bool(mapper.class_manager.dispatch.refresh_flush)
   53:     if refresh_flush:
>>>>>>         load_evt_attrs = []
       
   53:     if returning_cols:
    3:         row = returned_defaults
    3:         if row is not None:
    6:             for row_value, col in zip(row, returning_cols):
                       # pk cols returned from insert are handled
                       # distinctly, don't step on the values here
    3:                 if col.primary_key and result.context.isinsert:
    3:                     continue
       
                       # note that columns can be in the "return defaults" that are
                       # not mapped to this mapper, typically because they are
                       # "excluded", which can be specified directly or also occurs
                       # when using declarative w/ single table inheritance
>>>>>>                 prop = mapper._columntoproperty.get(col)
>>>>>>                 if prop:
>>>>>>                     dict_[prop.key] = row_value
>>>>>>                     if refresh_flush:
>>>>>>                         load_evt_attrs.append(prop.key)
       
  445:     for c in prefetch_cols:
  392:         if c.key in params and c in mapper._columntoproperty:
  392:             pkey = mapper._columntoproperty[c].key
       
                   # set prefetched value in dict and also pop from committed_state,
                   # since this is new database state that replaces whatever might
                   # have previously been fetched (see #10800).  this is essentially a
                   # shorthand version of set_committed_value(), which could also be
                   # used here directly (with more overhead)
  392:             dict_[pkey] = params[c.key]
  392:             state.committed_state.pop(pkey, None)
       
  392:             if refresh_flush:
>>>>>>                 load_evt_attrs.append(pkey)
       
   53:     if refresh_flush and load_evt_attrs:
>>>>>>         mapper.class_manager.dispatch.refresh_flush(
>>>>>>             state, uowtransaction, load_evt_attrs
               )
       
   53:     if isupdate and value_params:
               # explicitly suit the use case specified by
               # [ticket:3801], PK SQL expressions for UPDATE on non-RETURNING
               # database which are set to themselves in order to do a version bump.
>>>>>>         postfetch_cols.extend(
>>>>>>             [
>>>>>>                 col
>>>>>>                 for col in value_params
>>>>>>                 if col.primary_key and col not in returning_cols
                   ]
               )
       
   53:     if postfetch_cols:
>>>>>>         state._expire_attributes(
>>>>>>             state.dict,
>>>>>>             [
>>>>>>                 mapper._columntoproperty[c].key
>>>>>>                 for c in postfetch_cols
>>>>>>                 if c in mapper._columntoproperty
                   ],
               )
       
           # synchronize newly inserted ids from one table to the next
           # TODO: this still goes a little too often.  would be nice to
           # have definitive list of "columns that changed" here
   53:     for m, equated_pairs in mapper._table_to_equated[table]:
>>>>>>         sync.populate(
>>>>>>             state,
>>>>>>             m,
>>>>>>             state,
>>>>>>             m,
>>>>>>             equated_pairs,
>>>>>>             uowtransaction,
>>>>>>             mapper.passive_updates,
               )
       
       
    1: def _postfetch_bulk_save(mapper, dict_, table):
>>>>>>     for m, equated_pairs in mapper._table_to_equated[table]:
>>>>>>         sync.bulk_populate_inherit_keys(dict_, m, equated_pairs)
       
       
    1: def _connections_for_states(base_mapper, uowtransaction, states):
           """Return an iterator of (state, state.dict, mapper, connection).
       
           The states are sorted according to _sort_states, then paired
           with the connection they should be using for the given
           unit of work transaction.
       
           """
           # if session has a connection callable,
           # organize individual states with the connection
           # to use for update
   81:     if uowtransaction.session.connection_callable:
>>>>>>         connection_callable = uowtransaction.session.connection_callable
           else:
   81:         connection = uowtransaction.transaction.connection(base_mapper)
   81:         connection_callable = None
       
  135:     for state in _sort_states(base_mapper, states):
   54:         if connection_callable:
>>>>>>             connection = connection_callable(base_mapper, state.obj())
       
   54:         mapper = state.manager.mapper
       
   54:         yield state, state.dict, mapper, connection
       
       
    1: def _sort_states(mapper, states):
   81:     pending = set(states)
  216:     persistent = {s for s in pending if s.key is not None}
   81:     pending.difference_update(persistent)
       
   81:     try:
  162:         persistent_sorted = sorted(
   81:             persistent, key=mapper._persistent_sortkey_fn
               )
>>>>>>     except TypeError as err:
>>>>>>         raise sa_exc.InvalidRequestError(
>>>>>>             "Could not sort objects by primary key; primary key "
>>>>>>             "values must be sortable in Python (was: %s)" % err
>>>>>>         ) from err
   81:     return (
  162:         sorted(pending, key=operator.attrgetter("insert_order"))
   81:         + persistent_sorted
           )
