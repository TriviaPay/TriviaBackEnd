    1: """Convert python types to pydantic-core schema."""
    1: from __future__ import annotations as _annotations
       
    1: import collections.abc
    1: import dataclasses
    1: import inspect
    1: import re
    1: import sys
    1: import typing
    1: import warnings
    1: from contextlib import contextmanager
    1: from copy import copy, deepcopy
    1: from enum import Enum
    1: from functools import partial
    1: from inspect import Parameter, _ParameterKind, signature
    1: from itertools import chain
    1: from operator import attrgetter
    1: from types import FunctionType, LambdaType, MethodType
    1: from typing import (
           TYPE_CHECKING,
           Any,
           Callable,
           Dict,
           Final,
           ForwardRef,
           Iterable,
           Iterator,
           Mapping,
           Type,
           TypeVar,
           Union,
           cast,
           overload,
       )
    1: from warnings import warn
       
    1: from pydantic_core import CoreSchema, PydanticUndefined, core_schema, to_jsonable_python
    1: from typing_extensions import Annotated, Literal, TypeAliasType, TypedDict, get_args, get_origin, is_typeddict
       
    1: from ..aliases import AliasGenerator
    1: from ..annotated_handlers import GetCoreSchemaHandler, GetJsonSchemaHandler
    1: from ..config import ConfigDict, JsonDict, JsonEncoder
    1: from ..errors import PydanticSchemaGenerationError, PydanticUndefinedAnnotation, PydanticUserError
    1: from ..json_schema import JsonSchemaValue
    1: from ..version import version_short
    1: from ..warnings import PydanticDeprecatedSince20
    1: from . import _core_utils, _decorators, _discriminated_union, _known_annotated_metadata, _typing_extra
    1: from ._config import ConfigWrapper, ConfigWrapperStack
    1: from ._core_metadata import CoreMetadataHandler, build_metadata_dict
    1: from ._core_utils import (
           NEEDS_APPLY_DISCRIMINATED_UNION_METADATA_KEY,
           CoreSchemaOrField,
           collect_invalid_schemas,
           define_expected_missing_refs,
           get_ref,
           get_type_ref,
           is_function_with_inner_schema,
           is_list_like_schema_with_items_schema,
           simplify_schema_references,
           validate_core_schema,
       )
    1: from ._decorators import (
           Decorator,
           DecoratorInfos,
           FieldSerializerDecoratorInfo,
           FieldValidatorDecoratorInfo,
           ModelSerializerDecoratorInfo,
           ModelValidatorDecoratorInfo,
           RootValidatorDecoratorInfo,
           ValidatorDecoratorInfo,
           get_attribute_from_bases,
           inspect_field_serializer,
           inspect_model_serializer,
           inspect_validator,
       )
    1: from ._fields import collect_dataclass_fields, get_type_hints_infer_globalns
    1: from ._forward_ref import PydanticRecursiveRef
    1: from ._generics import get_standard_typevars_map, has_instance_in_type, recursively_defined_type_refs, replace_types
    1: from ._schema_generation_shared import (
           CallbackGetCoreSchemaHandler,
       )
    1: from ._typing_extra import is_finalvar
    1: from ._utils import lenient_issubclass
       
    1: if TYPE_CHECKING:
>>>>>>     from ..fields import ComputedFieldInfo, FieldInfo
>>>>>>     from ..main import BaseModel
>>>>>>     from ..types import Discriminator
>>>>>>     from ..validators import FieldValidatorModes
>>>>>>     from ._dataclasses import StandardDataclass
>>>>>>     from ._schema_generation_shared import GetJsonSchemaFunction
       
    1: _SUPPORTS_TYPEDDICT = sys.version_info >= (3, 12)
    1: _AnnotatedType = type(Annotated[int, 123])
       
    1: FieldDecoratorInfo = Union[ValidatorDecoratorInfo, FieldValidatorDecoratorInfo, FieldSerializerDecoratorInfo]
    1: FieldDecoratorInfoType = TypeVar('FieldDecoratorInfoType', bound=FieldDecoratorInfo)
    2: AnyFieldDecorator = Union[
    2:     Decorator[ValidatorDecoratorInfo],
    1:     Decorator[FieldValidatorDecoratorInfo],
    1:     Decorator[FieldSerializerDecoratorInfo],
       ]
       
    1: ModifyCoreSchemaWrapHandler = GetCoreSchemaHandler
    1: GetCoreSchemaFunction = Callable[[Any, ModifyCoreSchemaWrapHandler], core_schema.CoreSchema]
       
       
    1: TUPLE_TYPES: list[type] = [tuple, typing.Tuple]
    1: LIST_TYPES: list[type] = [list, typing.List, collections.abc.MutableSequence]
    1: SET_TYPES: list[type] = [set, typing.Set, collections.abc.MutableSet]
    1: FROZEN_SET_TYPES: list[type] = [frozenset, typing.FrozenSet, collections.abc.Set]
    1: DICT_TYPES: list[type] = [dict, typing.Dict, collections.abc.MutableMapping, collections.abc.Mapping]
       
       
    1: def check_validator_fields_against_field_name(
           info: FieldDecoratorInfo,
           field: str,
       ) -> bool:
           """Check if field name is in validator fields.
       
           Args:
               info: The field info.
               field: The field name to check.
       
           Returns:
               `True` if field name is in validator fields, `False` otherwise.
           """
>>>>>>     if isinstance(info, (ValidatorDecoratorInfo, FieldValidatorDecoratorInfo)):
>>>>>>         if '*' in info.fields:
>>>>>>             return True
>>>>>>     for v_field_name in info.fields:
>>>>>>         if v_field_name == field:
>>>>>>             return True
>>>>>>     return False
       
       
    1: def check_decorator_fields_exist(decorators: Iterable[AnyFieldDecorator], fields: Iterable[str]) -> None:
           """Check if the defined fields in decorators exist in `fields` param.
       
           It ignores the check for a decorator if the decorator has `*` as field or `check_fields=False`.
       
           Args:
               decorators: An iterable of decorators.
               fields: An iterable of fields name.
       
           Raises:
               PydanticUserError: If one of the field names does not exist in `fields` param.
           """
   78:     fields = set(fields)
   78:     for dec in decorators:
>>>>>>         if isinstance(dec.info, (ValidatorDecoratorInfo, FieldValidatorDecoratorInfo)) and '*' in dec.info.fields:
>>>>>>             continue
>>>>>>         if dec.info.check_fields is False:
>>>>>>             continue
>>>>>>         for field in dec.info.fields:
>>>>>>             if field not in fields:
>>>>>>                 raise PydanticUserError(
>>>>>>                     f'Decorators defined with incorrect fields: {dec.cls_ref}.{dec.cls_var_name}'
                           " (use check_fields=False if you're inheriting from the model and intended this)",
>>>>>>                     code='decorator-missing-field',
                       )
       
       
    1: def filter_field_decorator_info_by_field(
           validator_functions: Iterable[Decorator[FieldDecoratorInfoType]], field: str
       ) -> list[Decorator[FieldDecoratorInfoType]]:
 7152:     return [dec for dec in validator_functions if check_validator_fields_against_field_name(dec.info, field)]
       
       
    1: def apply_each_item_validators(
           schema: core_schema.CoreSchema,
           each_item_validators: list[Decorator[ValidatorDecoratorInfo]],
           field_name: str | None,
       ) -> core_schema.CoreSchema:
           # This V1 compatibility shim should eventually be removed
       
           # push down any `each_item=True` validators
           # note that this won't work for any Annotated types that get wrapped by a function validator
           # but that's okay because that didn't exist in V1
 1734:     if schema['type'] == 'nullable':
  840:         schema['schema'] = apply_each_item_validators(schema['schema'], each_item_validators, field_name)
  840:         return schema
  894:     elif schema['type'] == 'tuple':
>>>>>>         if (variadic_item_index := schema.get('variadic_item_index')) is not None:
>>>>>>             schema['items_schema'][variadic_item_index] = apply_validators(
>>>>>>                 schema['items_schema'][variadic_item_index], each_item_validators, field_name
                   )
  894:     elif is_list_like_schema_with_items_schema(schema):
   80:         inner_schema = schema.get('items_schema', None)
   80:         if inner_schema is None:
   18:             inner_schema = core_schema.any_schema()
   80:         schema['items_schema'] = apply_validators(inner_schema, each_item_validators, field_name)
  814:     elif schema['type'] == 'dict':
               # push down any `each_item=True` validators onto dict _values_
               # this is super arbitrary but it's the V1 behavior
  105:         inner_schema = schema.get('values_schema', None)
  105:         if inner_schema is None:
>>>>>>             inner_schema = core_schema.any_schema()
  105:         schema['values_schema'] = apply_validators(inner_schema, each_item_validators, field_name)
  709:     elif each_item_validators:
>>>>>>         raise TypeError(
>>>>>>             f"`@validator(..., each_item=True)` cannot be applied to fields with a schema of {schema['type']}"
               )
  894:     return schema
       
       
    1: def modify_model_json_schema(
           schema_or_field: CoreSchemaOrField, handler: GetJsonSchemaHandler, *, cls: Any
       ) -> JsonSchemaValue:
           """Add title and description for model-like classes' JSON schema.
       
           Args:
               schema_or_field: The schema data to generate a JSON schema from.
               handler: The `GetCoreSchemaHandler` instance.
               cls: The model-like class.
       
           Returns:
               JsonSchemaValue: The updated JSON schema.
           """
>>>>>>     from ..main import BaseModel
       
>>>>>>     json_schema = handler(schema_or_field)
>>>>>>     original_schema = handler.resolve_ref_schema(json_schema)
           # Preserve the fact that definitions schemas should never have sibling keys:
>>>>>>     if '$ref' in original_schema:
>>>>>>         ref = original_schema['$ref']
>>>>>>         original_schema.clear()
>>>>>>         original_schema['allOf'] = [{'$ref': ref}]
>>>>>>     if 'title' not in original_schema:
>>>>>>         original_schema['title'] = cls.__name__
           # BaseModel; don't use cls.__doc__ as it will contain the verbose class signature by default
>>>>>>     docstring = None if cls is BaseModel else cls.__doc__
>>>>>>     if docstring and 'description' not in original_schema:
>>>>>>         original_schema['description'] = inspect.cleandoc(docstring)
>>>>>>     return json_schema
       
       
    1: JsonEncoders = Dict[Type[Any], JsonEncoder]
       
       
    1: def _add_custom_serialization_from_json_encoders(
           json_encoders: JsonEncoders | None, tp: Any, schema: CoreSchema
       ) -> CoreSchema:
           """Iterate over the json_encoders and add the first matching encoder to the schema.
       
           Args:
               json_encoders: A dictionary of types and their encoder functions.
               tp: The type to check for a matching encoder.
               schema: The schema to add the encoder to.
           """
 2900:     if not json_encoders:
 2900:         return schema
>>>>>>     if 'serialization' in schema:
>>>>>>         return schema
           # Check the class type and its superclasses for a matching encoder
           # Decimal.__class__.__mro__ (and probably other cases) doesn't include Decimal itself
           # if the type is a GenericAlias (e.g. from list[int]) we need to use __class__ instead of .__mro__
>>>>>>     for base in (tp, *getattr(tp, '__mro__', tp.__class__.__mro__)[:-1]):
>>>>>>         encoder = json_encoders.get(base)
>>>>>>         if encoder is None:
>>>>>>             continue
       
>>>>>>         warnings.warn(
>>>>>>             f'`json_encoders` is deprecated. See https://docs.pydantic.dev/{version_short()}/concepts/serialization/#custom-serializers for alternatives',
>>>>>>             PydanticDeprecatedSince20,
               )
       
               # TODO: in theory we should check that the schema accepts a serialization key
>>>>>>         schema['serialization'] = core_schema.plain_serializer_function_ser_schema(encoder, when_used='json')
>>>>>>         return schema
       
>>>>>>     return schema
       
       
    1: TypesNamespace = Union[Dict[str, Any], None]
       
       
    2: class TypesNamespaceStack:
    1:     """A stack of types namespaces."""
       
    1:     def __init__(self, types_namespace: TypesNamespace):
  150:         self._types_namespace_stack: list[TypesNamespace] = [types_namespace]
       
    1:     @property
    1:     def tail(self) -> TypesNamespace:
  128:         return self._types_namespace_stack[-1]
       
    1:     @contextmanager
    1:     def push(self, for_type: type[Any]):
   86:         types_namespace = {**_typing_extra.get_cls_types_namespace(for_type), **(self.tail or {})}
   86:         self._types_namespace_stack.append(types_namespace)
   86:         try:
   86:             yield
               finally:
   86:             self._types_namespace_stack.pop()
       
       
    2: class GenerateSchema:
    1:     """Generate core schema for a Pydantic model, dataclass and types like `str`, `datetime`, ... ."""
       
    1:     __slots__ = (
               '_config_wrapper_stack',
               '_types_namespace_stack',
               '_typevars_map',
               '_needs_apply_discriminated_union',
               '_has_invalid_schema',
               'field_name_stack',
               'defs',
           )
       
    1:     def __init__(
               self,
               config_wrapper: ConfigWrapper,
               types_namespace: dict[str, Any] | None,
               typevars_map: dict[Any, Any] | None = None,
           ) -> None:
               # we need a stack for recursing into child models
  150:         self._config_wrapper_stack = ConfigWrapperStack(config_wrapper)
  150:         self._types_namespace_stack = TypesNamespaceStack(types_namespace)
  150:         self._typevars_map = typevars_map
  150:         self._needs_apply_discriminated_union = False
  150:         self._has_invalid_schema = False
  150:         self.field_name_stack = _FieldNameStack()
  150:         self.defs = _Definitions()
       
    1:     @classmethod
    1:     def __from_parent(
               cls,
               config_wrapper_stack: ConfigWrapperStack,
               types_namespace_stack: TypesNamespaceStack,
               typevars_map: dict[Any, Any] | None,
               defs: _Definitions,
           ) -> GenerateSchema:
   86:         obj = cls.__new__(cls)
   86:         obj._config_wrapper_stack = config_wrapper_stack
   86:         obj._types_namespace_stack = types_namespace_stack
   86:         obj._typevars_map = typevars_map
   86:         obj._needs_apply_discriminated_union = False
   86:         obj._has_invalid_schema = False
   86:         obj.field_name_stack = _FieldNameStack()
   86:         obj.defs = defs
   86:         return obj
       
    1:     @property
    1:     def _config_wrapper(self) -> ConfigWrapper:
21783:         return self._config_wrapper_stack.tail
       
    1:     @property
    1:     def _types_namespace(self) -> dict[str, Any] | None:
   42:         return self._types_namespace_stack.tail
       
    1:     @property
    1:     def _current_generate_schema(self) -> GenerateSchema:
   86:         cls = self._config_wrapper.schema_generator or GenerateSchema
  172:         return cls.__from_parent(
   86:             self._config_wrapper_stack,
   86:             self._types_namespace_stack,
   86:             self._typevars_map,
   86:             self.defs,
               )
       
    1:     @property
    1:     def _arbitrary_types(self) -> bool:
>>>>>>         return self._config_wrapper.arbitrary_types_allowed
       
    1:     def str_schema(self) -> CoreSchema:
               """Generate a CoreSchema for `str`"""
  481:         return core_schema.str_schema()
       
           # the following methods can be overridden but should be considered
           # unstable / private APIs
    1:     def _list_schema(self, tp: Any, items_type: Any) -> CoreSchema:
>>>>>>         return core_schema.list_schema(self.generate_schema(items_type))
       
    1:     def _dict_schema(self, tp: Any, keys_type: Any, values_type: Any) -> CoreSchema:
>>>>>>         return core_schema.dict_schema(self.generate_schema(keys_type), self.generate_schema(values_type))
       
    1:     def _set_schema(self, tp: Any, items_type: Any) -> CoreSchema:
>>>>>>         return core_schema.set_schema(self.generate_schema(items_type))
       
    1:     def _frozenset_schema(self, tp: Any, items_type: Any) -> CoreSchema:
>>>>>>         return core_schema.frozenset_schema(self.generate_schema(items_type))
       
    1:     def _arbitrary_type_schema(self, tp: Any) -> CoreSchema:
>>>>>>         if not isinstance(tp, type):
>>>>>>             warn(
>>>>>>                 f'{tp!r} is not a Python type (it may be an instance of an object),'
                       ' Pydantic will allow any object with no validation since we cannot even'
                       ' enforce that the input is an instance of the given type.'
                       ' To get rid of this error wrap the type with `pydantic.SkipValidation`.',
>>>>>>                 UserWarning,
                   )
>>>>>>             return core_schema.any_schema()
>>>>>>         return core_schema.is_instance_schema(tp)
       
    1:     def _unknown_type_schema(self, obj: Any) -> CoreSchema:
>>>>>>         raise PydanticSchemaGenerationError(
>>>>>>             f'Unable to generate pydantic-core schema for {obj!r}. '
                   'Set `arbitrary_types_allowed=True` in the model_config to ignore this error'
                   ' or implement `__get_pydantic_core_schema__` on your type to fully support it.'
                   '\n\nIf you got this error by calling handler(<some type>) within'
                   ' `__get_pydantic_core_schema__` then you likely need to call'
                   ' `handler.generate_schema(<some type>)` since we do not call'
                   ' `__get_pydantic_core_schema__` on `<some type>` otherwise to avoid infinite recursion.'
               )
       
    1:     def _apply_discriminator_to_union(
               self, schema: CoreSchema, discriminator: str | Discriminator | None
           ) -> CoreSchema:
>>>>>>         if discriminator is None:
>>>>>>             return schema
>>>>>>         try:
>>>>>>             return _discriminated_union.apply_discriminator(
>>>>>>                 schema,
>>>>>>                 discriminator,
                   )
>>>>>>         except _discriminated_union.MissingDefinitionForUnionRef:
                   # defer until defs are resolved
>>>>>>             _discriminated_union.set_discriminator(
>>>>>>                 schema,
>>>>>>                 discriminator,
                   )
>>>>>>             if 'metadata' in schema:
>>>>>>                 schema['metadata'][NEEDS_APPLY_DISCRIMINATED_UNION_METADATA_KEY] = True
                   else:
>>>>>>                 schema['metadata'] = {NEEDS_APPLY_DISCRIMINATED_UNION_METADATA_KEY: True}
>>>>>>             self._needs_apply_discriminated_union = True
>>>>>>             return schema
       
    2:     class CollectedInvalid(Exception):
    1:         pass
       
    1:     def clean_schema(self, schema: CoreSchema) -> CoreSchema:
  144:         schema = self.collect_definitions(schema)
  144:         schema = simplify_schema_references(schema)
  144:         schema = _discriminated_union.apply_discriminators(schema)
  144:         if collect_invalid_schemas(schema):
>>>>>>             raise self.CollectedInvalid()
  144:         schema = validate_core_schema(schema)
  144:         return schema
       
    1:     def collect_definitions(self, schema: CoreSchema) -> CoreSchema:
  144:         ref = cast('str | None', schema.get('ref', None))
  144:         if ref:
   44:             self.defs.definitions[ref] = schema
  144:         if 'ref' in schema:
   44:             schema = core_schema.definition_reference_schema(schema['ref'])
  288:         return core_schema.definitions_schema(
  144:             schema,
  144:             list(self.defs.definitions.values()),
               )
       
    1:     def _add_js_function(self, metadata_schema: CoreSchema, js_function: Callable[..., Any]) -> None:
  252:         metadata = CoreMetadataHandler(metadata_schema).metadata
  252:         pydantic_js_functions = metadata.setdefault('pydantic_js_functions', [])
               # because of how we generate core schemas for nested generic models
               # we can end up adding `BaseModel.__get_pydantic_json_schema__` multiple times
               # this check may fail to catch duplicates if the function is a `functools.partial`
               # or something like that
               # but if it does it'll fail by inserting the duplicate
  252:         if js_function not in pydantic_js_functions:
   68:             pydantic_js_functions.append(js_function)
       
    1:     def generate_schema(
               self,
               obj: Any,
               from_dunder_get_core_schema: bool = True,
           ) -> core_schema.CoreSchema:
               """Generate core schema.
       
               Args:
                   obj: The object to generate core schema for.
                   from_dunder_get_core_schema: Whether to generate schema from either the
                       `__get_pydantic_core_schema__` function or `__pydantic_core_schema__` property.
       
               Returns:
                   The generated core schema.
       
               Raises:
                   PydanticUndefinedAnnotation:
                       If it is not possible to evaluate forward reference.
                   PydanticSchemaGenerationError:
                       If it is not possible to generate pydantic-core schema.
                   TypeError:
                       - If `alias_generator` returns a disallowed type (must be str, AliasPath or AliasChoices).
                       - If V1 style validator with `each_item=True` applied on a wrong field.
                   PydanticUserError:
                       - If `typing.TypedDict` is used instead of `typing_extensions.TypedDict` on Python < 3.12.
                       - If `__modify_schema__` method is used instead of `__get_pydantic_json_schema__`.
               """
 1717:         schema: CoreSchema | None = None
       
 1717:         if from_dunder_get_core_schema:
 1667:             from_property = self._generate_schema_from_property(obj, obj)
 1662:             if from_property is not None:
  363:                 schema = from_property
       
 1712:         if schema is None:
 1349:             schema = self._generate_schema(obj)
       
 1687:         metadata_js_function = _extract_get_pydantic_json_schema(obj, schema)
 1687:         if metadata_js_function is not None:
  399:             metadata_schema = resolve_original_schema(schema, self.defs.definitions)
  399:             if metadata_schema:
  217:                 self._add_js_function(metadata_schema, metadata_js_function)
       
 1687:         schema = _add_custom_serialization_from_json_encoders(self._config_wrapper.json_encoders, obj, schema)
       
 1687:         schema = self._post_process_generated_schema(schema)
       
 1687:         return schema
       
    1:     def _model_schema(self, cls: type[BaseModel]) -> core_schema.CoreSchema:
               """Generate schema for a Pydantic model."""
   78:         with self.defs.get_schema_or_ref(cls) as (model_ref, maybe_schema):
   78:             if maybe_schema is not None:
>>>>>>                 return maybe_schema
       
   78:             fields = cls.model_fields
   78:             decorators = cls.__pydantic_decorators__
   78:             computed_fields = decorators.computed_fields
  156:             check_decorator_fields_exist(
  156:                 chain(
   78:                     decorators.field_validators.values(),
   78:                     decorators.field_serializers.values(),
   78:                     decorators.validators.values(),
                       ),
   78:                 {*fields.keys(), *computed_fields.keys()},
                   )
   78:             config_wrapper = ConfigWrapper(cls.model_config, check=False)
   78:             core_config = config_wrapper.core_config(cls)
   78:             metadata = build_metadata_dict(js_functions=[partial(modify_model_json_schema, cls=cls)])
       
   78:             model_validators = decorators.model_validators.values()
       
   78:             extras_schema = None
   78:             if core_config.get('extra_fields_behavior') == 'allow':
  336:                 for tp in (cls, *cls.__mro__):
  272:                     extras_annotation = cls.__annotations__.get('__pydantic_extra__', None)
  272:                     if extras_annotation is not None:
>>>>>>                         tp = get_origin(extras_annotation)
>>>>>>                         if tp not in (Dict, dict):
>>>>>>                             raise PydanticSchemaGenerationError(
>>>>>>                                 'The type annotation for `__pydantic_extra__` must be `Dict[str, ...]`'
                                   )
>>>>>>                         extra_items_type = self._get_args_resolving_forward_refs(
>>>>>>                             cls.__annotations__['__pydantic_extra__'],
>>>>>>                             required=True,
>>>>>>                         )[1]
>>>>>>                         if extra_items_type is not Any:
>>>>>>                             extras_schema = self.generate_schema(extra_items_type)
>>>>>>                             break
       
   78:             with self._config_wrapper_stack.push(config_wrapper), self._types_namespace_stack.push(cls):
   78:                 self = self._current_generate_schema
   78:                 if cls.__pydantic_root_model__:
>>>>>>                     root_field = self._common_field_schema('root', fields['root'], decorators)
>>>>>>                     inner_schema = root_field['schema']
>>>>>>                     inner_schema = apply_model_validators(inner_schema, model_validators, 'inner')
>>>>>>                     model_schema = core_schema.model_schema(
>>>>>>                         cls,
>>>>>>                         inner_schema,
>>>>>>                         custom_init=getattr(cls, '__pydantic_custom_init__', None),
>>>>>>                         root_model=True,
>>>>>>                         post_init=getattr(cls, '__pydantic_post_init__', None),
>>>>>>                         config=core_config,
>>>>>>                         ref=model_ref,
>>>>>>                         metadata=metadata,
                           )
                       else:
  145:                     fields_schema: core_schema.CoreSchema = core_schema.model_fields_schema(
 1018:                         {k: self._generate_md_field_schema(k, v, decorators) for k, v in fields.items()},
  201:                         computed_fields=[
>>>>>>                             self._computed_field_schema(d, decorators.field_serializers)
   67:                             for d in computed_fields.values()
                               ],
   67:                         extras_schema=extras_schema,
   67:                         model_name=cls.__name__,
                           )
   67:                     inner_schema = apply_validators(fields_schema, decorators.root_validators.values(), None)
   67:                     new_inner_schema = define_expected_missing_refs(inner_schema, recursively_defined_type_refs())
   67:                     if new_inner_schema is not None:
>>>>>>                         inner_schema = new_inner_schema
   67:                     inner_schema = apply_model_validators(inner_schema, model_validators, 'inner')
       
  134:                     model_schema = core_schema.model_schema(
   67:                         cls,
   67:                         inner_schema,
   67:                         custom_init=getattr(cls, '__pydantic_custom_init__', None),
   67:                         root_model=False,
   67:                         post_init=getattr(cls, '__pydantic_post_init__', None),
   67:                         config=core_config,
   67:                         ref=model_ref,
   67:                         metadata=metadata,
                           )
       
   67:                 schema = self._apply_model_serializers(model_schema, decorators.model_serializers.values())
   67:                 schema = apply_model_validators(schema, model_validators, 'outer')
   67:                 self.defs.definitions[model_ref] = self._post_process_generated_schema(schema)
  100:                 return core_schema.definition_reference_schema(model_ref)
       
    1:     def _unpack_refs_defs(self, schema: CoreSchema) -> CoreSchema:
               """Unpack all 'definitions' schemas into `GenerateSchema.defs.definitions`
               and return the inner schema.
               """
       
  134:         def get_ref(s: CoreSchema) -> str:
  203:             return s['ref']  # type: ignore
       
  134:         if schema['type'] == 'definitions':
  241:             self.defs.definitions.update({get_ref(s): s for s in schema['definitions']})
   19:             schema = schema['schema']
  134:         return schema
       
    1:     def _generate_schema_from_property(self, obj: Any, source: Any) -> core_schema.CoreSchema | None:
               """Try to generate schema from either the `__get_pydantic_core_schema__` function or
               `__pydantic_core_schema__` property.
       
               Note: `__get_pydantic_core_schema__` takes priority so it can
               decide whether to use a `__pydantic_core_schema__` attribute, or generate a fresh schema.
               """
               # avoid calling `__get_pydantic_core_schema__` if we've already visited this object
 3647:         with self.defs.get_schema_or_ref(obj) as (_, maybe_schema):
 3647:             if maybe_schema is not None:
  264:                 return maybe_schema
 3383:         if obj is source:
 2400:             ref_mode = 'unpack'
               else:
  983:             ref_mode = 'to-def'
       
               schema: CoreSchema
 3383:         get_schema = getattr(obj, '__get_pydantic_core_schema__', None)
 3383:         if get_schema is None:
 3244:             validators = getattr(obj, '__get_validators__', None)
 3244:             if validators is None:
 3244:                 return None
>>>>>>             warn(
>>>>>>                 '`__get_validators__` is deprecated and will be removed, use `__get_pydantic_core_schema__` instead.',
>>>>>>                 PydanticDeprecatedSince20,
                   )
>>>>>>             schema = core_schema.chain_schema([core_schema.with_info_plain_validator_function(v) for v in validators()])
               else:
  139:             if len(inspect.signature(get_schema).parameters) == 1:
                       # (source) -> CoreSchema
>>>>>>                 schema = get_schema(source)
                   else:
  278:                 schema = get_schema(
  139:                     source, CallbackGetCoreSchemaHandler(self._generate_schema, self, ref_mode=ref_mode)
                       )
       
  134:         schema = self._unpack_refs_defs(schema)
       
  134:         if is_function_with_inner_schema(schema):
    1:             ref = schema['schema'].pop('ref', None)  # pyright: ignore[reportGeneralTypeIssues]
    1:             if ref:
>>>>>>                 schema['ref'] = ref
               else:
  133:             ref = get_ref(schema)
       
  134:         if ref:
  123:             self.defs.definitions[ref] = self._post_process_generated_schema(schema)
  123:             return core_schema.definition_reference_schema(ref)
       
   11:         schema = self._post_process_generated_schema(schema)
       
   11:         return schema
       
    1:     def _resolve_forward_ref(self, obj: Any) -> Any:
               # we assume that types_namespace has the target of forward references in its scope,
               # but this could fail, for example, if calling Validator on an imported type which contains
               # forward references to other types only defined in the module from which it was imported
               # `Validator(SomeImportedTypeAliasWithAForwardReference)`
               # or the equivalent for BaseModel
               # class Model(BaseModel):
               #   x: SomeImportedTypeAliasWithAForwardReference
    6:         try:
    6:             obj = _typing_extra.eval_type_backport(obj, globalns=self._types_namespace)
    6:         except NameError as e:
   12:             raise PydanticUndefinedAnnotation.from_name_error(e) from e
       
               # if obj is still a ForwardRef, it means we can't evaluate it, raise PydanticUndefinedAnnotation
>>>>>>         if isinstance(obj, ForwardRef):
>>>>>>             raise PydanticUndefinedAnnotation(obj.__forward_arg__, f'Unable to evaluate forward reference {obj}')
       
>>>>>>         if self._typevars_map:
>>>>>>             obj = replace_types(obj, self._typevars_map)
       
>>>>>>         return obj
       
    1:     @overload
    1:     def _get_args_resolving_forward_refs(self, obj: Any, required: Literal[True]) -> tuple[Any, ...]:
>>>>>>         ...
       
    1:     @overload
    1:     def _get_args_resolving_forward_refs(self, obj: Any) -> tuple[Any, ...] | None:
>>>>>>         ...
       
    1:     def _get_args_resolving_forward_refs(self, obj: Any, required: bool = False) -> tuple[Any, ...] | None:
 1083:         args = get_args(obj)
 1083:         if args:
 4456:             args = tuple([self._resolve_forward_ref(a) if isinstance(a, ForwardRef) else a for a in args])
>>>>>>         elif required:  # pragma: no cover
>>>>>>             raise TypeError(f'Expected {obj} to have generic parameters but it had none')
 1079:         return args
       
    1:     def _get_first_arg_or_any(self, obj: Any) -> Any:
>>>>>>         args = self._get_args_resolving_forward_refs(obj)
>>>>>>         if not args:
>>>>>>             return Any
>>>>>>         return args[0]
       
    1:     def _get_first_two_args_or_any(self, obj: Any) -> tuple[Any, Any]:
>>>>>>         args = self._get_args_resolving_forward_refs(obj)
>>>>>>         if not args:
>>>>>>             return (Any, Any)
>>>>>>         if len(args) < 2:
>>>>>>             origin = get_origin(obj)
>>>>>>             raise TypeError(f'Expected two type arguments for {origin}, got 1')
>>>>>>         return args[0], args[1]
       
    1:     def _post_process_generated_schema(self, schema: core_schema.CoreSchema) -> core_schema.CoreSchema:
 4194:         if 'metadata' in schema:
 1632:             metadata = schema['metadata']
 1632:             metadata[NEEDS_APPLY_DISCRIMINATED_UNION_METADATA_KEY] = self._needs_apply_discriminated_union
               else:
 2562:             schema['metadata'] = {
 2562:                 NEEDS_APPLY_DISCRIMINATED_UNION_METADATA_KEY: self._needs_apply_discriminated_union,
                   }
 4194:         return schema
       
    1:     def _generate_schema(self, obj: Any) -> core_schema.CoreSchema:
               """Recursively generate a pydantic-core schema for any supported python type."""
 2339:         has_invalid_schema = self._has_invalid_schema
 2339:         self._has_invalid_schema = False
 2339:         needs_apply_discriminated_union = self._needs_apply_discriminated_union
 2339:         self._needs_apply_discriminated_union = False
 2339:         schema = self._post_process_generated_schema(self._generate_schema_inner(obj))
 2298:         self._has_invalid_schema = self._has_invalid_schema or has_invalid_schema
 2298:         self._needs_apply_discriminated_union = self._needs_apply_discriminated_union or needs_apply_discriminated_union
 2298:         return schema
       
    1:     def _generate_schema_inner(self, obj: Any) -> core_schema.CoreSchema:
 2339:         if isinstance(obj, _AnnotatedType):
  100:             return self._annotated_schema(obj)
       
 2239:         if isinstance(obj, dict):
                   # we assume this is already a valid schema
>>>>>>             return obj  # type: ignore[return-value]
       
 2239:         if isinstance(obj, str):
>>>>>>             obj = ForwardRef(obj)
       
 2239:         if isinstance(obj, ForwardRef):
    2:             return self.generate_schema(self._resolve_forward_ref(obj))
       
 2237:         from ..main import BaseModel
       
 2237:         if lenient_issubclass(obj, BaseModel):
   78:             return self._model_schema(obj)
       
 2159:         if isinstance(obj, PydanticRecursiveRef):
>>>>>>             return core_schema.definition_reference_schema(schema_ref=obj.type_ref)
       
 2159:         return self.match_type(obj)
       
    1:     def match_type(self, obj: Any) -> core_schema.CoreSchema:  # noqa: C901
               """Main mapping of types to schemas.
       
               The general structure is a series of if statements starting with the simple cases
               (non-generic primitive types) and then handling generics and other more complex cases.
       
               Each case either generates a schema directly, calls into a public user-overridable method
               (like `GenerateSchema.tuple_variable_schema`) or calls into a private method that handles some
               boilerplate before calling into the user-facing method (e.g. `GenerateSchema._tuple_schema`).
       
               The idea is that we'll evolve this into adding more and more user facing methods over time
               as they get requested and we figure out what the right API for them is.
               """
 2159:         if obj is str:
  481:             return self.str_schema()
 1678:         elif obj is bytes:
>>>>>>             return core_schema.bytes_schema()
 1678:         elif obj is int:
   81:             return core_schema.int_schema()
 1597:         elif obj is float:
   45:             return core_schema.float_schema()
 1552:         elif obj is bool:
  261:             return core_schema.bool_schema()
 1291:         elif obj is Any or obj is object:
   57:             return core_schema.any_schema()
 1234:         elif obj is None or obj is _typing_extra.NoneType:
>>>>>>             return core_schema.none_schema()
 1234:         elif obj in TUPLE_TYPES:
>>>>>>             return self._tuple_schema(obj)
 1234:         elif obj in LIST_TYPES:
>>>>>>             return self._list_schema(obj, self._get_first_arg_or_any(obj))
 1234:         elif obj in SET_TYPES:
>>>>>>             return self._set_schema(obj, self._get_first_arg_or_any(obj))
 1234:         elif obj in FROZEN_SET_TYPES:
>>>>>>             return self._frozenset_schema(obj, self._get_first_arg_or_any(obj))
 1234:         elif obj in DICT_TYPES:
>>>>>>             return self._dict_schema(obj, *self._get_first_two_args_or_any(obj))
 1234:         elif isinstance(obj, TypeAliasType):
>>>>>>             return self._type_alias_type_schema(obj)
 1234:         elif obj == type:
>>>>>>             return self._type_schema()
 1234:         elif _typing_extra.is_callable_type(obj):
>>>>>>             return core_schema.callable_schema()
 1234:         elif _typing_extra.is_literal_type(obj):
    1:             return self._literal_schema(obj)
 1233:         elif is_typeddict(obj):
    8:             return self._typed_dict_schema(obj, None)
 1225:         elif _typing_extra.is_namedtuple(obj):
>>>>>>             return self._namedtuple_schema(obj, None)
 1225:         elif _typing_extra.is_new_type(obj):
                   # NewType, can't use isinstance because it fails <3.10
>>>>>>             return self.generate_schema(obj.__supertype__)
 1225:         elif obj == re.Pattern:
>>>>>>             return self._pattern_schema(obj)
 1225:         elif obj is collections.abc.Hashable or obj is typing.Hashable:
>>>>>>             return self._hashable_schema()
 1225:         elif isinstance(obj, typing.TypeVar):
>>>>>>             return self._unsubstituted_typevar_schema(obj)
 1225:         elif is_finalvar(obj):
>>>>>>             if obj is Final:
>>>>>>                 return core_schema.any_schema()
>>>>>>             return self.generate_schema(
>>>>>>                 self._get_first_arg_or_any(obj),
                   )
 1225:         elif isinstance(obj, (FunctionType, LambdaType, MethodType, partial)):
>>>>>>             return self._callable_schema(obj)
 1225:         elif inspect.isclass(obj) and issubclass(obj, Enum):
   11:             from ._std_types_schema import get_enum_core_schema
       
   11:             return get_enum_core_schema(obj, self._config_wrapper.config_dict)
       
 1214:         if _typing_extra.is_dataclass(obj):
>>>>>>             return self._dataclass_schema(obj, None)
       
 1214:         res = self._get_prepare_pydantic_annotations_for_known_type(obj, ())
 1214:         if res is not None:
  231:             source_type, annotations = res
  231:             return self._apply_annotations(source_type, annotations)
       
  983:         origin = get_origin(obj)
  983:         if origin is not None:
  983:             return self._match_generic_type(obj, origin)
       
>>>>>>         if self._arbitrary_types:
>>>>>>             return self._arbitrary_type_schema(obj)
>>>>>>         return self._unknown_type_schema(obj)
       
    1:     def _match_generic_type(self, obj: Any, origin: Any) -> CoreSchema:  # noqa: C901
  983:         if isinstance(origin, TypeAliasType):
>>>>>>             return self._type_alias_type_schema(obj)
       
               # Need to handle generic dataclasses before looking for the schema properties because attribute accesses
               # on _GenericAlias delegate to the origin type, so lose the information about the concrete parametrization
               # As a result, currently, there is no way to cache the schema for generic dataclasses. This may be possible
               # to resolve by modifying the value returned by `Generic.__class_getitem__`, but that is a dangerous game.
  983:         if _typing_extra.is_dataclass(origin):
>>>>>>             return self._dataclass_schema(obj, origin)
  983:         if _typing_extra.is_namedtuple(origin):
>>>>>>             return self._namedtuple_schema(obj, origin)
       
  983:         from_property = self._generate_schema_from_property(origin, obj)
  983:         if from_property is not None:
>>>>>>             return from_property
       
  983:         if _typing_extra.origin_is_union(origin):
  983:             return self._union_schema(obj)
>>>>>>         elif origin in TUPLE_TYPES:
>>>>>>             return self._tuple_schema(obj)
>>>>>>         elif origin in LIST_TYPES:
>>>>>>             return self._list_schema(obj, self._get_first_arg_or_any(obj))
>>>>>>         elif origin in SET_TYPES:
>>>>>>             return self._set_schema(obj, self._get_first_arg_or_any(obj))
>>>>>>         elif origin in FROZEN_SET_TYPES:
>>>>>>             return self._frozenset_schema(obj, self._get_first_arg_or_any(obj))
>>>>>>         elif origin in DICT_TYPES:
>>>>>>             return self._dict_schema(obj, *self._get_first_two_args_or_any(obj))
>>>>>>         elif is_typeddict(origin):
>>>>>>             return self._typed_dict_schema(obj, origin)
>>>>>>         elif origin in (typing.Type, type):
>>>>>>             return self._subclass_schema(obj)
>>>>>>         elif origin in {typing.Sequence, collections.abc.Sequence}:
>>>>>>             return self._sequence_schema(obj)
>>>>>>         elif origin in {typing.Iterable, collections.abc.Iterable, typing.Generator, collections.abc.Generator}:
>>>>>>             return self._iterable_schema(obj)
>>>>>>         elif origin in (re.Pattern, typing.Pattern):
>>>>>>             return self._pattern_schema(obj)
       
>>>>>>         if self._arbitrary_types:
>>>>>>             return self._arbitrary_type_schema(origin)
>>>>>>         return self._unknown_type_schema(obj)
       
    1:     def _generate_td_field_schema(
               self,
               name: str,
               field_info: FieldInfo,
               decorators: DecoratorInfos,
               *,
    1:         required: bool = True,
           ) -> core_schema.TypedDictField:
               """Prepare a TypedDictField to represent a model or typeddict field."""
   32:         common_field = self._common_field_schema(name, field_info, decorators)
   64:         return core_schema.typed_dict_field(
   32:             common_field['schema'],
   32:             required=False if not field_info.is_required() else required,
   32:             serialization_exclude=common_field['serialization_exclude'],
   32:             validation_alias=common_field['validation_alias'],
   32:             serialization_alias=common_field['serialization_alias'],
   32:             metadata=common_field['metadata'],
               )
       
    1:     def _generate_md_field_schema(
               self,
               name: str,
               field_info: FieldInfo,
               decorators: DecoratorInfos,
           ) -> core_schema.ModelField:
               """Prepare a ModelField to represent a model field."""
  873:         common_field = self._common_field_schema(name, field_info, decorators)
 1724:         return core_schema.model_field(
  862:             common_field['schema'],
  862:             serialization_exclude=common_field['serialization_exclude'],
  862:             validation_alias=common_field['validation_alias'],
  862:             serialization_alias=common_field['serialization_alias'],
  862:             frozen=common_field['frozen'],
  862:             metadata=common_field['metadata'],
               )
       
    1:     def _generate_dc_field_schema(
               self,
               name: str,
               field_info: FieldInfo,
               decorators: DecoratorInfos,
           ) -> core_schema.DataclassField:
               """Prepare a DataclassField to represent the parameter/field, of a dataclass."""
>>>>>>         common_field = self._common_field_schema(name, field_info, decorators)
>>>>>>         return core_schema.dataclass_field(
>>>>>>             name,
>>>>>>             common_field['schema'],
>>>>>>             init=field_info.init,
>>>>>>             init_only=field_info.init_var or None,
>>>>>>             kw_only=None if field_info.kw_only else False,
>>>>>>             serialization_exclude=common_field['serialization_exclude'],
>>>>>>             validation_alias=common_field['validation_alias'],
>>>>>>             serialization_alias=common_field['serialization_alias'],
>>>>>>             frozen=common_field['frozen'],
>>>>>>             metadata=common_field['metadata'],
               )
       
    1:     @staticmethod
    1:     def _apply_alias_generator_to_field_info(
               alias_generator: Callable[[str], str] | AliasGenerator, field_info: FieldInfo, field_name: str
           ) -> None:
               """Apply an alias_generator to aliases on a FieldInfo instance if appropriate.
       
               Args:
                   alias_generator: A callable that takes a string and returns a string, or an AliasGenerator instance.
                   field_info: The FieldInfo instance to which the alias_generator is (maybe) applied.
                   field_name: The name of the field from which to generate the alias.
               """
               # Apply an alias_generator if
               # 1. An alias is not specified
               # 2. An alias is specified, but the priority is <= 1
>>>>>>         if alias_generator and (
>>>>>>             field_info.alias_priority is None
>>>>>>             or field_info.alias_priority <= 1
>>>>>>             or field_info.alias is None
>>>>>>             or field_info.validation_alias is None
>>>>>>             or field_info.serialization_alias is None
               ):
>>>>>>             alias, validation_alias, serialization_alias = None, None, None
       
>>>>>>             if isinstance(alias_generator, AliasGenerator):
>>>>>>                 alias, validation_alias, serialization_alias = alias_generator.generate_aliases(field_name)
>>>>>>             elif isinstance(alias_generator, Callable):
>>>>>>                 alias = alias_generator(field_name)
>>>>>>                 if not isinstance(alias, str):
>>>>>>                     raise TypeError(f'alias_generator {alias_generator} must return str, not {alias.__class__}')
       
                   # if priority is not set, we set to 1
                   # which supports the case where the alias_generator from a child class is used
                   # to generate an alias for a field in a parent class
>>>>>>             if field_info.alias_priority is None or field_info.alias_priority <= 1:
>>>>>>                 field_info.alias_priority = 1
       
                   # if the priority is 1, then we set the aliases to the generated alias
>>>>>>             if field_info.alias_priority == 1:
>>>>>>                 field_info.serialization_alias = serialization_alias or alias
>>>>>>                 field_info.validation_alias = validation_alias or alias
>>>>>>                 field_info.alias = alias
       
                   # if any of the aliases are not set, then we set them to the corresponding generated alias
>>>>>>             if field_info.alias is None:
>>>>>>                 field_info.alias = alias
>>>>>>             if field_info.serialization_alias is None:
>>>>>>                 field_info.serialization_alias = serialization_alias or alias
>>>>>>             if field_info.validation_alias is None:
>>>>>>                 field_info.validation_alias = validation_alias or alias
       
    1:     def _common_field_schema(  # C901
               self, name: str, field_info: FieldInfo, decorators: DecoratorInfos
           ) -> _CommonField:
               # Update FieldInfo annotation if appropriate:
  905:         from .. import AliasChoices, AliasPath
  905:         from ..fields import FieldInfo
       
  905:         if has_instance_in_type(field_info.annotation, (ForwardRef, str)):
   28:             types_namespace = self._types_namespace
   28:             if self._typevars_map:
>>>>>>                 types_namespace = (types_namespace or {}).copy()
                       # Ensure that typevars get mapped to their concrete types:
>>>>>>                 types_namespace.update({k.__name__: v for k, v in self._typevars_map.items()})
       
   28:             evaluated = _typing_extra.eval_type_lenient(field_info.annotation, types_namespace)
   28:             if evaluated is not field_info.annotation and not has_instance_in_type(evaluated, PydanticRecursiveRef):
   21:                 new_field_info = FieldInfo.from_annotation(evaluated)
   21:                 field_info.annotation = new_field_info.annotation
       
                       # Handle any field info attributes that may have been obtained from now-resolved annotations
   63:                 for k, v in new_field_info._attributes_set.items():
                           # If an attribute is already set, it means it was set by assigning to a call to Field (or just a
                           # default value), and that should take the highest priority. So don't overwrite existing attributes.
                           # We skip over "attributes" that are present in the metadata_lookup dict because these won't
                           # actually end up as attributes of the `FieldInfo` instance.
   42:                     if k not in field_info._attributes_set and k not in field_info.metadata_lookup:
    4:                         setattr(field_info, k, v)
       
                       # Finally, ensure the field info also reflects all the `_attributes_set` that are actually metadata.
   21:                 field_info.metadata = [*new_field_info.metadata, *field_info.metadata]
       
  905:         source_type, annotations = field_info.annotation, field_info.metadata
       
  905:         def set_discriminator(schema: CoreSchema) -> CoreSchema:
>>>>>>             schema = self._apply_discriminator_to_union(schema, field_info.discriminator)
>>>>>>             return schema
       
  905:         with self.field_name_stack.push(name):
  905:             if field_info.discriminator is not None:
>>>>>>                 schema = self._apply_annotations(source_type, annotations, transform_inner_schema=set_discriminator)
                   else:
 1810:                 schema = self._apply_annotations(
  905:                     source_type,
  905:                     annotations,
                       )
       
               # This V1 compatibility shim should eventually be removed
               # push down any `each_item=True` validators
               # note that this won't work for any Annotated types that get wrapped by a function validator
               # but that's okay because that didn't exist in V1
  894:         this_field_validators = filter_field_decorator_info_by_field(decorators.validators.values(), name)
  894:         if _validators_require_validate_default(this_field_validators):
>>>>>>             field_info.validate_default = True
 1788:         each_item_validators = [v for v in this_field_validators if v.info.each_item is True]
 1788:         this_field_validators = [v for v in this_field_validators if v not in each_item_validators]
  894:         schema = apply_each_item_validators(schema, each_item_validators, name)
       
  894:         schema = apply_validators(schema, filter_field_decorator_info_by_field(this_field_validators, name), name)
 1788:         schema = apply_validators(
  894:             schema, filter_field_decorator_info_by_field(decorators.field_validators.values(), name), name
               )
       
               # the default validator needs to go outside of any other validators
               # so that it is the topmost validator for the field validator
               # which uses it to check if the field has a default value or not
  894:         if not field_info.is_required():
  819:             schema = wrap_default(field_info, schema)
       
 1788:         schema = self._apply_field_serializers(
  894:             schema, filter_field_decorator_info_by_field(decorators.field_serializers.values(), name)
               )
  894:         json_schema_updates = {
  894:             'title': field_info.title,
  894:             'description': field_info.description,
  894:             'examples': to_jsonable_python(field_info.examples),
               }
 4470:         json_schema_updates = {k: v for k, v in json_schema_updates.items() if v is not None}
       
  894:         json_schema_extra = field_info.json_schema_extra
       
 1788:         metadata = build_metadata_dict(
  894:             js_annotation_functions=[get_json_schema_update_func(json_schema_updates, json_schema_extra)]
               )
       
  894:         alias_generator = self._config_wrapper.alias_generator
  894:         if alias_generator is not None:
>>>>>>             self._apply_alias_generator_to_field_info(alias_generator, field_info, name)
       
  894:         if isinstance(field_info.validation_alias, (AliasChoices, AliasPath)):
>>>>>>             validation_alias = field_info.validation_alias.convert_to_aliases()
               else:
  894:             validation_alias = field_info.validation_alias
       
 1788:         return _common_field(
  894:             schema,
  894:             serialization_exclude=True if field_info.exclude else None,
  894:             validation_alias=validation_alias,
  894:             serialization_alias=field_info.serialization_alias,
  894:             frozen=field_info.frozen,
  894:             metadata=metadata,
               )
       
    1:     def _union_schema(self, union_type: Any) -> core_schema.CoreSchema:
               """Generate schema for a Union."""
  983:         args = self._get_args_resolving_forward_refs(union_type, required=True)
  979:         choices: list[CoreSchema] = []
  979:         nullable = False
 3045:         for arg in args:
 2078:             if arg is None or arg is _typing_extra.NoneType:
  840:                 nullable = True
                   else:
 1238:                 choices.append(self.generate_schema(arg))
       
  967:         if len(choices) == 1:
  722:             s = choices[0]
               else:
  245:             choices_with_tags: list[CoreSchema | tuple[CoreSchema, str]] = []
  749:             for choice in choices:
  504:                 metadata = choice.get('metadata')
  504:                 if isinstance(metadata, dict):
  504:                     tag = metadata.get(_core_utils.TAGGED_UNION_TAG_KEY)
  504:                     if tag is not None:
>>>>>>                         choices_with_tags.append((choice, tag))
                           else:
  504:                         choices_with_tags.append(choice)
  245:             s = core_schema.union_schema(choices_with_tags)
       
  967:         if nullable:
  840:             s = core_schema.nullable_schema(s)
  967:         return s
       
    1:     def _type_alias_type_schema(
               self,
               obj: Any,  # TypeAliasType
           ) -> CoreSchema:
>>>>>>         with self.defs.get_schema_or_ref(obj) as (ref, maybe_schema):
>>>>>>             if maybe_schema is not None:
>>>>>>                 return maybe_schema
       
>>>>>>             origin = get_origin(obj) or obj
       
>>>>>>             annotation = origin.__value__
>>>>>>             typevars_map = get_standard_typevars_map(obj)
       
>>>>>>             with self._types_namespace_stack.push(origin):
>>>>>>                 annotation = _typing_extra.eval_type_lenient(annotation, self._types_namespace)
>>>>>>                 annotation = replace_types(annotation, typevars_map)
>>>>>>                 schema = self.generate_schema(annotation)
>>>>>>                 assert schema['type'] != 'definitions'
>>>>>>                 schema['ref'] = ref  # type: ignore
>>>>>>             self.defs.definitions[ref] = schema
>>>>>>             return core_schema.definition_reference_schema(ref)
       
    1:     def _literal_schema(self, literal_type: Any) -> CoreSchema:
               """Generate schema for a Literal."""
    1:         expected = _typing_extra.all_literal_values(literal_type)
    1:         assert expected, f'literal "expected" cannot be empty, obj={literal_type}'
    1:         return core_schema.literal_schema(expected)
       
    1:     def _typed_dict_schema(self, typed_dict_cls: Any, origin: Any) -> core_schema.CoreSchema:
               """Generate schema for a TypedDict.
       
               It is not possible to track required/optional keys in TypedDict without __required_keys__
               since TypedDict.__new__ erases the base classes (it replaces them with just `dict`)
               and thus we can track usage of total=True/False
               __required_keys__ was added in Python 3.9
               (https://github.com/miss-islington/cpython/blob/1e9939657dd1f8eb9f596f77c1084d2d351172fc/Doc/library/typing.rst?plain=1#L1546-L1548)
               however it is buggy
               (https://github.com/python/typing_extensions/blob/ac52ac5f2cb0e00e7988bae1e2a1b8257ac88d6d/src/typing_extensions.py#L657-L666).
       
               On 3.11 but < 3.12 TypedDict does not preserve inheritance information.
       
               Hence to avoid creating validators that do not do what users expect we only
               support typing.TypedDict on Python >= 3.12 or typing_extension.TypedDict on all versions
               """
    8:         from ..fields import FieldInfo
       
    8:         with self.defs.get_schema_or_ref(typed_dict_cls) as (typed_dict_ref, maybe_schema):
    8:             if maybe_schema is not None:
>>>>>>                 return maybe_schema
       
    8:             typevars_map = get_standard_typevars_map(typed_dict_cls)
    8:             if origin is not None:
>>>>>>                 typed_dict_cls = origin
       
    8:             if not _SUPPORTS_TYPEDDICT and type(typed_dict_cls).__module__ == 'typing':
>>>>>>                 raise PydanticUserError(
>>>>>>                     'Please use `typing_extensions.TypedDict` instead of `typing.TypedDict` on Python < 3.12.',
>>>>>>                     code='typed-dict-version',
                       )
       
    8:             try:
    8:                 config: ConfigDict | None = get_attribute_from_bases(typed_dict_cls, '__pydantic_config__')
>>>>>>             except AttributeError:
>>>>>>                 config = None
       
    8:             with self._config_wrapper_stack.push(config), self._types_namespace_stack.push(typed_dict_cls):
    8:                 core_config = self._config_wrapper.core_config(typed_dict_cls)
       
    8:                 self = self._current_generate_schema
       
    8:                 required_keys: frozenset[str] = typed_dict_cls.__required_keys__
       
    8:                 fields: dict[str, core_schema.TypedDictField] = {}
       
    8:                 decorators = DecoratorInfos.build(typed_dict_cls)
       
   48:                 for field_name, annotation in get_type_hints_infer_globalns(
    8:                     typed_dict_cls, localns=self._types_namespace, include_extras=True
                       ).items():
   32:                     annotation = replace_types(annotation, typevars_map)
   32:                     required = field_name in required_keys
       
   32:                     if get_origin(annotation) == _typing_extra.Required:
>>>>>>                         required = True
>>>>>>                         annotation = self._get_args_resolving_forward_refs(
>>>>>>                             annotation,
>>>>>>                             required=True,
>>>>>>                         )[0]
   32:                     elif get_origin(annotation) == _typing_extra.NotRequired:
>>>>>>                         required = False
>>>>>>                         annotation = self._get_args_resolving_forward_refs(
>>>>>>                             annotation,
>>>>>>                             required=True,
>>>>>>                         )[0]
       
   32:                     field_info = FieldInfo.from_annotation(annotation)
   64:                     fields[field_name] = self._generate_td_field_schema(
   32:                         field_name, field_info, decorators, required=required
                           )
       
   16:                 metadata = build_metadata_dict(
    8:                     js_functions=[partial(modify_model_json_schema, cls=typed_dict_cls)], typed_dict_cls=typed_dict_cls
                       )
       
   16:                 td_schema = core_schema.typed_dict_schema(
    8:                     fields,
   24:                     computed_fields=[
>>>>>>                         self._computed_field_schema(d, decorators.field_serializers)
    8:                         for d in decorators.computed_fields.values()
                           ],
    8:                     ref=typed_dict_ref,
    8:                     metadata=metadata,
    8:                     config=core_config,
                       )
       
    8:                 schema = self._apply_model_serializers(td_schema, decorators.model_serializers.values())
    8:                 schema = apply_model_validators(schema, decorators.model_validators.values(), 'all')
    8:                 self.defs.definitions[typed_dict_ref] = self._post_process_generated_schema(schema)
    8:                 return core_schema.definition_reference_schema(typed_dict_ref)
       
    1:     def _namedtuple_schema(self, namedtuple_cls: Any, origin: Any) -> core_schema.CoreSchema:
               """Generate schema for a NamedTuple."""
>>>>>>         with self.defs.get_schema_or_ref(namedtuple_cls) as (namedtuple_ref, maybe_schema):
>>>>>>             if maybe_schema is not None:
>>>>>>                 return maybe_schema
>>>>>>             typevars_map = get_standard_typevars_map(namedtuple_cls)
>>>>>>             if origin is not None:
>>>>>>                 namedtuple_cls = origin
       
>>>>>>             annotations: dict[str, Any] = get_type_hints_infer_globalns(
>>>>>>                 namedtuple_cls, include_extras=True, localns=self._types_namespace
                   )
>>>>>>             if not annotations:
                       # annotations is empty, happens if namedtuple_cls defined via collections.namedtuple(...)
>>>>>>                 annotations = {k: Any for k in namedtuple_cls._fields}
       
>>>>>>             if typevars_map:
>>>>>>                 annotations = {
>>>>>>                     field_name: replace_types(annotation, typevars_map)
>>>>>>                     for field_name, annotation in annotations.items()
                       }
       
>>>>>>             arguments_schema = core_schema.arguments_schema(
>>>>>>                 [
>>>>>>                     self._generate_parameter_schema(
>>>>>>                         field_name, annotation, default=namedtuple_cls._field_defaults.get(field_name, Parameter.empty)
                           )
>>>>>>                     for field_name, annotation in annotations.items()
                       ],
>>>>>>                 metadata=build_metadata_dict(js_prefer_positional_arguments=True),
                   )
>>>>>>             return core_schema.call_schema(arguments_schema, namedtuple_cls, ref=namedtuple_ref)
       
    1:     def _generate_parameter_schema(
               self,
               name: str,
               annotation: type[Any],
    1:         default: Any = Parameter.empty,
    1:         mode: Literal['positional_only', 'positional_or_keyword', 'keyword_only'] | None = None,
           ) -> core_schema.ArgumentsParameter:
               """Prepare a ArgumentsParameter to represent a field in a namedtuple or function signature."""
>>>>>>         from ..fields import FieldInfo
       
>>>>>>         if default is Parameter.empty:
>>>>>>             field = FieldInfo.from_annotation(annotation)
               else:
>>>>>>             field = FieldInfo.from_annotated_attribute(annotation, default)
>>>>>>         assert field.annotation is not None, 'field.annotation should not be None when generating a schema'
>>>>>>         source_type, annotations = field.annotation, field.metadata
>>>>>>         with self.field_name_stack.push(name):
>>>>>>             schema = self._apply_annotations(source_type, annotations)
       
>>>>>>         if not field.is_required():
>>>>>>             schema = wrap_default(field, schema)
       
>>>>>>         parameter_schema = core_schema.arguments_parameter(name, schema)
>>>>>>         if mode is not None:
>>>>>>             parameter_schema['mode'] = mode
>>>>>>         if field.alias is not None:
>>>>>>             parameter_schema['alias'] = field.alias
               else:
>>>>>>             alias_generator = self._config_wrapper.alias_generator
>>>>>>             if isinstance(alias_generator, AliasGenerator) and alias_generator.alias is not None:
>>>>>>                 parameter_schema['alias'] = alias_generator.alias(name)
>>>>>>             elif isinstance(alias_generator, Callable):
>>>>>>                 parameter_schema['alias'] = alias_generator(name)
>>>>>>         return parameter_schema
       
    1:     def _tuple_schema(self, tuple_type: Any) -> core_schema.CoreSchema:
               """Generate schema for a Tuple, e.g. `tuple[int, str]` or `tuple[int, ...]`."""
               # TODO: do we really need to resolve type vars here?
>>>>>>         typevars_map = get_standard_typevars_map(tuple_type)
>>>>>>         params = self._get_args_resolving_forward_refs(tuple_type)
       
>>>>>>         if typevars_map and params:
>>>>>>             params = tuple(replace_types(param, typevars_map) for param in params)
       
               # NOTE: subtle difference: `tuple[()]` gives `params=()`, whereas `typing.Tuple[()]` gives `params=((),)`
               # This is only true for <3.11, on Python 3.11+ `typing.Tuple[()]` gives `params=()`
>>>>>>         if not params:
>>>>>>             if tuple_type in TUPLE_TYPES:
>>>>>>                 return core_schema.tuple_schema([core_schema.any_schema()], variadic_item_index=0)
                   else:
                       # special case for `tuple[()]` which means `tuple[]` - an empty tuple
>>>>>>                 return core_schema.tuple_schema([])
>>>>>>         elif params[-1] is Ellipsis:
>>>>>>             if len(params) == 2:
>>>>>>                 return core_schema.tuple_schema([self.generate_schema(params[0])], variadic_item_index=0)
                   else:
                       # TODO: something like https://github.com/pydantic/pydantic/issues/5952
>>>>>>                 raise ValueError('Variable tuples can only have one type')
>>>>>>         elif len(params) == 1 and params[0] == ():
                   # special case for `Tuple[()]` which means `Tuple[]` - an empty tuple
                   # NOTE: This conditional can be removed when we drop support for Python 3.10.
>>>>>>             return core_schema.tuple_schema([])
               else:
>>>>>>             return core_schema.tuple_schema([self.generate_schema(param) for param in params])
       
    1:     def _type_schema(self) -> core_schema.CoreSchema:
>>>>>>         return core_schema.custom_error_schema(
>>>>>>             core_schema.is_instance_schema(type),
>>>>>>             custom_error_type='is_type',
>>>>>>             custom_error_message='Input should be a type',
               )
       
    1:     def _union_is_subclass_schema(self, union_type: Any) -> core_schema.CoreSchema:
               """Generate schema for `Type[Union[X, ...]]`."""
>>>>>>         args = self._get_args_resolving_forward_refs(union_type, required=True)
>>>>>>         return core_schema.union_schema([self.generate_schema(typing.Type[args]) for args in args])
       
    1:     def _subclass_schema(self, type_: Any) -> core_schema.CoreSchema:
               """Generate schema for a Type, e.g. `Type[int]`."""
>>>>>>         type_param = self._get_first_arg_or_any(type_)
>>>>>>         if type_param == Any:
>>>>>>             return self._type_schema()
>>>>>>         elif isinstance(type_param, typing.TypeVar):
>>>>>>             if type_param.__bound__:
>>>>>>                 if _typing_extra.origin_is_union(get_origin(type_param.__bound__)):
>>>>>>                     return self._union_is_subclass_schema(type_param.__bound__)
>>>>>>                 return core_schema.is_subclass_schema(type_param.__bound__)
>>>>>>             elif type_param.__constraints__:
>>>>>>                 return core_schema.union_schema(
>>>>>>                     [self.generate_schema(typing.Type[c]) for c in type_param.__constraints__]
                       )
                   else:
>>>>>>                 return self._type_schema()
>>>>>>         elif _typing_extra.origin_is_union(get_origin(type_param)):
>>>>>>             return self._union_is_subclass_schema(type_param)
               else:
>>>>>>             return core_schema.is_subclass_schema(type_param)
       
    1:     def _sequence_schema(self, sequence_type: Any) -> core_schema.CoreSchema:
               """Generate schema for a Sequence, e.g. `Sequence[int]`."""
>>>>>>         item_type = self._get_first_arg_or_any(sequence_type)
       
>>>>>>         list_schema = core_schema.list_schema(self.generate_schema(item_type))
>>>>>>         python_schema = core_schema.is_instance_schema(typing.Sequence, cls_repr='Sequence')
>>>>>>         if item_type != Any:
>>>>>>             from ._validators import sequence_validator
       
>>>>>>             python_schema = core_schema.chain_schema(
>>>>>>                 [python_schema, core_schema.no_info_wrap_validator_function(sequence_validator, list_schema)],
                   )
>>>>>>         return core_schema.json_or_python_schema(json_schema=list_schema, python_schema=python_schema)
       
    1:     def _iterable_schema(self, type_: Any) -> core_schema.GeneratorSchema:
               """Generate a schema for an `Iterable`."""
>>>>>>         item_type = self._get_first_arg_or_any(type_)
       
>>>>>>         return core_schema.generator_schema(self.generate_schema(item_type))
       
    1:     def _pattern_schema(self, pattern_type: Any) -> core_schema.CoreSchema:
>>>>>>         from . import _validators
       
>>>>>>         metadata = build_metadata_dict(js_functions=[lambda _1, _2: {'type': 'string', 'format': 'regex'}])
>>>>>>         ser = core_schema.plain_serializer_function_ser_schema(
>>>>>>             attrgetter('pattern'), when_used='json', return_schema=core_schema.str_schema()
               )
>>>>>>         if pattern_type == typing.Pattern or pattern_type == re.Pattern:
                   # bare type
>>>>>>             return core_schema.no_info_plain_validator_function(
>>>>>>                 _validators.pattern_either_validator, serialization=ser, metadata=metadata
                   )
       
>>>>>>         param = self._get_args_resolving_forward_refs(
>>>>>>             pattern_type,
>>>>>>             required=True,
>>>>>>         )[0]
>>>>>>         if param == str:
>>>>>>             return core_schema.no_info_plain_validator_function(
>>>>>>                 _validators.pattern_str_validator, serialization=ser, metadata=metadata
                   )
>>>>>>         elif param == bytes:
>>>>>>             return core_schema.no_info_plain_validator_function(
>>>>>>                 _validators.pattern_bytes_validator, serialization=ser, metadata=metadata
                   )
               else:
>>>>>>             raise PydanticSchemaGenerationError(f'Unable to generate pydantic-core schema for {pattern_type!r}.')
       
    1:     def _hashable_schema(self) -> core_schema.CoreSchema:
>>>>>>         return core_schema.custom_error_schema(
>>>>>>             core_schema.is_instance_schema(collections.abc.Hashable),
>>>>>>             custom_error_type='is_hashable',
>>>>>>             custom_error_message='Input should be hashable',
               )
       
    1:     def _dataclass_schema(
               self, dataclass: type[StandardDataclass], origin: type[StandardDataclass] | None
           ) -> core_schema.CoreSchema:
               """Generate schema for a dataclass."""
>>>>>>         with self.defs.get_schema_or_ref(dataclass) as (dataclass_ref, maybe_schema):
>>>>>>             if maybe_schema is not None:
>>>>>>                 return maybe_schema
       
>>>>>>             typevars_map = get_standard_typevars_map(dataclass)
>>>>>>             if origin is not None:
>>>>>>                 dataclass = origin
       
>>>>>>             config = getattr(dataclass, '__pydantic_config__', None)
>>>>>>             with self._config_wrapper_stack.push(config), self._types_namespace_stack.push(dataclass):
>>>>>>                 core_config = self._config_wrapper.core_config(dataclass)
       
>>>>>>                 self = self._current_generate_schema
       
>>>>>>                 from ..dataclasses import is_pydantic_dataclass
       
>>>>>>                 if is_pydantic_dataclass(dataclass):
>>>>>>                     fields = deepcopy(dataclass.__pydantic_fields__)
>>>>>>                     if typevars_map:
>>>>>>                         for field in fields.values():
>>>>>>                             field.apply_typevars_map(typevars_map, self._types_namespace)
                       else:
>>>>>>                     fields = collect_dataclass_fields(
>>>>>>                         dataclass,
>>>>>>                         self._types_namespace,
>>>>>>                         typevars_map=typevars_map,
                           )
       
                       # disallow combination of init=False on a dataclass field and extra='allow' on a dataclass
>>>>>>                 if config and config.get('extra') == 'allow':
                           # disallow combination of init=False on a dataclass field and extra='allow' on a dataclass
>>>>>>                     for field_name, field in fields.items():
>>>>>>                         if field.init is False:
>>>>>>                             raise PydanticUserError(
>>>>>>                                 f'Field {field_name} has `init=False` and dataclass has config setting `extra="allow"`. '
                                       f'This combination is not allowed.',
>>>>>>                                 code='dataclass-init-false-extra-allow',
                                   )
       
>>>>>>                 decorators = dataclass.__dict__.get('__pydantic_decorators__') or DecoratorInfos.build(dataclass)
                       # Move kw_only=False args to the start of the list, as this is how vanilla dataclasses work.
                       # Note that when kw_only is missing or None, it is treated as equivalent to kw_only=True
>>>>>>                 args = sorted(
>>>>>>                     (self._generate_dc_field_schema(k, v, decorators) for k, v in fields.items()),
>>>>>>                     key=lambda a: a.get('kw_only') is not False,
                       )
>>>>>>                 has_post_init = hasattr(dataclass, '__post_init__')
>>>>>>                 has_slots = hasattr(dataclass, '__slots__')
       
>>>>>>                 args_schema = core_schema.dataclass_args_schema(
>>>>>>                     dataclass.__name__,
>>>>>>                     args,
>>>>>>                     computed_fields=[
>>>>>>                         self._computed_field_schema(d, decorators.field_serializers)
>>>>>>                         for d in decorators.computed_fields.values()
                           ],
>>>>>>                     collect_init_only=has_post_init,
                       )
       
>>>>>>                 inner_schema = apply_validators(args_schema, decorators.root_validators.values(), None)
       
>>>>>>                 model_validators = decorators.model_validators.values()
>>>>>>                 inner_schema = apply_model_validators(inner_schema, model_validators, 'inner')
       
>>>>>>                 dc_schema = core_schema.dataclass_schema(
>>>>>>                     dataclass,
>>>>>>                     inner_schema,
>>>>>>                     post_init=has_post_init,
>>>>>>                     ref=dataclass_ref,
>>>>>>                     fields=[field.name for field in dataclasses.fields(dataclass)],
>>>>>>                     slots=has_slots,
>>>>>>                     config=core_config,
                       )
>>>>>>                 schema = self._apply_model_serializers(dc_schema, decorators.model_serializers.values())
>>>>>>                 schema = apply_model_validators(schema, model_validators, 'outer')
>>>>>>                 self.defs.definitions[dataclass_ref] = self._post_process_generated_schema(schema)
>>>>>>                 return core_schema.definition_reference_schema(dataclass_ref)
       
    1:     def _callable_schema(self, function: Callable[..., Any]) -> core_schema.CallSchema:
               """Generate schema for a Callable.
       
               TODO support functional validators once we support them in Config
               """
>>>>>>         sig = signature(function)
       
>>>>>>         type_hints = _typing_extra.get_function_type_hints(function)
       
>>>>>>         mode_lookup: dict[_ParameterKind, Literal['positional_only', 'positional_or_keyword', 'keyword_only']] = {
>>>>>>             Parameter.POSITIONAL_ONLY: 'positional_only',
>>>>>>             Parameter.POSITIONAL_OR_KEYWORD: 'positional_or_keyword',
>>>>>>             Parameter.KEYWORD_ONLY: 'keyword_only',
               }
       
>>>>>>         arguments_list: list[core_schema.ArgumentsParameter] = []
>>>>>>         var_args_schema: core_schema.CoreSchema | None = None
>>>>>>         var_kwargs_schema: core_schema.CoreSchema | None = None
       
>>>>>>         for name, p in sig.parameters.items():
>>>>>>             if p.annotation is sig.empty:
>>>>>>                 annotation = Any
                   else:
>>>>>>                 annotation = type_hints[name]
       
>>>>>>             parameter_mode = mode_lookup.get(p.kind)
>>>>>>             if parameter_mode is not None:
>>>>>>                 arg_schema = self._generate_parameter_schema(name, annotation, p.default, parameter_mode)
>>>>>>                 arguments_list.append(arg_schema)
>>>>>>             elif p.kind == Parameter.VAR_POSITIONAL:
>>>>>>                 var_args_schema = self.generate_schema(annotation)
                   else:
>>>>>>                 assert p.kind == Parameter.VAR_KEYWORD, p.kind
>>>>>>                 var_kwargs_schema = self.generate_schema(annotation)
       
>>>>>>         return_schema: core_schema.CoreSchema | None = None
>>>>>>         config_wrapper = self._config_wrapper
>>>>>>         if config_wrapper.validate_return:
>>>>>>             return_hint = type_hints.get('return')
>>>>>>             if return_hint is not None:
>>>>>>                 return_schema = self.generate_schema(return_hint)
       
>>>>>>         return core_schema.call_schema(
>>>>>>             core_schema.arguments_schema(
>>>>>>                 arguments_list,
>>>>>>                 var_args_schema=var_args_schema,
>>>>>>                 var_kwargs_schema=var_kwargs_schema,
>>>>>>                 populate_by_name=config_wrapper.populate_by_name,
                   ),
>>>>>>             function,
>>>>>>             return_schema=return_schema,
               )
       
    1:     def _unsubstituted_typevar_schema(self, typevar: typing.TypeVar) -> core_schema.CoreSchema:
>>>>>>         assert isinstance(typevar, typing.TypeVar)
       
>>>>>>         bound = typevar.__bound__
>>>>>>         constraints = typevar.__constraints__
>>>>>>         default = getattr(typevar, '__default__', None)
       
>>>>>>         if (bound is not None) + (len(constraints) != 0) + (default is not None) > 1:
>>>>>>             raise NotImplementedError(
>>>>>>                 'Pydantic does not support mixing more than one of TypeVar bounds, constraints and defaults'
                   )
       
>>>>>>         if default is not None:
>>>>>>             return self.generate_schema(default)
>>>>>>         elif constraints:
>>>>>>             return self._union_schema(typing.Union[constraints])  # type: ignore
>>>>>>         elif bound:
>>>>>>             schema = self.generate_schema(bound)
>>>>>>             schema['serialization'] = core_schema.wrap_serializer_function_ser_schema(
>>>>>>                 lambda x, h: h(x), schema=core_schema.any_schema()
                   )
>>>>>>             return schema
               else:
>>>>>>             return core_schema.any_schema()
       
    1:     def _computed_field_schema(
               self,
               d: Decorator[ComputedFieldInfo],
               field_serializers: dict[str, Decorator[FieldSerializerDecoratorInfo]],
           ) -> core_schema.ComputedField:
>>>>>>         try:
>>>>>>             return_type = _decorators.get_function_return_type(d.func, d.info.return_type, self._types_namespace)
>>>>>>         except NameError as e:
>>>>>>             raise PydanticUndefinedAnnotation.from_name_error(e) from e
>>>>>>         if return_type is PydanticUndefined:
>>>>>>             raise PydanticUserError(
>>>>>>                 'Computed field is missing return type annotation or specifying `return_type`'
                       ' to the `@computed_field` decorator (e.g. `@computed_field(return_type=int|str)`)',
>>>>>>                 code='model-field-missing-annotation',
                   )
       
>>>>>>         return_type = replace_types(return_type, self._typevars_map)
               # Create a new ComputedFieldInfo so that different type parametrizations of the same
               # generic model's computed field can have different return types.
>>>>>>         d.info = dataclasses.replace(d.info, return_type=return_type)
>>>>>>         return_type_schema = self.generate_schema(return_type)
               # Apply serializers to computed field if there exist
>>>>>>         return_type_schema = self._apply_field_serializers(
>>>>>>             return_type_schema,
>>>>>>             filter_field_decorator_info_by_field(field_serializers.values(), d.cls_var_name),
>>>>>>             computed_field=True,
               )
               # Handle alias_generator using similar logic to that from
               # pydantic._internal._generate_schema.GenerateSchema._common_field_schema,
               # with field_info -> d.info and name -> d.cls_var_name
>>>>>>         alias_generator = self._config_wrapper.alias_generator
>>>>>>         if alias_generator and (d.info.alias_priority is None or d.info.alias_priority <= 1):
>>>>>>             alias = None
>>>>>>             if isinstance(alias_generator, AliasGenerator) and alias_generator.alias is not None:
>>>>>>                 alias = alias_generator.alias(d.cls_var_name)
>>>>>>             elif isinstance(alias_generator, Callable):
>>>>>>                 alias = alias_generator(d.cls_var_name)
>>>>>>             if not isinstance(alias, str):
>>>>>>                 raise TypeError(f'alias_generator {alias_generator} must return str, not {alias.__class__}')
>>>>>>             d.info.alias = alias
>>>>>>             d.info.alias_priority = 1
       
>>>>>>         def set_computed_field_metadata(schema: CoreSchemaOrField, handler: GetJsonSchemaHandler) -> JsonSchemaValue:
>>>>>>             json_schema = handler(schema)
       
>>>>>>             json_schema['readOnly'] = True
       
>>>>>>             title = d.info.title
>>>>>>             if title is not None:
>>>>>>                 json_schema['title'] = title
       
>>>>>>             description = d.info.description
>>>>>>             if description is not None:
>>>>>>                 json_schema['description'] = description
       
>>>>>>             examples = d.info.examples
>>>>>>             if examples is not None:
>>>>>>                 json_schema['examples'] = to_jsonable_python(examples)
       
>>>>>>             json_schema_extra = d.info.json_schema_extra
>>>>>>             if json_schema_extra is not None:
>>>>>>                 add_json_schema_extra(json_schema, json_schema_extra)
       
>>>>>>             return json_schema
       
>>>>>>         metadata = build_metadata_dict(js_annotation_functions=[set_computed_field_metadata])
>>>>>>         return core_schema.computed_field(
>>>>>>             d.cls_var_name, return_schema=return_type_schema, alias=d.info.alias, metadata=metadata
               )
       
    1:     def _annotated_schema(self, annotated_type: Any) -> core_schema.CoreSchema:
               """Generate schema for an Annotated type, e.g. `Annotated[int, Field(...)]` or `Annotated[int, Gt(0)]`."""
  100:         from ..fields import FieldInfo
       
  200:         source_type, *annotations = self._get_args_resolving_forward_refs(
  100:             annotated_type,
  100:             required=True,
               )
  100:         schema = self._apply_annotations(source_type, annotations)
               # put the default validator last so that TypeAdapter.get_default_value() works
               # even if there are function validators involved
  200:         for annotation in annotations:
  100:             if isinstance(annotation, FieldInfo):
  100:                 schema = wrap_default(annotation, schema)
  100:         return schema
       
    1:     def _get_prepare_pydantic_annotations_for_known_type(
               self, obj: Any, annotations: tuple[Any, ...]
           ) -> tuple[Any, list[Any]] | None:
 2450:         from ._std_types_schema import PREPARE_METHODS
       
               # Check for hashability
 2450:         try:
 2450:             hash(obj)
>>>>>>         except TypeError:
                   # obj is definitely not a known type if this fails
>>>>>>             return None
       
19864:         for gen in PREPARE_METHODS:
17884:             res = gen(obj, annotations, self._config_wrapper.config_dict)
17884:             if res is not None:
  470:                 return res
       
 1980:         return None
       
    1:     def _apply_annotations(
               self,
               source_type: Any,
               annotations: list[Any],
  987:         transform_inner_schema: Callable[[CoreSchema], CoreSchema] = lambda x: x,
           ) -> CoreSchema:
               """Apply arguments from `Annotated` or from `FieldInfo` to a schema.
       
               This gets called by `GenerateSchema._annotated_schema` but differs from it in that it does
               not expect `source_type` to be an `Annotated` object, it expects it to be  the first argument of that
               (in other words, `GenerateSchema._annotated_schema` just unpacks `Annotated`, this process it).
               """
 1236:         annotations = list(_known_annotated_metadata.expand_grouped_metadata(annotations))
 1236:         res = self._get_prepare_pydantic_annotations_for_known_type(source_type, tuple(annotations))
 1236:         if res is not None:
  239:             source_type, annotations = res
       
 1236:         pydantic_js_annotation_functions: list[GetJsonSchemaFunction] = []
       
 1236:         def inner_handler(obj: Any) -> CoreSchema:
  997:             from_property = self._generate_schema_from_property(obj, obj)
  997:             if from_property is None:
  962:                 schema = self._generate_schema(obj)
                   else:
   35:                 schema = from_property
  986:             metadata_js_function = _extract_get_pydantic_json_schema(obj, schema)
  986:             if metadata_js_function is not None:
   35:                 metadata_schema = resolve_original_schema(schema, self.defs.definitions)
   35:                 if metadata_schema is not None:
   35:                     self._add_js_function(metadata_schema, metadata_js_function)
  986:             return transform_inner_schema(schema)
       
 1236:         get_inner_schema = CallbackGetCoreSchemaHandler(inner_handler, self)
       
 1905:         for annotation in annotations:
  669:             if annotation is None:
>>>>>>                 continue
 1338:             get_inner_schema = self._get_wrapped_inner_schema(
  669:                 get_inner_schema, annotation, pydantic_js_annotation_functions
                   )
       
 1236:         schema = get_inner_schema(source_type)
 1213:         if pydantic_js_annotation_functions:
   15:             metadata = CoreMetadataHandler(schema).metadata
   15:             metadata.setdefault('pydantic_js_annotation_functions', []).extend(pydantic_js_annotation_functions)
 1213:         return _add_custom_serialization_from_json_encoders(self._config_wrapper.json_encoders, source_type, schema)
       
    1:     def _apply_single_annotation(self, schema: core_schema.CoreSchema, metadata: Any) -> core_schema.CoreSchema:
  519:         from ..fields import FieldInfo
       
  519:         if isinstance(metadata, FieldInfo):
  100:             for field_metadata in metadata.metadata:
>>>>>>                 schema = self._apply_single_annotation(schema, field_metadata)
       
  100:             if metadata.discriminator is not None:
>>>>>>                 schema = self._apply_discriminator_to_union(schema, metadata.discriminator)
  100:             return schema
       
  419:         if schema['type'] == 'nullable':
                   # for nullable schemas, metadata is automatically applied to the inner schema
   93:             inner = schema.get('schema', core_schema.any_schema())
   93:             inner = self._apply_single_annotation(inner, metadata)
   93:             if inner:
   93:                 schema['schema'] = inner
   93:             return schema
       
  326:         original_schema = schema
  326:         ref = schema.get('ref', None)
  326:         if ref is not None:
>>>>>>             schema = schema.copy()
>>>>>>             new_ref = ref + f'_{repr(metadata)}'
>>>>>>             if new_ref in self.defs.definitions:
>>>>>>                 return self.defs.definitions[new_ref]
>>>>>>             schema['ref'] = new_ref  # type: ignore
  326:         elif schema['type'] == 'definition-ref':
>>>>>>             ref = schema['schema_ref']
>>>>>>             if ref in self.defs.definitions:
>>>>>>                 schema = self.defs.definitions[ref].copy()
>>>>>>                 new_ref = ref + f'_{repr(metadata)}'
>>>>>>                 if new_ref in self.defs.definitions:
>>>>>>                     return self.defs.definitions[new_ref]
>>>>>>                 schema['ref'] = new_ref  # type: ignore
       
  326:         maybe_updated_schema = _known_annotated_metadata.apply_known_metadata(metadata, schema.copy())
       
  326:         if maybe_updated_schema is not None:
   86:             return maybe_updated_schema
  240:         return original_schema
       
    1:     def _apply_single_annotation_json_schema(
               self, schema: core_schema.CoreSchema, metadata: Any
           ) -> core_schema.CoreSchema:
  426:         from ..fields import FieldInfo
       
  426:         if isinstance(metadata, FieldInfo):
  100:             for field_metadata in metadata.metadata:
>>>>>>                 schema = self._apply_single_annotation_json_schema(schema, field_metadata)
  100:             json_schema_update: JsonSchemaValue = {}
  100:             if metadata.title:
>>>>>>                 json_schema_update['title'] = metadata.title
  100:             if metadata.description:
>>>>>>                 json_schema_update['description'] = metadata.description
  100:             if metadata.examples:
>>>>>>                 json_schema_update['examples'] = to_jsonable_python(metadata.examples)
       
  100:             json_schema_extra = metadata.json_schema_extra
  100:             if json_schema_update or json_schema_extra:
>>>>>>                 CoreMetadataHandler(schema).metadata.setdefault('pydantic_js_annotation_functions', []).append(
>>>>>>                     get_json_schema_update_func(json_schema_update, json_schema_extra)
                       )
  426:         return schema
       
    1:     def _get_wrapped_inner_schema(
               self,
               get_inner_schema: GetCoreSchemaHandler,
               annotation: Any,
               pydantic_js_annotation_functions: list[GetJsonSchemaFunction],
           ) -> CallbackGetCoreSchemaHandler:
 1338:         metadata_get_schema: GetCoreSchemaFunction = getattr(annotation, '__get_pydantic_core_schema__', None) or (
  398:             lambda source, handler: handler(source)
               )
       
  669:         def new_handler(source: Any) -> core_schema.CoreSchema:
  438:             schema = metadata_get_schema(source, get_inner_schema)
  426:             schema = self._apply_single_annotation(schema, annotation)
  426:             schema = self._apply_single_annotation_json_schema(schema, annotation)
       
  426:             metadata_js_function = _extract_get_pydantic_json_schema(annotation, schema)
  426:             if metadata_js_function is not None:
   15:                 pydantic_js_annotation_functions.append(metadata_js_function)
  426:             return schema
       
  669:         return CallbackGetCoreSchemaHandler(new_handler, self)
       
    1:     def _apply_field_serializers(
               self,
               schema: core_schema.CoreSchema,
               serializers: list[Decorator[FieldSerializerDecoratorInfo]],
               computed_field: bool = False,
           ) -> core_schema.CoreSchema:
               """Apply field serializers to a schema."""
  894:         if serializers:
>>>>>>             schema = copy(schema)
>>>>>>             if schema['type'] == 'definitions':
>>>>>>                 inner_schema = schema['schema']
>>>>>>                 schema['schema'] = self._apply_field_serializers(inner_schema, serializers)
>>>>>>                 return schema
                   else:
>>>>>>                 ref = typing.cast('str|None', schema.get('ref', None))
>>>>>>                 if ref is not None:
>>>>>>                     schema = core_schema.definition_reference_schema(ref)
       
                   # use the last serializer to make it easy to override a serializer set on a parent model
>>>>>>             serializer = serializers[-1]
>>>>>>             is_field_serializer, info_arg = inspect_field_serializer(
>>>>>>                 serializer.func, serializer.info.mode, computed_field=computed_field
                   )
       
>>>>>>             try:
>>>>>>                 return_type = _decorators.get_function_return_type(
>>>>>>                     serializer.func, serializer.info.return_type, self._types_namespace
                       )
>>>>>>             except NameError as e:
>>>>>>                 raise PydanticUndefinedAnnotation.from_name_error(e) from e
       
>>>>>>             if return_type is PydanticUndefined:
>>>>>>                 return_schema = None
                   else:
>>>>>>                 return_schema = self.generate_schema(return_type)
       
>>>>>>             if serializer.info.mode == 'wrap':
>>>>>>                 schema['serialization'] = core_schema.wrap_serializer_function_ser_schema(
>>>>>>                     serializer.func,
>>>>>>                     is_field_serializer=is_field_serializer,
>>>>>>                     info_arg=info_arg,
>>>>>>                     return_schema=return_schema,
>>>>>>                     when_used=serializer.info.when_used,
                       )
                   else:
>>>>>>                 assert serializer.info.mode == 'plain'
>>>>>>                 schema['serialization'] = core_schema.plain_serializer_function_ser_schema(
>>>>>>                     serializer.func,
>>>>>>                     is_field_serializer=is_field_serializer,
>>>>>>                     info_arg=info_arg,
>>>>>>                     return_schema=return_schema,
>>>>>>                     when_used=serializer.info.when_used,
                       )
  894:         return schema
       
    1:     def _apply_model_serializers(
               self, schema: core_schema.CoreSchema, serializers: Iterable[Decorator[ModelSerializerDecoratorInfo]]
           ) -> core_schema.CoreSchema:
               """Apply model serializers to a schema."""
   75:         ref: str | None = schema.pop('ref', None)  # type: ignore
   75:         if serializers:
>>>>>>             serializer = list(serializers)[-1]
>>>>>>             info_arg = inspect_model_serializer(serializer.func, serializer.info.mode)
       
>>>>>>             try:
>>>>>>                 return_type = _decorators.get_function_return_type(
>>>>>>                     serializer.func, serializer.info.return_type, self._types_namespace
                       )
>>>>>>             except NameError as e:
>>>>>>                 raise PydanticUndefinedAnnotation.from_name_error(e) from e
>>>>>>             if return_type is PydanticUndefined:
>>>>>>                 return_schema = None
                   else:
>>>>>>                 return_schema = self.generate_schema(return_type)
       
>>>>>>             if serializer.info.mode == 'wrap':
>>>>>>                 ser_schema: core_schema.SerSchema = core_schema.wrap_serializer_function_ser_schema(
>>>>>>                     serializer.func,
>>>>>>                     info_arg=info_arg,
>>>>>>                     return_schema=return_schema,
>>>>>>                     when_used=serializer.info.when_used,
                       )
                   else:
                       # plain
>>>>>>                 ser_schema = core_schema.plain_serializer_function_ser_schema(
>>>>>>                     serializer.func,
>>>>>>                     info_arg=info_arg,
>>>>>>                     return_schema=return_schema,
>>>>>>                     when_used=serializer.info.when_used,
                       )
>>>>>>             schema['serialization'] = ser_schema
   75:         if ref:
   75:             schema['ref'] = ref  # type: ignore
   75:         return schema
       
       
    1: _VALIDATOR_F_MATCH: Mapping[
           tuple[FieldValidatorModes, Literal['no-info', 'with-info']],
           Callable[[Callable[..., Any], core_schema.CoreSchema, str | None], core_schema.CoreSchema],
    1: ] = {
    1:     ('before', 'no-info'): lambda f, schema, _: core_schema.no_info_before_validator_function(f, schema),
    1:     ('after', 'no-info'): lambda f, schema, _: core_schema.no_info_after_validator_function(f, schema),
    1:     ('plain', 'no-info'): lambda f, _1, _2: core_schema.no_info_plain_validator_function(f),
    1:     ('wrap', 'no-info'): lambda f, schema, _: core_schema.no_info_wrap_validator_function(f, schema),
    1:     ('before', 'with-info'): lambda f, schema, field_name: core_schema.with_info_before_validator_function(
>>>>>>         f, schema, field_name=field_name
           ),
    1:     ('after', 'with-info'): lambda f, schema, field_name: core_schema.with_info_after_validator_function(
>>>>>>         f, schema, field_name=field_name
           ),
    1:     ('plain', 'with-info'): lambda f, _, field_name: core_schema.with_info_plain_validator_function(
>>>>>>         f, field_name=field_name
           ),
    1:     ('wrap', 'with-info'): lambda f, schema, field_name: core_schema.with_info_wrap_validator_function(
>>>>>>         f, schema, field_name=field_name
           ),
       }
       
       
    1: def apply_validators(
           schema: core_schema.CoreSchema,
           validators: Iterable[Decorator[RootValidatorDecoratorInfo]]
           | Iterable[Decorator[ValidatorDecoratorInfo]]
           | Iterable[Decorator[FieldValidatorDecoratorInfo]],
           field_name: str | None,
       ) -> core_schema.CoreSchema:
           """Apply validators to a schema.
       
           Args:
               schema: The schema to apply validators on.
               validators: An iterable of validators.
               field_name: The name of the field if validators are being applied to a model field.
       
           Returns:
               The updated schema.
           """
 2040:     for validator in validators:
>>>>>>         info_arg = inspect_validator(validator.func, validator.info.mode)
>>>>>>         val_type = 'with-info' if info_arg else 'no-info'
       
>>>>>>         schema = _VALIDATOR_F_MATCH[(validator.info.mode, val_type)](validator.func, schema, field_name)
 2040:     return schema
       
       
    1: def _validators_require_validate_default(validators: Iterable[Decorator[ValidatorDecoratorInfo]]) -> bool:
           """In v1, if any of the validators for a field had `always=True`, the default value would be validated.
       
           This serves as an auxiliary function for re-implementing that logic, by looping over a provided
           collection of (v1-style) ValidatorDecoratorInfo's and checking if any of them have `always=True`.
       
           We should be able to drop this function and the associated logic calling it once we drop support
           for v1-style validator decorators. (Or we can extend it and keep it if we add something equivalent
           to the v1-validator `always` kwarg to `field_validator`.)
           """
  894:     for validator in validators:
>>>>>>         if validator.info.always:
>>>>>>             return True
  894:     return False
       
       
    1: def apply_model_validators(
           schema: core_schema.CoreSchema,
           validators: Iterable[Decorator[ModelValidatorDecoratorInfo]],
           mode: Literal['inner', 'outer', 'all'],
       ) -> core_schema.CoreSchema:
           """Apply model validators to a schema.
       
           If mode == 'inner', only "before" validators are applied
           If mode == 'outer', validators other than "before" are applied
           If mode == 'all', all validators are applied
       
           Args:
               schema: The schema to apply validators on.
               validators: An iterable of validators.
               mode: The validator mode.
       
           Returns:
               The updated schema.
           """
  142:     ref: str | None = schema.pop('ref', None)  # type: ignore
  142:     for validator in validators:
>>>>>>         if mode == 'inner' and validator.info.mode != 'before':
>>>>>>             continue
>>>>>>         if mode == 'outer' and validator.info.mode == 'before':
>>>>>>             continue
>>>>>>         info_arg = inspect_validator(validator.func, validator.info.mode)
>>>>>>         if validator.info.mode == 'wrap':
>>>>>>             if info_arg:
>>>>>>                 schema = core_schema.with_info_wrap_validator_function(function=validator.func, schema=schema)
                   else:
>>>>>>                 schema = core_schema.no_info_wrap_validator_function(function=validator.func, schema=schema)
>>>>>>         elif validator.info.mode == 'before':
>>>>>>             if info_arg:
>>>>>>                 schema = core_schema.with_info_before_validator_function(function=validator.func, schema=schema)
                   else:
>>>>>>                 schema = core_schema.no_info_before_validator_function(function=validator.func, schema=schema)
               else:
>>>>>>             assert validator.info.mode == 'after'
>>>>>>             if info_arg:
>>>>>>                 schema = core_schema.with_info_after_validator_function(function=validator.func, schema=schema)
                   else:
>>>>>>                 schema = core_schema.no_info_after_validator_function(function=validator.func, schema=schema)
  142:     if ref:
   75:         schema['ref'] = ref  # type: ignore
  142:     return schema
       
       
    1: def wrap_default(field_info: FieldInfo, schema: core_schema.CoreSchema) -> core_schema.CoreSchema:
           """Wrap schema with default schema if default value or `default_factory` are available.
       
           Args:
               field_info: The field info object.
               schema: The schema to apply default on.
       
           Returns:
               Updated schema by default value or `default_factory`.
           """
  919:     if field_info.default_factory:
>>>>>>         return core_schema.with_default_schema(
>>>>>>             schema, default_factory=field_info.default_factory, validate_default=field_info.validate_default
               )
  919:     elif field_info.default is not PydanticUndefined:
 1638:         return core_schema.with_default_schema(
  819:             schema, default=field_info.default, validate_default=field_info.validate_default
               )
           else:
  100:         return schema
       
       
    1: def _extract_get_pydantic_json_schema(tp: Any, schema: CoreSchema) -> GetJsonSchemaFunction | None:
           """Extract `__get_pydantic_json_schema__` from a type, handling the deprecated `__modify_schema__`."""
 4272:     js_modify_function = getattr(tp, '__get_pydantic_json_schema__', None)
       
 4272:     if hasattr(tp, '__modify_schema__'):
>>>>>>         from pydantic import BaseModel  # circular reference
       
>>>>>>         has_custom_v2_modify_js_func = (
>>>>>>             js_modify_function is not None
>>>>>>             and BaseModel.__get_pydantic_json_schema__.__func__  # type: ignore
>>>>>>             not in (js_modify_function, getattr(js_modify_function, '__func__', None))
               )
       
>>>>>>         if not has_custom_v2_modify_js_func:
>>>>>>             raise PydanticUserError(
>>>>>>                 'The `__modify_schema__` method is not supported in Pydantic v2. '
                       'Use `__get_pydantic_json_schema__` instead.',
>>>>>>                 code='custom-json-schema',
                   )
       
           # handle GenericAlias' but ignore Annotated which "lies" about its origin (in this case it would be `int`)
 4272:     if hasattr(tp, '__origin__') and not isinstance(tp, type(Annotated[int, 'placeholder'])):
 1173:         return _extract_get_pydantic_json_schema(tp.__origin__, schema)
       
 3099:     if js_modify_function is None:
 2650:         return None
       
  449:     return js_modify_function
       
       
    1: def get_json_schema_update_func(
           json_schema_update: JsonSchemaValue, json_schema_extra: JsonDict | typing.Callable[[JsonDict], None] | None
       ) -> GetJsonSchemaFunction:
  894:     def json_schema_update_func(
               core_schema_or_field: CoreSchemaOrField, handler: GetJsonSchemaHandler
           ) -> JsonSchemaValue:
>>>>>>         json_schema = {**handler(core_schema_or_field), **json_schema_update}
>>>>>>         add_json_schema_extra(json_schema, json_schema_extra)
>>>>>>         return json_schema
       
  894:     return json_schema_update_func
       
       
    1: def add_json_schema_extra(
           json_schema: JsonSchemaValue, json_schema_extra: JsonDict | typing.Callable[[JsonDict], None] | None
       ):
>>>>>>     if isinstance(json_schema_extra, dict):
>>>>>>         json_schema.update(to_jsonable_python(json_schema_extra))
>>>>>>     elif callable(json_schema_extra):
>>>>>>         json_schema_extra(json_schema)
       
       
    2: class _CommonField(TypedDict):
    1:     schema: core_schema.CoreSchema
    1:     validation_alias: str | list[str | int] | list[list[str | int]] | None
    1:     serialization_alias: str | None
    1:     serialization_exclude: bool | None
    1:     frozen: bool | None
    1:     metadata: dict[str, Any]
       
       
    1: def _common_field(
           schema: core_schema.CoreSchema,
           *,
    1:     validation_alias: str | list[str | int] | list[list[str | int]] | None = None,
    1:     serialization_alias: str | None = None,
    1:     serialization_exclude: bool | None = None,
    1:     frozen: bool | None = None,
    1:     metadata: Any = None,
       ) -> _CommonField:
  894:     return {
  894:         'schema': schema,
  894:         'validation_alias': validation_alias,
  894:         'serialization_alias': serialization_alias,
  894:         'serialization_exclude': serialization_exclude,
  894:         'frozen': frozen,
  894:         'metadata': metadata,
           }
       
       
    2: class _Definitions:
    1:     """Keeps track of references and definitions."""
       
    1:     def __init__(self) -> None:
  150:         self.seen: set[str] = set()
  150:         self.definitions: dict[str, core_schema.CoreSchema] = {}
       
    1:     @contextmanager
    1:     def get_schema_or_ref(self, tp: Any) -> Iterator[tuple[str, None] | tuple[str, CoreSchema]]:
               """Get a definition for `tp` if one exists.
       
               If a definition exists, a tuple of `(ref_string, CoreSchema)` is returned.
               If no definition exists yet, a tuple of `(ref_string, None)` is returned.
       
               Note that the returned `CoreSchema` will always be a `DefinitionReferenceSchema`,
               not the actual definition itself.
       
               This should be called for any type that can be identified by reference.
               This includes any recursive types.
       
               At present the following types can be named/recursive:
       
               - BaseModel
               - Dataclasses
               - TypedDict
               - TypeAliasType
               """
 3733:         ref = get_type_ref(tp)
               # return the reference if we're either (1) in a cycle or (2) it was already defined
 3733:         if ref in self.seen or ref in self.definitions:
  264:             yield (ref, core_schema.definition_reference_schema(ref))
               else:
 3469:             self.seen.add(ref)
 3469:             try:
 3469:                 yield (ref, None)
                   finally:
 3469:                 self.seen.discard(ref)
       
       
    1: def resolve_original_schema(schema: CoreSchema, definitions: dict[str, CoreSchema]) -> CoreSchema | None:
  434:     if schema['type'] == 'definition-ref':
  433:         return definitions.get(schema['schema_ref'], None)
    1:     elif schema['type'] == 'definitions':
>>>>>>         return schema['schema']
           else:
    1:         return schema
       
       
    2: class _FieldNameStack:
    1:     __slots__ = ('_stack',)
       
    1:     def __init__(self) -> None:
  236:         self._stack: list[str] = []
       
    1:     @contextmanager
    1:     def push(self, field_name: str) -> Iterator[None]:
  905:         self._stack.append(field_name)
  905:         yield
  894:         self._stack.pop()
       
    1:     def get(self) -> str | None:
>>>>>>         if self._stack:
>>>>>>             return self._stack[-1]
               else:
>>>>>>             return None
